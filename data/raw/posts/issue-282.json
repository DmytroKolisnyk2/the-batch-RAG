{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-282","id":"677598db4b838200017dcf51","uuid":"f1bad245-03d9-4e6f-bb2a-85593b99d31b","title":"Happy New Year! Hopes For 2025 With Mustafa Suleyman, Audrey Tang, Albert Gu, Hanno Basse, Joseph Gonzalez, David Ding","html":"<p>Dear friends,</p><p>Happy&nbsp;sum(i**3 for i in range(10)) !</p><p>Despite having worked on AI since I was a teenager, I‚Äôm now more excited than ever about what we can do with it, especially in building AI applications. Sparks are flying in our field, and 2025 will be a great year for building!</p><p>One aspect of AI that I‚Äôm particularly excited about is how easy it is to build software prototypes. AI is lowering the cost of software development and expanding the set of possible applications. While it can help extend or maintain large software systems, it shines particularly in building prototypes and other simple applications quickly.</p><p>If you want to build an app to print out flash cards for your kids (I just did this in a couple of hours with o1‚Äôs help), or write an application that monitors foreign exchange rates to manage international bank accounts (a real example from DeepLearning.AI‚Äôs finance team), or analyzes &nbsp;user reviews automatically to quickly flag problems with your products (DeepLearning.AI's content team does this), it is now possible to build these applications quickly through AI-assisted coding.</p><p>I find AI-assisted coding especially effective for prototyping because (i) stand-alone prototypes require relatively little context and software integration and (ii) prototypes in alpha testing usually don‚Äôt have to be reliable. While generative AI also helps with engineering large, mission-critical software systems, the improvements in productivity there aren't as dramatic, because it‚Äôs challenging to give the AI system all the context it needs to navigate a large codebase and also to make sure the generated code is reliable (for example, covering all important corner cases).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--35-.png\" class=\"kg-image\" alt=\"Andrew Ng celebrating and wishing a Happy New Year 2025 with sparklers.\" loading=\"lazy\" width=\"1200\" height=\"674\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--35-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--35-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--35-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Until now, a huge friction point for getting a prototype into users‚Äô hands has been deployment. Platforms like Bolt, Replit Agent, Vercel V0 use generative AI with agentic workflows to improve code quality, but more importantly, they also help deploy generated applications directly. (While I find these systems useful, my own workflow typically uses an LLM to design the system architecture and then generate code, one module at a time if there are multiple large modules. Then I test each module, edit the code further if needed ‚Äî sometimes using an AI-enabled IDE like Cursor ‚Äî and finally assemble the modules.)</p><p>Building prototypes quickly is an efficient way to test ideas and get tasks done. It‚Äôs also a great way to learn. Perhaps most importantly, it‚Äôs really fun! (At least I think it is. üòÑ)</p><p>How can you take advantage of these opportunities in the coming year? As you form new year resolutions, I hope you will:</p><ul><li><strong>Make a learning plan!</strong>&nbsp;To be effective builders, we all need to keep up with the exciting changes that continue to unfold. How many short courses a month do you want to take in 2025? If you discuss your learning plan with friends, you can help each other along. For instance, we launched a&nbsp;<a href=\"https://learn.deeplearning.ai/my/learnings?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">learning summary page</a>&nbsp;that shows what short courses people have taken. A few DeepLearning.AI team members have agreed to a friendly competition to see who can take more courses in 2025! &nbsp;</li><li><strong>Go build!</strong>&nbsp;If you already know how to code, I encourage you to build prototypes whenever inspiration strikes and you have a spare moment. And if you don‚Äôt yet code, it would be well worth your while to&nbsp;<a href=\"https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">learn</a>! Even small wins ‚Äî like the flash cards I printed out, which inspired my daughter to spend an extra 20 minutes practicing her multiplication table last night ‚Äî make life better. Perhaps you‚Äôll invent something that really takes off. And even if you don‚Äôt, you‚Äôll have fun and learn a lot along the way.</li></ul><p>Happy New Year!&nbsp;<br>Andrew</p><p>P.S. I develop mostly in Python. But if you prefer JavaScript: Happy&nbsp;Array.from({ length: 10 }, (_, i) =&gt; i ** 3).reduce((a, b) =&gt; a + b, 0) !</p><h1 id=\"2025-beckons\">2025 Beckons</h1><p>We stand at the threshold of a new era: One in which AI systems possess striking abilities to reason about the world, grasp our wishes, and take actions to fulfill them. What will we do with these powers? We asked leaders of the field to share their hopes for the coming year. As in our&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/issue-229/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">previous</a>&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/issue-177/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">New</a>&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/issue-125/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">Year<u>&nbsp;</u></a><a href=\"https://www.deeplearning.ai/the-batch/issue-72/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">special</a>&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/issue-20/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3x-UXmTAnW8kegCf35Jtc_r6APvCp-nI6Shjc5ArNos3a6Uly9QN8bkCLho3UsQSykNBS\" rel=\"noopener\">issues</a>, their answers offer inspiring views of what we may build and the good we can bring.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--36-.png\" class=\"kg-image\" alt=\"HANNO BASSE\" loading=\"lazy\" width=\"1200\" height=\"674\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--36-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--36-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--36-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"hanno-basse-generative-ai-for-artists\">Hanno Basse: Generative AI for Artists</h1><p>Stability AI‚Äôs aim is to liberate artists of all trades from the repetitive, mechanical aspects of their work and help them spend the majority of their time on the creative side. So our highest hope for next year is that generative AI will help people to be more creative and productive.</p><p>&nbsp; &nbsp; &nbsp;In addition, I hope the AI community will focus on:</p><ul><li><strong>Safety and integrity:</strong>&nbsp;Building safe products by embedding integrity from the earliest stages of development, ensuring the technology is used responsibly and makes a meaningful contribution to the art of storytelling.</li><li><strong>Accessibility:</strong>&nbsp;Generative AI products and tools must be accessible and usable for the broadest possible audience. Currently, much of generative AI remains&nbsp; accessible primarily to individuals who have advanced technical expertise, such as engineers. To address this, we need to develop much better tooling on top of foundational models, so they provide value to a diverse audience.</li><li><strong>Customization:</strong>&nbsp;Looking ahead, we expect generative AI to become increasingly specialized. Alongside large foundational models, we expect a significant rise in smaller, fine-tuned models tailored for specific and often quite narrow use cases and applications, even down to the level of a single task. This is where the true potential of generative AI will come to bear. Moreover, it is the safest and most responsible way to deploy generative AI in the real world.</li></ul><p><em>Hanno Basse is Chief Technology Officer of Stability AI. Previously he served as CTO of Digital Domain, Microsoft Azure Media and Entertainment, and 20th Century Fox Film Corp</em>.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--37-.png\" class=\"kg-image\" alt=\"DAVID DING\" loading=\"lazy\" width=\"1200\" height=\"672\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--37-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--37-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--37-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"david-ding-generated-video-with-music-sound-effects-and-dialogue\">David Ding: Generated Video With Music, Sound Effects, and Dialogue</h1><p>Last year, we saw an explosion of models that generate either video or audio outputs in high quality. In the coming year, I look forward to models that produce video clips complete with audio soundtracks including speech, music, and sound effects. I hope these models will bring a new era of cinematic creativity.</p><p>&nbsp; &nbsp; &nbsp;The technologies required for such cinematic video generators are in place. Several companies provide very competitive video models, and Udio and others create music models. All that‚Äôs left is to model video and audio simultaneously, including dialog and voiceovers. (In fact, we‚Äôve already seen something like this: Meta‚Äôs Movie Gen. Users describe a scene and Movie Gen will produce a video clip complete with a music score and sound effects.)</p><p>&nbsp; &nbsp; &nbsp;Of course, training such models will require extensive datasets. But I suspect that the videos used to train existing video generators had soundtracks that include these elements, so data may not be a barrier to developing these models.</p><p>&nbsp; &nbsp; &nbsp;Initially, these models won‚Äôt produce output that competes with the best work of professional video editors. But they will advance quickly. Before long, they‚Äôll generate videos and soundtracks that approach Hollywood productions in raw quality, just as current image models can produce images that are indistinguishable from high-end photographs.</p><p>&nbsp; &nbsp; &nbsp;At the same time, the amount of control users have over the video and audio outputs will continue to increase. For instance, when we first released Udio, users couldn‚Äôt control the harmony it generated. A few months later, we launched an update that enables users to specify the key, or tonal center. So users can take an existing song and remix it in a different key. We are continuing to do research into giving users additional levers of control, such as voice, melody, and beats, and I‚Äôm sure video modeling teams are doing similar research on controllability.</p><p>&nbsp; &nbsp; &nbsp;Some people may find the prospect of models that generate fully produced cinematic videos unsettling. I understand this feeling. I enjoy photography and playing music, but I‚Äôve found that image and audio generators are helpful starting points for my creative work. If I choose, AI can give me a base image that I can work on in Photoshop, or a musical composition to sample from or build on. Or consider AI coding assistants that generate the files for an entire website. You no longer need to rely on web developers, but if you talk to them, you‚Äôll learn that they don‚Äôt always enjoy writing the boilerplate code for a website. Having a tool that builds a site‚Äôs scaffold lets them spend their time on development tasks they find more stimulating and fun.</p><p>&nbsp; &nbsp; &nbsp;In a similar way, you‚Äôll be able to write a screenplay and quickly produce a rough draft of what the movie might look like. You might generate 1,000 takes, decide which one you like, and draw inspiration from that to guide a videographer and actors.</p><p>&nbsp; &nbsp; &nbsp;Art is all about the creative choices that go into it. Both you and I can use Midjourney to make a picture of a landscape, but if you‚Äôre an artist and you have a clear idea of the landscape you want to see, your Midjourney output will be more compelling than mine. Similarly, anyone can use Udio to make high-production quality music, but if you have good musical taste, your music will be better than mine. Video will remain an art form, because individuals will choose what their movie is about, how it looks, and how it feels ‚Äî and they‚Äôll be able to make those choices more fluidly, quickly, and interactively.</p><p><em>David Ding is a lifelong musician and co-founder of Udio, maker of a music-creation web app that empowers users to make original music. Previously, he was a Senior Research Engineer at Google DeepMind.</em></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--38-.png\" class=\"kg-image\" alt=\"JOSEPH GONZALEZ\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--38-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--38-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--38-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"joseph-gonzalez-general-intelligence\">Joseph Gonzalez: General Intelligence</h1><p>In 2025, I expect progress in training foundation models to slow down as we hit scaling limits and inference costs continue to rise. Instead, I hope for an explosion of innovation on top of AI, such as the rapidly developing&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfV03qgyTW7lCdLW6lZ3mcVCFdyG8bf-80W2W9w0k3DbqwrMxWwDDhfMq_W3Xmzhg8VYdw-Mq5x1Px6q9CW2HzxL9856psvW2phKjz4R3-_DN2K0jtMNQKkMW1hKTfX4B4k-0W5grprr4cK085W3Z_-VY8_cTkyW3TCFwR7WwgJLV8HFNJ2hmY7cW2hBCgH7G8NMxN3H1QY8DGvlKW5gg6lk24nyWQN8f-lc_5JZ6nN2yWfGW_jQMcW1HJn2M3HJWcNVNy3dL1wHpzxW21-wTG7qJZ0gW7DxX6y37fjcZW2q6Xtx7GrzKWV4Jb0H8cqbdlf2hTvld04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">agents stack</a>. I hope we will see innovation in how we&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfVj3qgyTW7Y8-PT6lZ3nGW5wzNP-1WCq-9W3LZwSY5_6FhLW7lrhN17fTMMkVWD1225GFcfvW4lZZTR8WP5gjW7NSQl81mk-6DW7JCsfq1KGggrN1PKvC2hYxCNW5f89fj71NMQGN4jB_cy5cwHFW8y45Wf24s0xlW7frhdq3qMVVcW31DKJD1fzpngW1T8cVT961RBqW1jh-VK1yrh3jW1sGmH25Q33tXW8Rg3gr70xkp7W3wRwxx5Qy0QYV8qgGy18qsX0W7J7Vdk5qGnDNW2B7nsb4zJtFDW7W4P8M7rYT_ZW1-nrMN7hkCjsW4BvpzN8R8qHqW6GxmSD680BLDN7vVcm9S4Cs3f6vPJ8d04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">combine AI with tools</a>&nbsp;and existing systems to deliver exciting new capabilities and create new product categories. Perhaps most of all, I am excited to see how people change in response to this new world.</p><p>&nbsp; &nbsp; &nbsp;<strong>We have achieved AGI. Now what?</strong>&nbsp;Let‚Äôs start with ‚Äî and hopefully end ‚Äî the longstanding debate around artificial general intelligence (AGI). I know this is controversial, but I think we have achieved AGI, at least definitionally: Our AI is now&nbsp;<em>general</em>. I will leave the longer debate about sentience and superintelligence to the philosophers and instead focus on the key innovation: generality.</p><p>&nbsp; &nbsp; &nbsp;The artificial intelligence or machine learning of previous decades was intelligent but highly specialized. It could often surpass human ability on a narrowly defined task (such as image recognition or content recommendation). Models today, and perhaps more importantly the&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfV03qgyTW7lCdLW6lZ3k_W1LX2XK1sXM_qW3_GlFJ97CwXGW169-C-8GgksHW2wmGk66xt6GvW3k7HYk3R5HdFW3BRfn23yPdg9W2T7pYJ2ktHc_W9f1tqT8MqlRwW81yftL5DWXqGW4_fdcQ8lZMLrVZ81NC5X-VW6W4LZGkN4W4ltBW8FWPFm36278JW2FvcD_62QwWzW3yn4Cl4ysFWGW7zkkNz4JlBhVW339P8K6Jq_k5N2q571gGgp_xV2g9393MVd17W4mrMqr7GQsTKV1vNDt6slwrTW7MVd8n5QHb72W65FMc68JgzzMW92FrKj98fzl4f3TmqvH04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">systems around them</a>, are capable of accomplishing a very wide range of tasks often as well as, and in some cases better, than humans. It is this generality that will allow engineers, scientists, and artists to use these models to innovate in ways that the model developers never imagined. It is also this generality, combined with market forces, that will make 2025 so exciting.</p><p>&nbsp; &nbsp; &nbsp;<strong>Becoming AI-native:</strong>&nbsp;The generality of these models and their natural language interfaces mean that everyone can use and explore AI.<em>&nbsp;</em>And we are!&nbsp;We are learning to explain our situations to machines, give context and guidance, and expect personalized answers and solutions. At&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfTq3qgyTW69sMD-6lZ3pXW255RkJ6S23P_W7K5NZm5X6n6KW4kpWtC8mH-dqW1wmcNy8SJSFsW2yDfz16c5fvnW8Glx3N8WK3YYW6ZSCmy3Jptt-W3pmvgR4_C5BLV5M5Hk6DPQs-W62QZ1l3G9344W99-j5H80njM9W6wXKd63PykWTW1GkjTJ1cCnrRW5LWLvy189H5kW7j9M_D5--wLrW2pnQPY3GwFHxW7m3lFJ6-3C4gW5TfF955fztfFW14K3M-60SMF8V5LccL6BF9qtf3rB44C04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">RunLLM</a>, where I‚Äôm a co-founder, we‚Äôre building high-quality technical support agents. We find that users increasingly use our agents not just to solve problems but to personalize solutions to their specific tasks. We‚Äôve also found ‚Äî to our surprise ‚Äî that users share much more with an AI than they would share with another person.</p><p>&nbsp; &nbsp; &nbsp;Meanwhile, at UC Berkeley, I am impressed by students who use AI to re-explain my lecture or study from an AI-generated practice exam. They have found ways to use AI to help personalize and improve their learning experiences. In 2025, maybe we will begin to prefer AIs over humans when we need help or are trying to learn.</p><p>&nbsp; &nbsp; &nbsp;Across all these use cases, we‚Äôre clearly getting better at working around the limitations of large language models and using AI in ways I would not have imagined 12 months ago.</p><p>&nbsp; &nbsp; &nbsp;<strong>Return on AI:</strong>&nbsp;The focus in 2025 will turn to showing real value from past investments. Investors and enterprises will expect startups and enterprise AI teams to transition from exploring to solving real problems ‚Äî reducing cost, generating revenue, improving customer experience, and so on. This is bad news for academics who need to raise research funds (DM me if you have any leftover funds from fiscal year 2024) but great news for everyone else, who will ride the wave of new AI-powered features.</p><p>&nbsp; &nbsp; &nbsp;There will be a race to find innovative ways to incorporate AI into every aspect of a product and business. In many cases, we will see hastily executed chatbots and auto-summarization features ‚Äî the first step on the AI journey. I hope these will be quickly replaced by contextual agents that adapt to users‚Äô needs and learn from their interactions. The pandemic paved the way for remote (digital) assistants and exposed a virtually accessible workplace with the tools needed for tomorrow‚Äôs agents. These agents likely will specialize in filling roles once held by people or maybe filling new roles created by other agents. Perhaps we will know that AI has delivered on its promise when everyone manages their own team of custom agents.</p><p>&nbsp; &nbsp; &nbsp;<strong>Chat is only the beginning:</strong>&nbsp;My hope for 2025 is that we move beyond chatting and discover how to use AI to do great things! I hope we will see AI agents that work in the background, invisibly helping us with our daily tasks. They will surface the right context as we make decisions and help us learn as the world changes. Through context and tools, they will let us know what we are missing and catch the balls we drop. We will chat less and our AI powered agents will accomplish more on our behalf. I look forward to the day when I can confidently step away from a keyboard and focus on the human interactions that matter.</p><p><em>Joseph Gonzalez is a professor at UC Berkeley, a co-founder of RunLLM, and an advisor to Genmo and Letta.</em></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--39-.png\" class=\"kg-image\" alt=\"ALBERT GU\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--39-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--39-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--39-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"albert-gu-more-learning-less-data\">Albert Gu: More Learning, Less Data</h1><p>Building a foundation model takes tremendous amounts of data. In the coming year, I hope we‚Äôll enable models to learn more from less data.</p><p>&nbsp; &nbsp; &nbsp;The AI community has achieved remarkable success by scaling up transformers and datasets. But this approach may be reaching a point of diminishing returns ‚Äî an increasingly widespread belief among the pretraining community as they try to train next-generation models. In any case, the current approach poses practical problems. Training huge models on huge datasets consumes huge amounts of time and energy, and we‚Äôre running out of new sources of data for training large models.</p><p>&nbsp; &nbsp; &nbsp;The fact is, current models consume much more data than humans require for learning. We‚Äôve known this for a while, but we‚Äôve ignored it due to the amazing effectiveness of scaling. It takes trillions of tokens to train a model but orders of magnitude less for a human to become a reasonably intelligent being. So there‚Äôs a difference in sample efficiency between our best models and humans. Human learning shows that there‚Äôs a learning algorithm, objective function, architecture, or a combination thereof that can learn more sample-efficiently than current models.</p><p>&nbsp; &nbsp; &nbsp;One of the keys to solving this problem is enabling models to produce higher-level abstractions and filter out noise. I believe this concept, and thus the general problem of data efficiency, is related to several other current problems in AI:&nbsp;</p><ul><li><strong>Data curation:</strong>&nbsp;We know that the specific data we use to train our models is extremely important. It‚Äôs an open secret that most of the work that goes into training foundation models these days is about the data, not the architecture. Why is this? I think it‚Äôs related to the fact that our models don‚Äôt learn efficiently. We have to do the work ahead of time to prepare the data for a model, which may hinder the core potential of AI as an automatic process for learning from data.</li><li><strong>Feature engineering:</strong>&nbsp;In deep learning, we always move toward more generalized approaches. From the beginning of the deep learning revolution, we‚Äôve progressively removed handcrafted features such as edge detectors in computer vision and n-grams in natural language processing. But that engineering has simply moved to other parts of the pipeline. Tokenization, for instance, involves engineering implicit features. This suggests that there‚Äôs still a lot of room to make model architectures that are more data-efficient and more generally able to handle more raw modalities and data streams.</li><li><strong>Multimodality:</strong>&nbsp;The key to training a model to understand a variety of data types together is figuring out the core abstractions in common and relating them to each other. This should enable models to learn from less data by leveraging all the modalities jointly, which is a core goal of multimodal learning.&nbsp;</li><li><strong>Interpretability and robustness:</strong>&nbsp;To determine why a model produced the output it did, it needs to be able to produce higher-level abstractions, and we need to track the way it captures those abstractions. The better a model is at doing this, the more interpretable it should be, the more robust it should be to noise, and likely the less data it should need for learning.</li><li><strong>Reasoning:</strong>&nbsp;Extracting higher-level patterns and abstractions should allow models to reason better over them. Similarly, better reasoning should mean less training data.</li><li><strong>Democratization:</strong>&nbsp;State-of-the-art models are expensive to build, and that includes the cost of collecting and preparing enormous amounts of data. Few players can afford to do it. This makes developments in the field less applicable to domains that lack sufficient data or wealth. Thus more data-efficient models would be more accessible and useful.&nbsp;</li></ul><p>&nbsp; &nbsp; &nbsp;Considering data efficiency in light of these other problems, I believe they‚Äôre all related. It‚Äôs not clear which is the cause and which are the effects. If we solve interpretability, the mechanisms we engineer may lead to models that can extract better features and lead to more data-efficient models. Or we may find that greater data efficiency leads to more interpretable models.</p><p>&nbsp; &nbsp; &nbsp;Either way, data efficiency is fundamentally important, and progress in that area will be an indicator of broader progress in AI. I hope to see major strides in the coming year.</p><p><em>Albert Gu is an Assistant Professor of Machine Learning at Carnegie Mellon University and Chief Scientist of Cartesia AI. He appears on Time‚Äôs list of the most influential people in AI in 2024.</em></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--40-.png\" class=\"kg-image\" alt=\"MUSTAFA SULEYMAN\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--40-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--40-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--40-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"mustafa-suleyman-agents-of-action\">Mustafa Suleyman: Agents of Action</h1><p>In 2025, AI will have learned to see, it will be way smarter and more accurate, and it will start to do things on your behalf.</p><p>&nbsp; &nbsp; &nbsp;Today AI systems struggle to understand our full context. Their perception is limited to the chat window and a fairly narrow set of interactions. They don‚Äôt have a full understanding of what we‚Äôre doing or aiming for beyond that. To really grasp our intentions, they need to see what we see.</p><p>&nbsp; &nbsp; &nbsp;This capability is now here. AI can sit within the software we use and work alongside us co-browsing. If text was the first modality for interacting with AI, and voice the breakthrough feature of 2024, I think vision will occupy a similar place in 2025. At Microsoft AI, it has been a major priority of mine to create an AI that can work alongside you in your browser, so you can chat through what you‚Äôre looking at or working on and make it a true two-way interaction.</p><p>&nbsp; &nbsp; &nbsp;Vision is a step change, palpably different from the ways we‚Äôve been able to use computers in the past. I can‚Äôt wait to see where it goes in the coming months.</p><p>&nbsp; &nbsp; &nbsp;Alongside vision, we‚Äôll see enormous progress in reducing hallucinations. This is still a critical blocker for widespread adoption of AI. If people doubt what AI tells them, it severely limits what they‚Äôll use it for. Trust is utterly foundational for AI. The good news is that the quality of models as well as their retrieval and grounding capabilities are still rapidly improving.</p><p>&nbsp; &nbsp; &nbsp;While I don‚Äôt think we‚Äôll eliminate hallucinations entirely, by this time next year, we won‚Äôt be fussing about them as much. On most topics, talking to an AI will be at least as reliable as using a search engine and probably more so. This isn‚Äôt about a single technical advance, but the persistent accretion of gains across the spectrum. It will make a massive difference.</p><p>&nbsp; &nbsp; &nbsp;Lastly, we‚Äôre entering the agentic era. We‚Äôve been dreaming of this moment for decades. In my book,&nbsp;<em>The Coming Wave: Technology, Power, and the 21st Century‚Äôs Greatest Dilemma</em>, I proposed that we start thinking about ACI, or&nbsp;<em>artificially capable intelligence</em>: the moment when AI starts taking concrete actions on behalf of users. Giving AI the ability to take actions marks the moment when AI isn‚Äôt just talking to us, it‚Äôs doing things. This is a critical change, and it‚Äôs right around the corner.</p><p>&nbsp; &nbsp; &nbsp;If we get it right, we‚Äôll be able to, at once, make life easier and calmer while supercharging businesses and personal productivity alike. But agentic capabilities demand the highest standards of safety, security, and responsibility. Meanwhile, creating genuinely useful agents still has many formidable hurdles, not least integrating with myriad other systems.</p><p>&nbsp; &nbsp; &nbsp;The momentum is there. Actions are on their way. 2025 is going to be a big year.</p><p><em>Mustafa Suleyman is Chief Executive Officer of Microsoft AI. He co-founded Inflection AI and founded DeepMind Technologies.</em></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--41-.png\" class=\"kg-image\" alt=\"AUDREY TANG\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--41-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--41-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--41-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"audrey-tang-ai-that-unites-us\">Audrey Tang: AI That Unites Us</h1><p>As we approach 2025, my greatest hope for AI is that it will enable&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfVj3qgyTW7Y8-PT6lZ3pJW5BGbBm83TnJVW5fVK3R3m74vYW8rC14X1WtKrVVF35Gq8xq2YJVq3sjH99-DHhW7bkDfb8gM-RpW77jWWT2RY-19W5WDjS_78crHtW4BT4yc1rd8NGW2_M-BW3LC5sMW462nN34QfC12W4mCVcp3jjd7jW2ZjMsq84NCDYW91rlBx2x92xzW8J-1Zk3n8WQhW5bNKW-6KZZrJW1mmqVz4xHFgyW4v6kBQ3q7jDgW7--dGV3xYSSKW8KL5m5117HfSW8vBYp08w-BLFW4YfNJr8XPgw-W8mJhMr7Fm7RGW1DD8rJ5hgrxrW3fjD9n4tzNTnW6PZtcB7HBYQpf7q_Gtq04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">prosocial</a>&nbsp;platforms that promote empathy, understanding, and collaboration rather than division.</p><p>&nbsp; &nbsp; &nbsp;For too long, the algorithms that drive social media have functioned like strip-mining machines, extracting attention while eroding trust and social cohesion. What remains are depleted online spaces, where empathy struggles to take root and collective problem-solving finds no fertile ground. AI can ‚Äî and should ‚Äî help us transcend these entrenched divides.</p><p>&nbsp; &nbsp; &nbsp;To achieve this, we must design AI systems that place prosocial values at their core. Instead of reinforcing fragmentation, recommendation algorithms can guide us toward ‚Äú<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfTK3qgyTW6N1vHY6lZ3mdW91PQQS9hZtfMW9dM39r1jWlwpW45pklJ4N0WTVW97gNv33m8C1kW7kR6g94_FThBVfPY7X1wY1fnW3XWvtK6Z1d67W1bFsf21g4BWjW7dpW6J2CdzdjW3zP8MS96TNfHW68zJ6w2NnvbdW2JhMwG8fNZtVW4g4C__6d9Bc1W4H_qzb6yjPygW77VQB42ms-cfW5-vtRt5MgJlTW7N9wrP6Y0N9xW1YbNXX7Qd77HW7Tqj_j35ctxJW4-7CKd5ynd-vW9cb4dP7pGzrfN1Ks5PpdX5VTf71fhsR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">bridging content</a>‚Äù that reveals common ground. They should clearly identify the communities a piece of content relates to ‚Äî whether physical, religious, political, social, cultural, or professional ‚Äî and illuminate the specific lines of division it seeks to mend.</p><p>&nbsp; &nbsp; &nbsp;Realizing this vision requires a fundamental shift in what we optimize for. Instead of relying on pure engagement metrics, we should adopt values-driven indicators that prioritize constructive discourse and mutual understanding. For instance, we might spotlight ‚Äúsurprising validators,‚Äù or individuals and perspectives that productively challenge assumptions, thereby enriching our sense of what seemed irreconcilable. Researchers and developers should co-create new ranking and curation methods, embed them into widely used platforms, and rigorously&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfVC3qgyTW8wLKSR6lZ3n6W5fP8rW4Y6BM4W5hX8hP8HsfRKW3qSyJt290fywW6fdfwS99sB5cW2yh2Vb6dZbt9W1CC18n1kHmBhW5tX9rT7YYxdXN7j2XFRTQkhXW2qt0xX4QbfmnW4LqL3T8ZBcxLVBcDG06wbLLmW1jwHn46WHcZJW3dN6Sp7QdVVRW5xYSc4614mZ8W6tVxCP3C5gllW9dpq574cJcjFVLVBGg1SBYf_W3rFhfX81j6_fW55Cx-j35tTRyW2BY0L-6dkV-lW2XpZJF37Y3x1W8zfpLG1YbZkQW3vQyfY6-ZVnzN3Yyd9Vq8ZbsW2qxpyy7_t2rqW88DNvX7W6MSJVdhtSQ8vw2rgVjdLsj21TBdff8F5J4x04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">assess</a>&nbsp;their impact on democratic life.</p><p>&nbsp; &nbsp; &nbsp;At the same time, the AI community must embrace participatory, inclusive approaches to development and governance. Research on&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfV03qgyTW7lCdLW6lZ3mmW37tmtP8c8Nd2W2R2Xdz6Mgq7_N7ShnMmZsch7W2_D8R79kYM6jW7qJnBD8MQxp-W1d-5BQ5KnGqSW22cL195f0Nc-VX8yRG1k1CYpW8SpcLC25s1z9W6V9LwW3_0c3XN4Jr1TCjmKlMN96B_DLntGm0W2kn_jr6FnNfCW4Zfcfs6njBtJW14J-qw4w2QG_W5YJ-bD8_-llBW5TLqPw3W9VfFW7WfGLj4j1m8kW3hxT554FDBKjW3KRGtV2d_CzzM3s5H8pnSqTVSbGK329Tx_wW8Xpy518CNhKxW5WCcm67XjtMhf3JYx4s04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">pluralistic alignment</a>&nbsp;stresses that AI systems emerge from and operate within complex social contexts, and including a wide range of voices helps guard against institutional blind spots. Tools like&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfV03qgyTW7lCdLW6lZ3p4W3gN80C6crVhXW97QFHP5tDVpSW44mHLL3J3p1-V925h46vF4rbW25wM1S9gz7vXW1WzqmT3HBpzvW6-JGVv3KRhG_W679cfP5SrzHwW2CnBn08CnY-YN8MCPvnF7LCLW1hCSNv7fmzNNW3vgvFW6SWzqpW5FXx8L6VkTxgW1MmThk1xx1wCW7WD5Hp5YG_lsW3zdwdK7xKGh4W8spKCR1z_d2VW5NCh3S52BvntMZVzT27-0TJW36h_nv8rQpgqW2Xk2xF1hGDryW2LPSvX3XyvKwW6NTRNV18vpvXW1KsbwG8f0tKTf31D2rq04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Polis</a>, which can visualize stances and reveal hidden areas of consensus, already illustrate how complexity can be transformed into clarity. Such participatory methods ensure that AI reflects the priorities and values of the societies it serves, rather than amplifying the biases of the few.</p><p>&nbsp; &nbsp; &nbsp;By embracing these inclusive, democratic principles, AI can help us co-create&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWDWFb7nZnZjW5NftxJ44cwFYW6rg8CD5qhw-_MGxfTK3qgyTW6N1vHY6lZ3lgW2qs4N07G44N6W683jG82QS2fqW6tydh383ZsC2W7DN9-g5kkMtYW5h-HpV2HsKFvW8RkqKc2vX6HWW8xhVc83fF4FMN8KPqy3-bflGW3QDQXZ6rFTlCW8Fzb_Y326PynW2NSc7x1Z3bTmW7fzBWs8kvjg-W2lxBjY5-r--DW34gQWh5V8tFvW9bMgmf7KpKJyW6Q97NV8YbFw_W8VCWNZ1yYmYmN81B6bclj3XhVmWcRv1GTsnJW6MDL5s5fVHRMW6HJzSc1Lj2Z2W1KY3655WZMBzf8m514x04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">digital public squares</a>&nbsp;that foster social cohesion rather than erode it. Embedding collective input at every stage ‚Äî from how we build datasets to how we set governance policies ‚Äî ensures that AI systems genuinely align with a spectrum of human values and serve as catalysts for common understanding.</p><p><em>Audrey Tang is Taiwan‚Äôs Cyber Ambassador, former Minister of Digital Affairs, and co-author of&nbsp;</em>Plurality: The Future of Collaborative Technology and Democracy<em>.</em></p>","comment_id":"677598db4b838200017dcf51","feature_image":"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--35--1.png","featured":false,"visibility":"public","created_at":"2025-01-01T11:34:51.000-08:00","updated_at":"2025-02-13T14:02:30.000-08:00","published_at":"2025-01-01T11:58:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: Despite having worked on AI since I was a teenager, I‚Äôm now more excited than ever about what we can do with it, especially in building AI applications.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"632200f702f3e2003d8e83a1","name":"Interviews & Essays","slug":"interviews-essays","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/interviews-essays/"},{"id":"62cc5c4c7343db004d5756cd","name":"New Year","slug":"new-year","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/new-year/"},{"id":"67759f094b838200017dcfba","name":"Jan 01, 2025","slug":"jan-01-2025","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/jan-01-2025/"},{"id":"67759f094b838200017dcfbb","name":"issue-282","slug":"issue-282","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-282/"}],"authors":[{"id":"630fb12a0605aa004d50999b","name":"Editorial Team","slug":"editor","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/editor/"},{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"630fb12a0605aa004d50999b","name":"Editorial Team","slug":"editor","profile_image":null,"cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/editor/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-282/","excerpt":"The Batch AI News and Insights: Despite having worked on AI since I was a teenager, I‚Äôm now more excited than ever about what we can do with it, especially in building AI applications.","reading_time":17,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Happy New Year! Hopes For 2025 With Mustafa Suleyman, Audrey Tang, Albert Gu, Hanno Basse, and more...","meta_description":"The Batch AI News and Insights: Despite having worked on AI since I was a teenager, I‚Äôm now more excited than ever about what we can do with it...","email_subject":null,"frontmatter":null,"feature_image_alt":"Andrew Ng celebrating and wishing a Happy New Year 2025 with sparklers.","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--35--1.png","dimensions":{"width":1200,"height":674}},"banner":{"title":"Data Analytics Professional Certificate","databaseId":36316,"id":"cG9zdDozNjMxNg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2025/03/Vertical-side-banner-ads-7.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3XWMC3m","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"‚ú® Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}