{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-209","id":"64d3ddfe133a7c00015884bb","uuid":"7cd21579-cc95-482d-b674-4c8f3b5c5e62","title":"Medical AI Advances, Chatbots Work the Drive-Thru, ChatGPT Racks Up Server Fees, Image Generators Get an Upgrade","html":"<p><em>Dear friends,</em></p><p><em>Do large language models understand the world? As a scientist and engineer, I’ve avoided asking whether an AI system “understands” anything. There’s no widely agreed-upon, scientific test for whether a system really understands — as opposed to appearing to understand — just as no such tests exist for consciousness or sentience, as I discussed in an earlier </em><a href=\"https://www.deeplearning.ai/the-batch/can-an-ai-system-be-sentient-ask-a-philosopher?ref=dl-staging-website.ghost.io\"><em>letter</em></a><em>. This makes the question of understanding a matter of philosophy rather than science. But with this caveat, I believe that LLMs build sufficiently complex models of the world that I feel comfortable saying that, to some extent, they do understand the world.</em></p><p><em>To me, the work on </em><a href=\"https://arxiv.org/abs/2210.13382?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\"><em>Othello-GPT</em></a><em> is a compelling demonstration that LLMs build world models; that is, they figure out what the world really is like rather than blindly parrot words. Kenneth Li and colleagues trained a variant of the GPT language model on sequences of moves from Othello, a board game in which two players take turns placing game pieces on an 8x8 grid. For example, one sequence of moves might be d3 c5 f6 f5 e6 e3…, where each pair of characters (such as d3) corresponds to placing a game piece at a board location.</em></p><p><em>During training, the network saw only sequences of moves. It wasn’t explicitly told that these were moves on a square, 8x8 board or the rules of the game. After training on a large dataset of such moves, it did a decent job of predicting what the next move might be.</em></p><p><em>The key question is: Did the network make these predictions by building a world model? That is, did it discover that there was an 8x8 board and a specific set of rules for placing pieces on it, that underpinned these moves? The authors demonstrate convincingly that the answer is yes. Specifically, given a sequence of moves, the network’s hidden-unit activations appeared to capture a representation of the current board position as well as available legal moves. This shows that, rather than being a “</em><a href=\"https://en.wikipedia.org/wiki/Stochastic_parrot?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\"><em>stochastic parrot</em></a><em>” that tried only to mimic the statistics of its training data, the network did indeed build a world model.</em></p><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--24-.jpg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--24-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--24-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--24-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p><em>While this study used Othello, I have little doubt that LLMs trained on human text also build world models. A lot of “emergent” behaviors of LLMs — for example, the fact that a model fine-tuned to follow English instructions can follow instructions written in other languages — seem very hard to explain unless we view them as understanding the world.</em></p><p><em>AI has wrestled with the notion of understanding for a long time. Philosopher John Searle published the </em><a href=\"https://plato.stanford.edu/entries/chinese-room/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\"><em>Chinese Room Argument</em></a><em> in 1980. He proposed a thought experiment: Imagine an English speaker alone in a room with a rulebook for manipulating symbols, who is able to translate Chinese written on paper slipped under the door into English, even though the person understands no Chinese. Searle argued that a computer is like this person. It appears to understand Chinese, but it really doesn’t.</em></p><p><em>A common counterargument known as the Systems Reply is that, even if no single part of the Chinese Room scenario understands Chinese, the complete system of the person, rulebook, paper, and so on does. Similarly, no single neuron in my brain understands machine learning, but the system of all the neurons in my brain hopefully do. In my recent conversation with Geoff Hinton, which you can watch </em><a href=\"https://www.linkedin.com/posts/andrewyng_had-an-insightful-conversation-with-geoff-activity-7073688821803978752-DO9h?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\"><em>here</em></a><em>, the notion that LLMs understand the world was a point we both agreed on.</em></p><p><em>Although philosophy is important, I seldom write about it because such debates can rage on endlessly and I would rather spend my time coding. I’m not sure what the current generation of philosophers thinks about LLMs understanding the world, but I am certain that we live in an age of wonders!</em></p><p><em>Okay, back to coding.</em></p><p><em>Keep learning,</em></p><p><em>Andrew</em></p><p></p><h1 id=\"news\">News</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--43-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"679\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--43-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--43-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--43-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"rigorous-trial-ai-matches-humans-in-breast-cancer-diagnosis\">Rigorous Trial: AI Matches Humans in Breast Cancer Diagnosis</h1><p>A deep learning system detected breast cancer in mammograms as well as experienced radiologists, according to a landmark study.</p><p><strong>What’s new:</strong> Researchers at Lund University in Sweden <a href=\"https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(23)00298-X/fulltext?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">conducted</a> a randomized, controlled, clinical trial to determine whether an AI system could save radiologists’ time without endangering patients — purportedly the first study of AI’s ability to diagnose breast cancer from mammograms whose design met the so-called gold standard for medical tests. Their human-plus-machine evaluation procedure enabled radiologists to spend substantially less time per patient while exceeding a baseline for safety.</p><p><strong>How it works:</strong> The authors randomly divided 80,000 Swedish women into a control group and an experimental group.</p><ul><li>The control group had its mammograms evaluated manually by two radiologists (the standard practice in much of Europe).</li><li>The second, experimental group had its mammograms evaluated by <a href=\"https://transparabreastcare.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">Transpara</a>, a convolutional neural network trained to recognize breast tumors. Transpara scored mammograms for cancer risk on a scale from 1 (low risk) to 10 (high risk). It added marks to mammograms that scored 8 to 10 highlighting potential cancer locations.</li><li>Human radiologists evaluated the experimental group’s mammograms, scores, and marks. One radiologist reviewed each mammogram, unless Transpara had assigned a score of 10, in which case two radiologists reviewed it. Thus at least one radiologist examined each patient in the study.</li><li>Finally, the radiologists chose whether or not to recall each patient for further examination. This enabled them to detect false positives.</li></ul><p><strong>Results</strong>: The AI-assisted diagnosis achieved a cancer detection rate of 6.1 per 1,000 patients screened, comparable to the control method and above an established lower limit for safety. The radiologists recalled 2.0 percent of the control group and 2.2 percent of the experimental group, and both the control and experimental groups showed the same false-positive rate of 1.5 percent. (The difference in recall rates coupled with the matching false-positive rate suggests that the AI method detected 20 percent more cancer cases than the manual method, though authors didn’t emphasize that finding.) Moreover, since approximately 37,000 patients were only examined by one radiologist, the results indicate that AI saved 44.3 percent of the examination workload without increasing the number of misdiagnosed patients.</p><p><strong>Yes, but:</strong> The authors’ method requires more study before it can enter clinical practice; for instance, tracking patients of varied genetic backgrounds. The authors are continuing the trial and plan to publish a further analysis after 100,000 patients have been enrolled for two years.</p><p><strong>Behind the news:</strong> Radiologists have used AI to help diagnose breast cancer since the 1980s (though that method is <a href=\"https://www.deeplearning.ai/the-batch/radiologists-eye-ai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">questionable</a>.) A 2020 <a href=\"https://www.deeplearning.ai/the-batch/pushing-for-reproducible-research/?ref=dl-staging-website.ghost.io\" rel=\"noopener\">study</a> by Google Health claimed that AI outperformed radiologists, but critics found flaws in the methodology.</p><p><strong>Why it matters:</strong> Breast cancer <a href=\"https://www.who.int/news-room/fact-sheets/detail/breast-cancer?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">causes</a> more than 600,000 deaths annually worldwide. This work suggests that AI can enable doctors to evaluate more cases faster, helping to alleviate a shortage of radiologists. Moreover, treatment is more effective the earlier the cancer is diagnosed, and the authors’ method caught more early than late ones.</p><p><strong>We’re thinking:</strong> Medical AI systems that perform well in the lab often fail in the clinic. For instance, a neural network may outperform humans at cancer diagnosis in a specific setting but, having been trained and tested on the same data distribution, isn’t robust to changes in input (say, images from different hospitals or patients from different populations). Meanwhile, medical AI systems have been subjected to very <a href=\"https://www.jmir.org/2022/8/e37188?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">few</a> randomized, controlled trials, which is considered the gold standard for medical testing. Such trials have their limitations, but they’re a powerful tool for bridging the gap between lab and clinic.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--25-.jpg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--25-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--25-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--25-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"robots-work-the-drive-thru\">Robots Work the Drive-Thru</h1><p>Chatbots are taking orders for burgers and fries — and making sure you buy a milkshake with them.</p><p><strong>What’s new:</strong> Drive-thru fast-food restaurants across the United States are rolling out chatbots to take orders, <em>The Wall Street Journal</em> <a href=\"https://www.wsj.com/articles/can-ai-replace-humans-we-went-to-the-fast-food-drive-through-to-find-out-193c03e9?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">reported</a>. Reporter Joanna Stern delivers a hilarious consumer’s-eye view in an accompanying <a href=\"https://www.youtube.com/watch?v=JJxBySZwBAI&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">video</a>.</p><p><strong>How it works:</strong> Hardee’s, Carl’s Jr., Checkers and Del Taco use technology from Presto, a startup that specializes in automated order-taking systems. The company <a href=\"https://presto.com/drive-thru/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">claims</a> 95 percent order completion and $3,000 in savings per month per store. A major selling point: Presto’s bot pushes bigger orders that yield $4,500 per month per store in additional revenue.</p><ul><li>Presto uses proprietary natural language understanding and large language model technology. It constrains the bot to stick to the menu if customers make unrelated comments.</li><li>Approached by a customer, it reads an introductory script and waits for a reply. Then it converses until it determines that the order is complete (for instance, when the customer says, “That’s it”). Then it passes the order to human employees for fulfillment.</li><li>The Presto bot passes the conversation on to a human if it encounters a comment it doesn’t understand. In <em>The Wall Street Journal</em>’s reporting, it did this when asked to speak with a human and when subjected to loud background noise. However, when asked if a cheeseburger contains gluten, it erroneously answered, “no.”</li><li>Presto optimizes its technology for upsales: It pushes customers to increase their orders by making suggestions (“Would you like to add a drink?”) based on the current order, the customer’s order history, current supplies, time of day, and weather.</li></ul><p><strong>Behind the news: </strong>The fast-food industry is embracing AI to help out in the kitchen, too.</p><ul><li>In late 2022, Chipotle began <a href=\"https://www.deeplearning.ai/the-batch/chipotle-tests-ai-for-predicting-customer-demand/?ref=dl-staging-website.ghost.io\">testing</a> AI tools from New York-based <a href=\"https://precitaste.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">PreciTaste</a> that monitor a restaurant location’s customer traffic and ingredient supplies to estimate which and how many menu items employees will need to prepare.</li><li>Since 2021, White Castle <a href=\"https://www.deeplearning.ai/the-batch/deep-learning-for-deep-frying/?ref=dl-staging-website.ghost.io\">has deployed</a> robotic arms from Southern California-based <a href=\"https://misorobotics.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">Miso Robotics</a> to deep-fry foods in <a href=\"https://misorobotics.com/newsroom/white-castle-expands-partnership-with-miso-robotics-to-install-flippy-2-in-100-new-locations/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">more than 100</a> locations.</li><li>In 2021, Yum! Brands, which owns KFC, Pizza Hut, and Taco Bell, <a href=\"https://www.qsrmagazine.com/news/yum-brands-completes-935-million-purchase-dragontail-systems?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">acquired</a> Dragontail Systems, whose software uses AI to coordinate the timing of cooking and delivering orders.</li></ul><p><strong>Yes, but:</strong> McDonald’s, the world’s biggest fast-food chain by revenue, uses technology from IBM and startup Apprente, which it <a href=\"https://techcrunch.com/2019/09/10/mcdonalds-acquires-apprente/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">acquired</a> in 2019. As of early this year, the system <a href=\"https://gizmodo.com/mcdonalds-ai-fast-food-big-mac-tiktok-1850112205?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">achieved</a> 80 percent accuracy — far below the 95 percent that executives had expected.</p><p><strong>Why it matters:</strong> In fast food, chatbots are continuing a trend in food service that began with Automat cafeterias in the early 1900s. Not only are they efficient at taking orders, apparently they’re more disciplined than typical employees when it comes to suggesting ways to enlarge a customer’s order (and, consequently, waist).</p><p><strong>We’re thinking:</strong> When humans aren’t around, order-taking robots order chips.</p><hr><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM <strong>DEEPLEARNING.AI</strong></h2><figure class=\"kg-card kg-image-card\"><a href=\"https://www.eventbrite.com/e/deep-dive-into-llm-evaluation-with-weights-biases-tickets-689536541357?aff=Batch&ref=dl-staging-website.ghost.io\"><img src=\"https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--49-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--49-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/The-Batch-ads-and-exclusive-banners--49-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/The-Batch-ads-and-exclusive-banners--49-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--49-.png 1680w\" sizes=\"(min-width: 720px) 720px\"></a></figure><p>Join our upcoming workshop with Weights &amp; Biases and learn how to evaluate Large Language Model systems, focusing on Retrieval Augmented Generation (RAG) systems. <a href=\"https://www.eventbrite.com/e/deep-dive-into-llm-evaluation-with-weights-biases-tickets-689536541357?aff=Batch&ref=dl-staging-website.ghost.io\">Register now</a></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--44-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--44-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--44-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--44-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"the-high-cost-of-serving-llms\">The High Cost of Serving LLMs</h1><p>Amid the hype that surrounds large language models, a crucial caveat has receded into the background: The current cost of serving them at scale.</p><p><strong>What’s new:</strong> As chatbots go mainstream, providers must contend with the expense of serving sharply rising numbers of users, the <em>Washington Post</em> <a href=\"https://www.washingtonpost.com/technology/2023/06/05/chatgpt-hidden-cost-gpu-compute/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">reported</a>.</p><p><strong>The price of scaling:</strong> The transformer architecture, which is the basis of models like OpenAI’s ChatGPT, requires a lot of processing. Its self-attention mechanism is computation-intensive, and it gains performance with higher parameter counts and bigger training datasets, giving developers ample incentive to raise the compute budget.</p><ul><li>Hugging Face CEO Clem Delangue said that serving a large language model typically costs much more than customers pay.</li><li><em>SemiAnalysis</em>, a newsletter that covers the chip market, in February <a href=\"https://www.semianalysis.com/p/the-inference-cost-of-search-disruption?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">estimated</a> that OpenAI spent $0.0036 to process a GPT-3.5 prompt. At that rate, if Google were to use GPT-3.5 to answer the approximately 320,000 queries per second its search engine receives, its operating income would drop from $55.5 billion to $19.5 billion annually.</li><li>In February, Google <a href=\"https://blog.google/technology/ai/bard-google-ai-search-updates/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">cited</a> savings on processing as the reason it based its Bard chatbot on a relatively small version of its LaMDA large language model.</li><li>Rising demand for chatbots means a greater need for the GPU chips that often process these models at scale. This demand is driving up the prices of both the chips and cloud services based on them.</li></ul><p><strong>Why it matters:</strong> Tech giants are <a href=\"https://www.deeplearning.ai/the-batch/google-and-microsoft-both-announce-ai-powered-search/?ref=dl-staging-website.ghost.io\">racing</a> to integrate large language models into search engines, email, document editing, and an increasing variety of other services. Serving customers may require taking losses in the short term, but winning in the market ultimately requires balancing costs against revenue.<br><br><strong>We’re thinking: </strong>Despite the high cost of using large language models to fulfill web searches — which Google, Bing, and Duckduckgo do for free, thus creating pressure to cut the cost per query — for developers looking to call them, the expense looks quite affordable. In our <a href=\"https://www.deeplearning.ai/the-batch/doing-business-with-chatbots/?ref=dl-staging-website.ghost.io\">back-of-the-envelope calculation</a>, the cost to generate enough text to keep someone busy for an hour is around $0.08.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--80-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--80-.gif 600w\"></figure><h1 id=\"diffusion-transformed\">Diffusion Transformed</h1><p>A tweak to diffusion models, which are responsible for most of the recent excitement about AI-generated images, enables them to produce more realistic output.</p><p><strong>What's new:</strong> William Peebles at UC Berkeley and Saining Xie at New York University improved a diffusion model by replacing a key component, a U-Net convolutional neural network, with a transformer. They call the work <a href=\"https://arxiv.org/abs/2212.09748?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">Diffusion Transformer (DiT)</a>.</p><p><strong>Diffusion basics: </strong>During training, a <a href=\"https://www.deeplearning.ai/short-courses/how-diffusion-models-work/?ref=dl-staging-website.ghost.io\">diffusion model</a> takes an image to which noise has been added, a descriptive embedding (typically an embedding of a text phrase that describes the original image, in this experiment, the image’s class), and an embedding of the current time step. The system learns to use the descriptive embedding to remove the noise in successive time steps. At inference, it generates an image by starting with pure noise and a descriptive embedding and removing noise iteratively according to that embedding. A variant known as a <a href=\"https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">latent diffusion model</a> saves computation by removing noise not from an image but from an image embedding that represents it.</p><p><strong>Key insight:</strong> In a typical diffusion model, a <a href=\"https://arxiv.org/abs/1505.04597?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">U-Net</a> convolutional neural network (CNN) learns to estimate the noise to be removed from an image. <a href=\"https://arxiv.org/abs/2010.11929?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">Recent</a> <a href=\"https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">work</a> showed that transformers outperform CNNs in many computer vision tasks. Replacing the CNN with a transformer can lead to similar gains.</p><p><strong>How it works:</strong> The authors modified a latent diffusion model (specifically <a href=\"https://stability.ai/blog/stable-diffusion-public-release?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">Stable Diffusion</a>) by putting a transformer at its core. They trained it on <a href=\"https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">ImageNet</a> in the usual manner for diffusion models.</p><ul><li>To accommodate the transformer, the system broke the noisy image embeddings into a series of tokens.</li><li>Within the transformer, modified transformer blocks learned to process the tokens to produce an estimate of the noise.</li><li>Before each attention and fully connected layer, the system multiplied the tokens by a separate vector based on the image class and time step embeddings. (A vanilla neural network, trained with the transformer, computed this vector.)</li></ul><p><strong>Results:</strong> The authors assessed the quality of DiT’s output according to <a href=\"https://arxiv.org/abs/1706.08500?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">Fréchet Inception Distance</a> (FID), which measures how the distribution of a generated version of an image compares to the distribution of the original (lower is better). FID improved depending on the processing budget: On 256-by-256-pixel ImageNet images, a small DiT with 6 gigaflops of compute achieved 68.4 FID, a large DiT with 80.7 gigaflops achieved 23.3 FID, and the largest DiT with 119 gigaflops achieved 9.62 FID. A <a href=\"https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Nb-a1BUHkAvW21WlcuyZuAvv0TS4IQoGggo5bTi1WwYUuEFH4RunaPClPpQPx7iBhn-BH\" rel=\"noopener\">latent diffusion model that used a U-Net</a> (104 gigaflops) achieved 10.56 FID.</p><p><strong>Why it matters: </strong>Given more processing power and data, transformers achieve better performance than other architectures in numerous tasks. This goes for the authors’ transformer-enhanced diffusion model as well.</p><p><strong>We're thinking:</strong> Transformers continue to replace CNNs for many tasks. We’ll see if this replacement sticks.</p><hr><h2 id=\"data-points\">Data Points</h2><p><strong>Arizona law school embraces ChatGPT</strong><br>The Sandra Day O’Connor College of Law at Arizona State University now permits prospective students to use generative AI tools to draft their applications, as long as the information they submit is truthful. While the policy is limited to applications, the law school is working on guidelines for using AI in coursework and classrooms. (<a href=\"https://www.reuters.com/legal/transactional/students-can-use-ai-applications-arizona-state-law-school-says-2023-07-28/?ref=dl-staging-website.ghost.io\"><em>Reuters</em></a>)<br><br><strong>Regulators probe investment firms over use of AI</strong><br>Massachusetts securities regulators sent letters of inquiry to investment firms including JPMorgan Chase and Morgan Stanley. The letters question the firms’ potential use of AI and its implications for investors. The state investigation comes in the wake of the U.S. Securities and Exchange Commission's recent proposal to mitigate conflicts of interest related to AI used in trading platforms. (<a href=\"https://www.reuters.com/technology/massachusetts-regulators-launch-probe-into-ai-securities-industry-2023-08-03/?ref=dl-staging-website.ghost.io\"><em>Reuters</em></a>)<br><br><strong>AI dominated second-quarter earnings calls</strong><br>Companies  featured AI prominently in their conference calls during the second-quarter earnings reporting season. Prominent tech companies mentioned AI over 50 times, and over one-third of S&amp;P 500 companies mentioned it at least once. (<a href=\"https://www.reuters.com/technology/companies-double-down-ai-june-quarter-analyst-calls-2023-07-31/?ref=dl-staging-website.ghost.io\"><em>Reuters</em></a>)<br><br><strong>Kickstarter implements AI transparency policy</strong><br>The crowdfunding platform, which raises money for projects like art and video games, now mandates that users seeking funds  provide details about how their projects use AI to ensure proper attribution of AI-generated work. (<a href=\"https://www.videogameschronicle.com/news/kickstarter-says-new-projects-will-have-to-disclose-whether-they-use-ai/?ref=dl-staging-website.ghost.io\"><em>Video Games Chronicle</em></a>)<br><br><strong>Adobe’s use of AI raises employee concerns</strong><br>The integration of AI tools like Firefly in Adobe’s products prompted internal debates about the role of AI in design and creativity. Some employees worry about potential job losses, while others emphasize the benefits for efficiency and productivity. (<a href=\"https://www.businessinsider.com/adobe-ai-firefly-kill-graphic-designer-jobs-cut-seat-sales-2023-7?IR=T&ref=dl-staging-website.ghost.io\"><em>Business Insider</em></a>)<br><br><strong>Google to revamp Google Assistant</strong><br>The division of Alphabet is working on an overhaul of its virtual assistant to add generative AI features. The move marks a shift away from earlier technology. (<a href=\"https://www.axios.com/2023/07/31/google-assistant-artificial-intelligence-news?ref=dl-staging-website.ghost.io\"><em>Axios</em></a>)<br><br><strong>YouTube to introduce automatic summaries</strong><br>The platform is experimenting with AI-generated video summaries and emphasizes that they are not intended to replace creators’ written video descriptions. Previous summarizer tools provided by third parties received mixed reviews. (<a href=\"https://techcrunch.com/2023/08/01/youtube-experiments-with-ai-auto-generated-video-summaries/?guccounter=1&ref=dl-staging-website.ghost.io\"><em>TechCrunch</em></a> and <a href=\"https://support.google.com/youtube/thread/18138167?ref=dl-staging-website.ghost.io\"><em>Google</em></a>)<br><br><strong>Aides reveal U.S. President Biden’s views on AI </strong><br>President Biden is navigating AI with a mix of fascination and caution, according to his aides and advisers. He's personally experimented with ChatGPT for various tasks including generating descriptions of legal cases for first-graders and crafting Bruce Springsteen-style lyrics about legal matters. (<a href=\"https://www.wsj.com/articles/wonder-and-worry-how-biden-views-artificial-intelligence-5724bfef?ref=dl-staging-website.ghost.io\"><em>The Wall Street Journal</em></a>)</p>","comment_id":"64d3ddfe133a7c00015884bb","feature_image":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--24--1.jpg","featured":false,"visibility":"public","created_at":"2023-08-09T11:42:06.000-07:00","updated_at":"2024-10-04T09:53:22.000-07:00","published_at":"2023-08-09T11:56:46.000-07:00","custom_excerpt":"The Batch - AI News & Insights: Do large language models understand the world? As a scientist and engineer, I’ve avoided asking whether an AI system “understands” anything. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"64d3e0e7133a7c0001588511","name":"issue-209","slug":"issue-209","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-209/"},{"id":"64d3e0e7133a7c0001588512","name":"Aug 09, 2023","slug":"aug-09-2023","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/aug-09-2023/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-209/","excerpt":"The Batch - AI News & Insights: Do large language models understand the world? As a scientist and engineer, I’ve avoided asking whether an AI system “understands” anything. ","reading_time":12,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Medical AI Advances, Chatbots Work the Drive-Thru, and more","meta_description":"The Batch - AI News & Insights: Do large language models understand the world? As a scientist and engineer, I’ve avoided asking whether an AI system...","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--24--1.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"Data Analytics Professional Certificate","databaseId":36316,"id":"cG9zdDozNjMxNg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2025/03/Vertical-side-banner-ads-7.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3XWMC3m","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}