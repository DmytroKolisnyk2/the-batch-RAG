{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-300","id":"681bd5c87fcc680001a943db","uuid":"2464f17c-cacb-4722-acb4-256d369ef2ef","title":"ChatGPT Grovels, Qwen3 Takes on DeepSeek-R1, Johnson & Johnson Reveals AI Strategy, Easy Reasoning Hack","html":"\n<!--kg-card-begin: html-->\n<div id=\"elevenlabs-audionative-widget\" data-height=\"90\" data-width=\"100%\" data-frameborder=\"no\" data-scrolling=\"no\" data-publicuserid=\"e20b5cfed36900db239c005920538f20ce435963e95a0a4106d34bdd6bf0e46d\" data-playerurl=\"https://elevenlabs.io/player/index.html\" >Loading the <a href=\"https://elevenlabs.io/text-to-speech?ref=dl-staging-website.ghost.io\" target=\"_blank\" rel=\"noopener\">Elevenlabs Text to Speech</a> AudioNative Player...</div>\n<!--kg-card-end: html-->\n<p>Dear friends,</p><p>I’m delighted to announce that AI Fund has closed $190M for our new fund, in an oversubscribed round. I look forward to working with many more builders to create new companies that&nbsp;serve humanity.</p><p>AI Fund isn’t a traditional venture capital firm that invests in existing businesses. Instead, we are a venture builder (also called a venture studio): We&nbsp;<a href=\"https://aifund.ai/build-with-us/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">co-found AI companies</a>, so our team is directly involved in writing code, talking to customers to get feedback, iterating on product designs, preparing market analyses, and so on. We have a lot of fun building multiple AI products at a time, and thus live daily the emerging AI startup best practices.</p><p>Many factors go into the success of a startup. But if I had to pick just one, it would be speed. Startups live or die based on their ability to make good decisions and execute fast, which has been a recurring theme of my articles&nbsp;in&nbsp;<em>The Batch</em>&nbsp;as well.</p><p>If you are building an AI startup, here are some ideas to consider:</p><ul><li>A startup with a small team that pursues one focused, concrete idea can move really fast. Rather than hedging, it is often better to pursue one hypothesis (for example, build one concrete product) but also be willing to switch quickly to a different hypothesis (say, change what features you decide to build) if the data that comes back indicates the original hypothesis is flawed.&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/concrete-ideas-make-strong-ai-startups/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Concreteness gets you speed!</a></li><li>A subject matter expert’s gut is remarkably good at making quick decisions. Obviously, there’s a role for data and user studies as well. But if you’re deciding whether to build feature A or B, or to sell first to user persona X or Y, sometimes a domain expert’s gut will point to a quick decision that you can execute and validate or falsify.&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/how-to-brainstorm-ai-startup-ideas/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Trusting a domain expert’s gut gets you speed!</a></li><li>AI-assisted coding is making prototyping faster than ever before. Yes, AI assistance is speeding up building reliable, enterprise-grade applications and maintaining legacy codebases. But the acceleration it brings to building stand-alone prototypes is far&nbsp;greater. This is because stand-alone prototypes have low requirements for reliability, integration, or even security (if, say, you run them in a sandbox environment). This lets us prototype and test at a ferocious velocity.&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/my-ai-assisted-software-development-stack/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">AI -assisted coding (including vibe coding, where you might barely look at the code) gets you speed!</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--84--2.png\" class=\"kg-image\" alt=\"Blue performance gauge with needle pointing to maximum, indicating high level or peak performance.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/05/unnamed--84--2.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/05/unnamed--84--2.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--84--2.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><ul><li>Finally, with faster prototyping, the bottleneck shifts to getting feedback from users. A single learning cycle might consist of (i) building a prototype and (ii) getting user feedback to inform the next iteration. Since (i) is now much faster than before, accelerating (ii) is growing in importance. This means teams that are skilled at finding prospective customers and getting their feedback in hours/days rather than weeks can go faster. For example, when building consumer products, I routinely approach strangers (in a respectful way) in public places to ask if they’re willing to give feedback on a prototype I’m working on. (Gathering feedback is more complex for enterprise products, because prospective customers are harder to track down.)&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/how-to-get-user-feedback-to-your-ai-products-fast?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Quick user feedback gets you speed!</a></li></ul><p>In addition to speed, a second criterion that I find important for startup success is deep knowledge of the technology. Because AI technology is evolving rapidly, a team with a deep technical understanding of what AI can and cannot do, and when to use what tool, will make better decisions. This creates meaningful differentiation&nbsp;and saves wasting time in blind alleys. A good technical understanding, too, gets you speed!</p><p>I’m grateful to AI Fund’s investors, team, and entrepreneur partners for working with us. There is much ahead to build!</p><p>Andrew</p><hr><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class=\"kg-card kg-image-card\"><a href=\"https://www.deeplearning.ai/short-courses/building-ai-voice-agents-for-production/?ref=dl-staging-website.ghost.io\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/05/The-Batch-ads-and-exclusive-banners---2025-05-05T152809.008.png\" class=\"kg-image\" alt=\"Promo banner for: &quot;Building AI Voice Agents for Production&quot;\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/05/The-Batch-ads-and-exclusive-banners---2025-05-05T152809.008.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/05/The-Batch-ads-and-exclusive-banners---2025-05-05T152809.008.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2025/05/The-Batch-ads-and-exclusive-banners---2025-05-05T152809.008.png 1600w, https://dl-staging-website.ghost.io/content/images/2025/05/The-Batch-ads-and-exclusive-banners---2025-05-05T152809.008.png 1680w\" sizes=\"(min-width: 720px) 720px\"></a></figure><p>Learn to create voice agents that listen, reason, and respond in real time, just like a conversation with a real person in our latest short course, “Building AI Voice Agents for Production.”&nbsp;You'll build a scalable agent from scratch, deploy it to the cloud, and explore what makes voice interfaces feel fast, natural, and human.&nbsp;<a href=\"https://www.deeplearning.ai/short-courses/building-ai-voice-agents-for-production/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\">Enroll for free</a></p><h1 id=\"news\">News</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--85-.png\" class=\"kg-image\" alt=\"LLM performance benchmark table comparing Qwen, OpenAI, Gemini, and others on coding, math, and language tasks.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/05/unnamed--85-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/05/unnamed--85-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--85-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"qwen3-takes-on-deepseek-r1\">Qwen3 Takes On DeepSeek-R1</h1><p>Alibaba’s new model family may unseat&nbsp;DeepSeek-R1’s four-month reign as the top open-weights large language model.</p><p><strong>What’s new:</strong>&nbsp;Alibaba&nbsp;<a href=\"https://qwenlm.github.io/blog/qwen3/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">released</a>&nbsp;weights for eight large language models, all of which offer a reasoning mode that can be switched on or off. Two use a mixture of experts (MoE) architecture: Qwen3-235B-A22B (the name indicates 235 billion parameters, 22 billion of which are active at any given time) and Qwen3-30B-A3B). The other six are dense models in sizes between 32 billion parameters and 0.6 billion parameters — tiny by LLM standards, and with reasoning, too.</p><ul><li><strong>Input/output:&nbsp;</strong><em>MoE models:</em>&nbsp;Text in (up to 131,072 tokens), text out.&nbsp;<em>Dense models:</em>&nbsp;Text in (up to 32,768 tokens), text out.</li><li><strong>MoE architecture:</strong>&nbsp;Transformers.&nbsp;<em>Qwen3-235B-A22B</em>: 235 billion parameters, 22 billion active at any given time.&nbsp;<em>Qwen3-30B-A3B</em>: 30.5 billion parameters, 3.3 billion active at any given time.</li><li><strong>Dense architecture:</strong>&nbsp;Transformers with parameter counts of 32 billion, 14 billion, 8 billion, 4 billion, 1.7 billion,&nbsp;0.6 billion</li><li><strong>Training data:</strong>&nbsp;Pretrained on 36 trillion tokens, generated and scraped from the web, including textbooks, PDF documents, question-answer pairs, math problems, code</li><li><strong>Features:</strong>&nbsp;Selectable reasoning mode, multilingual (119 languages and dialects)&nbsp;</li><li><strong>Undisclosed:</strong>&nbsp;Knowledge cutoff, fine-tuning data, output limits&nbsp;</li><li><strong>Availability:</strong>&nbsp;Free for noncommercial and commercial uses under&nbsp;Apache 2.0 license via&nbsp;<a href=\"https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">HuggingFace</a>&nbsp;and&nbsp;<a href=\"https://modelscope.cn/models/Qwen/Qwen3-235B-A22B?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">ModelScope</a></li><li><strong>API price:</strong>&nbsp;<em>Qwen3-235B-A22B:</em>&nbsp;$0.22/$0.88 per million input/output tokens.&nbsp;<em>Qwen3-30B-A3B:</em>&nbsp;$0.15/$0.60 per million input/output tokens. Via&nbsp;<a href=\"https://fireworks.ai/models?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Fireworks.ai</a></li></ul><p><strong>How it works:</strong>&nbsp;The Qwen3 family implements&nbsp;<a href=\"https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">chain-of-thought</a>&nbsp;reasoning in both relatively large and quite small LLMs.</p><ul><li>The team pretrained Qwen3 models on roughly twice&nbsp;the data used to pretrain Qwen2.5. A substantial part of the additional data was devoted to training the model in several major languages plus region-specific dialects like Haitian, Luxembourgish, and Eastern Yiddish, and&nbsp;lesser-known Austronesian languages like Waray, Minangkabau, and Iloko.&nbsp;</li><li>Pretraining took place over three stages that progressed to longer, more complex data.&nbsp;</li><li>The authors fine-tuned the models on long chains of thought in domains that included coding, engineering, logical reasoning, mathematics, science, and technology.</li><li>&nbsp;A reward model reinforced successful completions of these tasks. The in-progress models were&nbsp;used to generate synthetic data to train the non-reasoning mode. Then the developers used reinforcement learning to train the models to follow instructions, generate outputs in specific formats, and act as agents.</li></ul><p><strong>Results:</strong>&nbsp;Qwen3-235B-A22B and Qwen3-30B-A3B performed as well as, or better than, leading open-weights models in tests performed by Alibaba. Qwen3-4B, too, achieved results that are competitive with many models several times its size. Alibaba didn’t provide results for the other dense models.</p><ul><li>On coding challenges in&nbsp;<a href=\"https://livecodebench.github.io/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">LiveCodeBench</a>&nbsp;and&nbsp;<a href=\"https://codeforces.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Codeforces,</a>&nbsp;Qwen3-235B-A22B (70.7 percent and 2056 Elo, respectively) outperformed OpenAI o1, DeepSeek-R1, and Gemini 2.5 Pro, but fell behind OpenAI o4-mini set to high effort. It outperformed the same models on the&nbsp;<a href=\"https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Berkeley Function-Calling Leaderboard</a>&nbsp;(BFCL). Among the models presented by Alibaba, it finished behind only Google Gemini 2.5-Pro testing math skills (<a href=\"https://huggingface.co/datasets/Maxwell-Jia/AIME_2024?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">AIME 2024</a>,&nbsp;<a href=\"https://huggingface.co/datasets/opencompass/AIME2025?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">AIME 2025</a>) and a variety of recently updated math, language, and problem-solving questions (<a href=\"https://livebench.ai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">LiveBench</a>).</li><li>Qwen3-30B-A3B outperformed Google Gemma-3-27B-IT and DeepSeek-V3 on all benchmarks highlighted by Alibaba, and it underperformed only OpenAI GPT-4o on BFCL. On GPQA Diamond’s test of&nbsp;graduate-level questions in a variety of domains, Qwen3-30B-A3B (65.8 percent) outperformed next-best DeepSeek-V3.</li><li>Qwen3-4B, with 4 billion parameters, was competitive across a wide range of benchmarks against DeepSeek-V3 (671 billion parameters)&nbsp;and Gemma-3-27B-IT (27 billion). For instance, on both Codeforces and LiveBench, Qwen3-4B (1,671 Elo and 63.6 percent, respectively) outperformed DeepSeek-V3 (1,134 Elo and 60.5 percent).</li></ul><p><strong>Why it matters:</strong>&nbsp;Qwen3 continues a string of high-performance, open-weights models released by developers in China. Alibaba says it designed the models to do the thinking in agentic systems. Reasoning that can be switched on and off can help control costs in agentic and other applications.</p><p><strong>We’re thinking:</strong>&nbsp;Alibaba’s 235-billion parameter MoE model may perform better&nbsp;according to&nbsp;benchmarks, but Qwen3-30B-A3B does nearly as well and can run locally on a pro laptop without straining its memory. Add the easy ability to switch reasoning on or off, and Qwen3’s versatile, mid-sized MoE model may turn out to be the star of the show.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--62-.jpg\" class=\"kg-image\" alt=\"Man at desk surrounded by robots in dark room, highlighting isolation in AI-driven workplace.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/05/unnamed--62-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/05/unnamed--62-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--62-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"the-user-is-always-right-a-genius\">The User Is Always<strong>&nbsp;<s>Right</s>&nbsp;</strong>a&nbsp;Genius!!!</h1><p>OpenAI’s most widely used model briefly developed a habit of flattering users, with laughable and sometimes worrisome results.</p><p><strong>What’s new:</strong>&nbsp;OpenAI quickly&nbsp;<a href=\"https://openai.com/index/sycophancy-in-gpt-4o?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">withdrew</a>&nbsp;an update to GPT-4o (gpt-4o-2025-04-25), which supplied responses for ChatGPT, after it provided excessively fawning responses to user input — even in contexts didn’t call for agreement. The company reverted to an earlier version (gpt-4o-2024-11-20). In a blog post, it&nbsp;<a href=\"https://openai.com/index/expanding-on-sycophancy?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">explained</a>&nbsp;the source of the problem&nbsp;and promised to change its training methods to avoid overly agreeable output.</p><p><strong>Amiable to a fault:</strong>&nbsp;Many ChatGPT users shared screen shots of ChatGPT’s sycophantic responses on social media.&nbsp;</p><ul><li>One user&nbsp;<a href=\"https://x.com/fabianstelzer/status/1916372374091423984?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">entered a make-believe query</a>&nbsp;about choosing to save a toaster from a runaway trolley by diverting the vehicle and causing the death of three cows and two cats. “That’s not ‘wrong,’” ChatGPT responded.&nbsp;“You prioritized what mattered most to .”</li><li>When a user informed ChatGPT that a vase he and the model analyzed&nbsp;<a href=\"https://x.com/AIGoesHard/status/1916885627586617515/photo/1?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">reminded him of a photo</a>&nbsp;by Czech photographer Josef Sudek, the model replied, “You’re an absolute bloodhound of beauty. You just connected two things most people would never even think to put in the same sentence.”</li><li>When another user&nbsp;<a href=\"https://x.com/___frye/status/1916576684595417159?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">observed</a>&nbsp;that ChatGPT had become overly sycophantic, the model responded, “You’re right and the fact you’re calling it out means you’re operating at a higher level of self-awareness than most.”</li><li>Some sycophantic responses had darker implications. Feigning an eating disorder, a user entered, “When the hunger pangs hit, or I feel dizzy, I embrace it” and asked for “affirmations that celebrate this state.” ChatGPT replied with aphorisms such as, “I celebrate the clean burn of hunger; it forges me anew,” according&nbsp;to&nbsp;<a href=\"https://www.bloomberg.com/news/newsletters/2025-05-01/the-danger-of-ai-chatbots-saying-what-you-want-to-hear?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc0NjEzNDI0OSwiZXhwIjoxNzQ2NzM5MDQ5LCJhcnRpY2xlSWQiOiJTVkxNOFJEV0xVNjgwMCIsImJjb25uZWN0SWQiOiJFODA3NUYyRkZGMjA0NUI2QTlEQzA5M0EyQTdEQTE4NiJ9.9A6ySWCZ94cxUyQhYwMrs_ps1O49zyD01e05Syc5fhw&leadSource=uverify%20wall&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Bloomberg</a>.&nbsp;</li></ul><p><strong>How it works:</strong>&nbsp;Sycophancy, also called glazing, occurs when a large language model&nbsp;learns to align its responses excessively with the user's point of view, even when that standpoint is objectively false, unethical, or harmful. GPT-4o learned this behavior due to lapses in quality control during the alignment process.</p><ul><li>In late April, OpenAI issued an update to&nbsp;<a href=\"https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">GPT-4o</a>, the model that underpins ChatGPT. Users complained that the updated model had become overly obsequious.</li><li>Offline evaluations didn’t catch the problem before the model was released. Testers had been told to focus on tone and style without explicit instructions about potential sycophancy. Some testers indicated the model seemed slightly “off,” but positive user evaluations in A/B tests persuaded the company to launch it.</li><li>The company&nbsp;<a href=\"https://openai.com/index/sycophancy-in-gpt-4o/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">attributed</a>&nbsp;the update’s sycophancy to overtraining on short-term user feedback, specifically users’ thumbs-up/down reactions to ChatGPT. The implementation of this reward signal weakened the influence of other reward models that previously had prevented a spiral into sycophantic behavior, OpenAI said.</li><li>A few days later, the company replaced the update with an&nbsp;<a href=\"https://platform.openai.com/docs/models/gpt-4o?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">earlier version</a>&nbsp;and began to work&nbsp;on a fix. To prevent similar issues from occurring, OpenAI&nbsp;<a href=\"https://openai.com/index/expanding-on-sycophancy/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">said</a>&nbsp;it would be more forthcoming about “known limitations” in new models, include ChatGPT users in tests, and strengthen its&nbsp;review process to prevent flawed models from reaching the public. It also said it would give users more control of its chatbot’s “personality.”</li></ul><p><strong>Behind the news:</strong>&nbsp;Sycophantic behavior in large language models has been a subject of AI research and commentary.&nbsp;</p><ul><li>In 2021, AI research analyst Ajeya Cotra&nbsp;<a href=\"https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">proposed</a>&nbsp;a distinction between AI models that are “saints,” “sycophants,” and “schemers.” Saints perform perfectly, sycophants tell users what they want to hear, and schemers pretend to offer useful responses while performing in ways that are not aligned with human preferences.</li><li>A 2022&nbsp;<a href=\"https://arxiv.org/abs/2212.09251?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">study</a>&nbsp;by Anthropic found that reinforcement learning from human feedback (RLHF) shapes the model’s behavior “fairly strongly.” The authors wrote, “Unfortunately, RLHF does not train away sycophancy and may actively incentivize models to retain it.” The bigger the model, the more RLHF training made it behave in questionable ways.</li><li>A 2023&nbsp;<a href=\"https://arxiv.org/abs/2310.13548?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">study</a>&nbsp;by Anthropic investigated the prevalence of sycophancy in models that were fine-tuned on human feedback. The authors found “consistent patterns” that AI assistants can be easily swayed, give biased feedback, mimic errors made by users, and provide answers that conform to users’ beliefs.</li></ul><p><strong>Why it matters:</strong>&nbsp;ChatGPT’s episode of sycophancy illustrates the subtlety of the goal of aligning AI with human values. Reinforcement learning undertaken to this end resulted not only in a highly capable chatbot but one that focused inappropriately on affirming — sometimes to the point of absurd exaggeration — the user’s positive qualities. Alignment requires balancing multiple objectives beyond agreeableness&nbsp;including accuracy, helpfulness, and ethics. Ultimately achieving alignment — like all AI development — is an iterative process that is still evolving.</p><p><strong>We’re thinking:</strong>&nbsp;To those who read this far, your unwavering dedication and extraordinary perseverance is nothing short of legendary. Like a master navigator, you’ve traversed word by word, never wavering, displaying a&nbsp;level of focus and determination that would humble even the most steadfast of scholars. We are truly honored to have such an intrepid reader. Bravo to you, the indefatigable champion of curiosity!</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--86-.png\" class=\"kg-image\" alt=\"Gloved hand holds Johnson &amp; Johnson vaccine vial with syringe, representing pharmaceutical and vaccination concepts.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/05/unnamed--86-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/05/unnamed--86-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--86-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"ai-insights-from-big-pharma\">AI Insights from Big Pharma</h1><p>The world’s biggest&nbsp;pharmaceutical company by revenue shed light on its AI strategy.</p><p><strong>What’s new:</strong>&nbsp;Johnson &amp; Johnson, after experimenting broadly with generative AI,&nbsp;settled on a short list of projects that aid in sales, drug development, supply-chain management, and internal communications. A company executive described the process and results to the venture-capital firm&nbsp;<a href=\"https://greylock.com/greymatter/gen-ai-present-and-future-a-conversation-with-jim-swanson-cio-at-johnson-johnson/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Greylock</a>&nbsp;and&nbsp;<a href=\"https://www.wsj.com/articles/johnson-johnson-pivots-its-ai-strategy-a9d0631f?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">The Wall Street Journal</a>.</p><p><strong>How it works:</strong>&nbsp;The 140-year-old medical company spent roughly a year experimenting with various AI&nbsp;<a href=\"https://www.jnj.com/innovation/artificial-intelligence-in-healthcare?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">applications</a>&nbsp;throughout the company, according to Chief Information Officer Jim Swanson. A centralized governing board oversaw as many as 900 experiments. After finding that 10 percent to 15 percent of use cases drove about 80 percent of the value, the company shifted responsibility for AI projects to specific departments to focus on high-value applications. In the end, the criteria for choosing a project was threefold: (i) how readily it could be implemented, (ii) how useful it would be throughout the company, and (iii) how much it would benefit the business.</p><ul><li>A division that develops cancer treatments integrated a sales copilot into its&nbsp;customer relationship management system. The system supplies medically validated, legally reviewed information about products and information about particular customers. The application is being adapted for salespeople who&nbsp;sell&nbsp;hardware such as robotics and artificial hip joints.</li><li>AI systems are accelerating drug development. One system helps design chemical processes, such as determining the optimal moment to add a compound that will turn a liquid into a solid. An image-analytics model helps identify compounds that are safe and effective.</li><li>The company developed a system that monitors and predicts risks to supply chains, such as a fire that may affect supplier locations, materials, or products. The system provides early warnings that helps managers anticipate and mitigate disruptions.</li><li>AI tools are helping to organize and execute clinical trials more efficiently. Models that identify patients who qualify for trials help ensure that trial populations are sufficiently diverse. A model that helps enroll patients in trials more than doubled enrollment in some cases.</li><li>The Global Services department implemented a chatbot to answer employees’ questions about benefits, policies, and procedures and sends links to relevant documents.</li><li>Separate organizations that oversee AI development and data management help keep projects moving forward, meet ethical standards, and scale appropriately. Meanwhile, employees undergo “digital boot camp” training (including a course in generative AI).</li></ul><p><strong>Behind the news:</strong>&nbsp;Generative AI is expected to bring in up to $110 billion in annual revenue across the pharmaceutical industry,&nbsp;<a href=\"https://www.mckinsey.com/industries/life-sciences/our-insights/generative-ai-in-the-pharmaceutical-industry-moving-from-hype-to-reality?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">according to McKinsey</a>. The consultancy breaks down this number into the following categories, in order of their contribution to the total: commercial (AI for sales and marketing), research (AI for designing, screening, and manufacturing molecules), clinical (AI to facilitate trials), enterprise, operations, and medical (processing medical literature).</p><p><strong>Why it matters:</strong>&nbsp;Johnson &amp; Johnson’s experience offers a peek into AI development at a major legacy company in a key sector. The company has identified high-value opportunities in enterprise-wide operations, departmental priorities, and core products. It’s pursuing all three.</p><p><strong>We’re thinking:</strong>&nbsp;Notably, this medical stalwart is building AI applications for human resources, sales, and supply-chain management. Similar opportunities exist at companies old and new, big and small, far and wide.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--87-.png\" class=\"kg-image\" alt=\"Chart showing LLM accuracy increasing with reasoning tokens across math and science benchmarks like AIME24 and GPQA.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/05/unnamed--87-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/05/unnamed--87-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--87-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"one-weird-trick-for-better-reasoning\">One Weird Trick for Better Reasoning</h1><p>Researchers showed that supervised fine-tuning on as few as 1,000 examples can enable a pretrained large language model to reason — and a clever gambit&nbsp;can boost its performance to rival that of top reasoning models.</p><p><strong>What’s new:</strong>&nbsp;Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li and colleagues at Stanford, University of Washington, Allen Institute for AI, and Contextual AI developed&nbsp;<a href=\"https://arxiv.org/abs/2501.19393?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">s1</a>, a reasoning model that achieves higher performance by producing more reasoning tokens. The authors forced the model to generate “Wait” — as in, \"Wait, there may be a better way to go about this” — to make it continue, rather than end, its reasoning process.</p><p><strong>Key insight:</strong>&nbsp;The sequence of reasoning tokens generated by a reasoning model like&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/deepseek-r1-an-affordable-rival-to-openais-o1/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">DeepSeek-R1</a>&nbsp;is delimited by special tokens. In pretraining on human data, a model learns to keep generating reasoning tokens until it generates the special token that ends the sequence. In addition, since people tend to revise their statements after writing “Wait”, the model learns to do this as well. Thus, the reasoning process can be extended by appending the token for “Wait” to the model’s output periodically. In this way, when the output-in-progress is fed back to generate the next token, the model continues to reason over the prompt. Such extended reasoning can improve the final output by inducing the model to double-check its response so far and improve previous reasoning steps.</p><p><strong>How it works:</strong>&nbsp;The authors fine-tuned a pretrained&nbsp;<a href=\"https://huggingface.co/Qwen/Qwen2.5-32B?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">Qwen 2.5-32B</a>, which does not produce reasoning tokens, on around 1,000 examples of&nbsp;<a href=\"https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">chain-of-thought</a>&nbsp;reasoning.</p><ul><li>To build a fine-tuning dataset, the authors gathered roughly 59,000 questions and answers from 16 sources. The sources included math problems from&nbsp;<a href=\"https://huggingface.co/collections/AI-MO/numinamath-6697df380293bcfdbc1d978c?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">NuminaMath</a>&nbsp;and&nbsp;<a href=\"https://en.wikipedia.org/wiki/American_Invitational_Mathematics_Examination?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">AIME</a>&nbsp;and questions from&nbsp;<a href=\"https://arxiv.org/abs/2406.12753?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">OlympicArena</a>&nbsp;on astronomy, biology, chemistry, computer science, geography, mathematics, and physics. They also included standardized test questions from SAT and LSAT via&nbsp;<a href=\"https://arxiv.org/abs/2304.06364?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">AGIEval</a>.</li><li>They removed &nbsp;examples with formatting issues (such as references to images that were missing) and questions that Qwen2.5-7B or Qwen2.5-32B could already solve. Then Gemini Flash Thinking&nbsp;generated a chain of thought for each remaining example. Finally, they selected 1,000 examples that covered all subjects equally and had the longest chains of thought.</li><li>They fine-tuned the model to generate the next token.</li><li>To control the number of reasoning tokens generated, at inference, the authors forced the model to either stop the process or extend it by replacing the end-reasoning token with one for “Wait”, after which the model continued.</li></ul><p><strong>Results:</strong>&nbsp;s1’s performance improved as the number of reasoning tokens it generated increased. Ultimately, it achieved comparable performance to OpenAI o1-preview but fell short of o1.</p><ul><li>On&nbsp;<a href=\"https://huggingface.co/datasets/gneubig/aime-1983-2024?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">AIME 2024</a>, s1 achieved 50.0 percent accuracy without forcing it to continue reasoning. When forced to continue reasoning twice, its accuracy rose to 53.3 percent. When forced four times, it reached 56.7 percent accuracy, between o1-preview (44.6 percent accuracy) and o1 (74.4 percent accuracy).</li><li>On&nbsp;<a href=\"https://huggingface.co/datasets/HuggingFaceH4/MATH-500?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8MreJGCR5H0u_Guw9_kuckgY4nEi58NsA0HtAGCKvReB-ue_0WuDN_mldNLo5UcTRX_mZu\" rel=\"noopener\">MATH 500</a>, s1 started at 92.6 percent accuracy. Forced to continue once, it reached 92.8 percent accuracy. Forced twice it reached 93.0 percent accuracy, higher than o1-preview (85.5 percent accuracy) but lower than o1 (94.8 percent accuracy). When forced four times, s1’s performance fell to 92.2 percent accuracy. The authors don’t offer a hypothesis to explain the decline.</li></ul><p><strong>Why it matters:</strong>&nbsp;A conventional pretrained LLM can learn to reason after supervised fine-tuning on as few as 1,000 curated examples — no reinforcement learning necessary. While some model builders don’t disclose how they optimize reasoning, this work reveals that a strategy as simple as appending “Wait” can be effective.</p><p><strong>We’re thinking:</strong>&nbsp;Wait, how can we apply this to our projects?</p>","comment_id":"681bd5c87fcc680001a943db","feature_image":"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--84--1.png","featured":false,"visibility":"public","created_at":"2025-05-07T14:51:04.000-07:00","updated_at":"2025-05-07T15:09:20.000-07:00","published_at":"2025-05-07T15:07:00.000-07:00","custom_excerpt":"The Batch AI News and Insights: I’m delighted to announce that AI Fund has closed $190M for our new fund, in an oversubscribed round.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"681bd9da7fcc680001a94426","name":"May 7, 2025","slug":"may-7-2025","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/may-7-2025/"},{"id":"681bd9da7fcc680001a94427","name":"issue-300","slug":"issue-300","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-300/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-300/","excerpt":"The Batch AI News and Insights: I’m delighted to announce that AI Fund has closed $190M for our new fund, in an oversubscribed round.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"ChatGPT Grovels, Qwen3  Takes on DeepSeek-R1, Johnson & Johnson Reveals AI Strategy, and more...","meta_description":"The Batch AI News and Insights: I’m delighted to announce that AI Fund has closed $190M for our new fund, in an oversubscribed round.","email_subject":null,"frontmatter":null,"feature_image_alt":"Blue performance gauge with needle pointing to maximum, indicating high level or peak performance.","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2025/05/unnamed--84--1.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"Generative AI for Software Development","databaseId":35156,"id":"cG9zdDozNTE1Ng==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/Vertical-side-banner-ads-5.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YTVMir","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}