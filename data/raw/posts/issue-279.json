{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-279","id":"6759f81f58d8b10001af9b7b","uuid":"1e5f3304-e695-4b3c-87c2-ee297c2bd353","title":"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs","html":"\n<!--kg-card-begin: html-->\n<div id=\"elevenlabs-audionative-widget\" data-height=\"90\" data-width=\"100%\" data-frameborder=\"no\" data-scrolling=\"no\" data-publicuserid=\"e20b5cfed36900db239c005920538f20ce435963e95a0a4106d34bdd6bf0e46d\" data-playerurl=\"https://elevenlabs.io/player/index.html\" >Loading the <a href=\"https://elevenlabs.io/text-to-speech?ref=dl-staging-website.ghost.io\" target=\"_blank\" rel=\"noopener\">Elevenlabs Text to Speech</a> AudioNative Player...</div><script src=\"https://elevenlabs.io/player/audioNativeHelper.js\" type=\"text/javascript\"></script>\n<!--kg-card-end: html-->\n<p>Dear friends,</p><p>AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications. This is making it possible to build new kinds of things, which in turn is driving shifts in best practices in product management — the discipline of defining what to build to serve users — because what is possible to build has shifted. In this letter, I’ll share some best practices I have noticed.</p><p><strong>Use concrete examples to specify AI products.</strong>&nbsp;Starting with a&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/concrete-ideas-make-strong-ai-startups/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--Eqm_4XfMsvT6wPKNDMd230B1utOFB2bNF_Fwr6VDghY4piRLWWELt22IvV9osotn89tB_\" rel=\"noopener\">concrete idea</a>&nbsp;helps teams gain speed. If a product manager (PM) proposes to build “a chatbot to answer banking inquiries that relate to user accounts,” this is a vague specification that leaves much to the imagination. For instance, should the chatbot answer questions only about account balances or also about interest rates, processes for initiating a wire transfer, and so on? But if the PM writes out a number (say, between 10 and 50) of concrete examples of conversations they’d like a chatbot to execute, the scope of their proposal becomes much clearer. Just as a machine learning algorithm needs training examples to learn from, an AI product development team needs concrete examples of what we want an AI system to do. In other words, the data is your PRD (product requirements document)!</p><p>In a similar vein, if someone requests “a vision system to detect pedestrians outside our store,” it’s hard for a developer to understand the boundary conditions. Is the system expected to work at night? What is the range of permissible camera angles? Is it expected to detect pedestrians who appear in the image even though they’re 100m away? But if the PM collects a handful of pictures and annotates them with the desired output, the meaning of “detect pedestrians” becomes concrete. An engineer can assess if the specification is technically feasible and if so, build toward it. Initially, the data might be obtained via a one-off, scrappy process, such as the PM walking around taking pictures and annotating them. Eventually, the data mix will shift to real-word data collected by a system running in production.</p><p>Using examples (such as inputs and desired outputs) to specify a product has been helpful for many years, but the explosion of possible AI applications is creating a need for more product managers to learn this practice.</p><p><strong>Assess technical feasibility of LLM-based applications by prompting.</strong>&nbsp;When a PM scopes out a potential AI application, whether the application can actually be built — that is, its technical feasibility — is a key criterion in deciding what to do next. For many ideas for LLM-based applications, it’s increasingly possible for a PM, who might not be a software engineer, to try prompting — or write just small amounts of code — to get an initial sense of feasibility.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.jpg\" class=\"kg-image\" alt=\"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--38-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--38-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>For example, a PM may envision a new internal tool for routing emails from customers to the right department (such as customer service, sales, etc.). They can prompt an LLM to see if they can get it to select the right department based on an input email, and see if they can achieve high accuracy. If so, this gives engineering a great starting point from which to implement the tool. If not, the PM can falsify the idea themselves and perhaps improve the product idea much faster than if they had to rely on an engineer to build a prototype.</p><p>Often, testing feasibility requires a little more than prompting. For example, perhaps the LLM-based email system needs basic RAG capability to help it make decisions. Fortunately, the barrier to writing small amounts of code is now quite low, since AI can help by acting as a coding companion, as I describe in the course, “<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3lYW366bW34PBtQRW6Wkd-k7PwcdwW14_2YN81Tn-yW5t7CqF3SNF94VWKqBH5rby5QW64ct3m6yR4VZW18BSTt9jQmJKW6-_6J77-R-2rW5kQBLL8b78lFW2P4_QF4GHgYXW29wFH-7hgGRDW3wyzhL3p6GkzW66bcJP2LjtMYW424vZP4HzRhpW6jP8fY14mB7mW31BVsj6XJqNgW17mrQ510wZC4W1Vk4Vg15WDD0N30kx6Z1zKs0N87bJ3Qyn97MVxkGq44XLlD8N6k64JcgfB0_W2BLkrS2rpvqfW4-Lbdm4KBP-VW6vY4b-5xQSxMW22xtDG1ghL_4f96h33b04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">AI Python for Beginners</a>.” This means that PMs can do much more technical feasibility testing, at least at a basic level, than was possible before.</p><p><strong>Prototype and test without engineers.</strong>&nbsp;User feedback to initial prototypes is also instrumental to shaping products. Fortunately, barriers to building prototypes rapidly are falling, and PMs themselves can move prototypes forward without needing software developers.</p><p>In addition to using LLMs to help write code for prototyping, tools like Replit, Vercel’s V0, Bolt, and Anthropic’s Artifacts (I’m a fan of all of these!) are making it easier for people without a coding background to build and experiment with simple prototypes. These tools are increasingly accessible to non-technical users, though I find that those who understand basic coding are able to use them much more effectively, so it’s still important to learn basic coding. (Interestingly, highly technical, experienced developers use them too!) Many members of my teams routinely use such tools to prototype, get user feedback, and iterate quickly.</p><p>AI is enabling a lot of new applications to be built, creating massive growth in demand for AI product managers who know how to scope out and help drive progress in building these products. AI product management existed before the rise of generative AI, but the increasing ease of building applications is creating greater demand for AI applications, and thus a lot of PMs are learning AI and these emerging best practices for building AI products. I find this discipline fascinating, and will keep on sharing best practices as they grow and evolve.</p><p>Keep learning!</p><p>Andrew</p><hr><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class=\"kg-card kg-image-card\"><a href=\"https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/?ref=dl-staging-website.ghost.io\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png\" class=\"kg-image\" alt=\"Promo banner for &quot;Collaborative Writing and Coding with OpenAI Canvas&quot;\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1680w\" sizes=\"(min-width: 720px) 720px\"></a></figure><p>Write and code more effectively with OpenAI Canvas, a user-friendly workspace for collaborating with AI. In this free course, explore use cases like building game apps and designing SQL databases from screenshots, and gain insights into how GPT-4o powers Canvas’ features.&nbsp;<a href=\"https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\">Join for free</a></p><h1 id=\"news\">News</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--36-.gif\" class=\"kg-image\" alt=\"Berkeley Function Calling Leaderboard with metrics like accuracy, latency, and relevance.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--36-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--36-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--36-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"competitive-performance-competitive-prices\">Competitive Performance, Competitive Prices</h1><p>Amazon introduced a range of models that confront competitors head-on.</p><p><strong>What’s new:</strong>&nbsp;The&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdv5nR32W5BWr2F6lZ3pHW98tKVM9h8gZfW63HtBL8N30bJW25KwPF6lQ7T4W3jFfzj6wrp79W6Mp8MD5HX5bWVZHrpq8jD1mrN3Rt4CwtC8NgW27cjdP58q1YxW2YW6g03MmPv0W6T3J052zSYtsN3G872BFR4fPN1YfKLDvkcsvW6h9ZqT1Bvs3xN860NNtMdRPhW4cBR4d5sV7l6W6KwXB95pYmNqW4h5h745zT4X5W2PqfgN5zy8JTW45GzZ-2XKrqdW3qg8Z_3MKfCcW2_5FrD2HPYvzW2_ntTR20cwNXW8yNwWF353pVWTMznl8Z9758W6R4vzp1s4pd6W4HmnMG3y33T7VpjHFG79npRpW3H77Kn7pq71CVC3P7Z8gBmGqW6CrXWj5m_q1bW1LgP712qTXjrW64Z_ZB6x9LvFW8gqyb28g-pW3W6kXMcH4dTvS6f6KwPzx04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Nova</a>&nbsp;line from Amazon includes three vision-language models (Nova Premier, Nova Pro, and Nova Lite), one language model (Nova Micro), an image generator (Nova Canvas), and a video generator (Nova Reel). All but Nova Premier are&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lrW3lhZCM3nYVfSMhhFSLNYz8qW2GkrGV1M1pX8W43R0cx6BQC8RW3rN35587H06_W5fmw7C8TZYnfW2n0QXP552JlhN6rwqhhjckQLW94xH2k6FMbNLW8Td11D7T5jYkW1Qxc_t3D9d2HN42dW9RRhyRlN7Czn9hlwtXjW7GRb2825c4-VW38mHDz4rgSsjW4JsPys8dgry3W7jtMrY2nGSZQW12gqgC755sXBW2N-kvF1NwNl6W1D1B742c7mYwW7JgfGx6fLN-sN3RbsMCDh3x4VMHxbP6M9SRtN1SjvbybhpG9f3P8Rtb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">available</a>&nbsp;on Amazon’s Bedrock platform, and Nova Premier, which is the most capable, is expected in early 2025. In addition, Amazon plans to release a speech-to-speech model in early 2025 and a multimodal model that processes text, images, video, and audio by mid-year. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)</p><p><strong>How it works:</strong>&nbsp;Nova models deliver competitive&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3mbW4fdCNV65QDb8W5HL_y_93s5dgVjHRx355q56yW1Z65TH8cczlpVR9Svw61KqCsW3YXMvT2wyH9sW8CvMp14WzQVmW39p7Qx2cYVssW4DpMRv8ylrn-W8sYkWM6DhPg5VKn88N55w45sW65lBBF6HzlrJW7RbC_V2w_W7qW60B_Pw82xBYQN8W1Mmv3pGr5W3jG25F4KbRJ5W54FKxt7nxK8JW4zv0wb98WwD2W8Rz2DZ2Kw6TvW5b4sRx8vxLbXW7JCft34zsW_WW2ZV83v61qhzkW8NkfyG4NF0BgW2Jh6-C94KH7VW9hf5zg7TH11hN9h8Jm0klZJ4W6YgNjD333K55W5jfb_M2j22sjW8LCn2t4gxNR8W8VBHJF3G4tncW4Dn1r98-3scXVGKPKd6MKdWMf3Qqywv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">performance</a>&nbsp;at relatively low prices. Amazon hasn’t disclosed parameter counts or details about how the models were built except to say that Nova Pro, Lite, and Micro were trained on a combination of proprietary, licensed, public, and open-source text, images, and video in over 200 languages.</p><ul><li><strong>Nova Pro</strong>&nbsp;is roughly comparable to that of Anthropic Claude 3.5 Sonnet, OpenAI GPT-4o, and Google Gemini Pro. It has a 300,000-token input context window, enabling it to process relatively large vision-language inputs. Nova Pro outperforms its primary competitors in tests of following complex instructions (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pkV-H8v67JsKKSW13QMcP4pTG_lN4K1bd8YGrN5W8t6rDX4YxZVWW7HGMPL287yGvW4Myqvt975HF9N4PVzqL1rKXSW2k0Fjf4dWPRSW7YyZkN7sNylLW4m1KTq6GTNVrW2swtX26ws_KVV26LBl969WdKW4tHthy6nh3ffW5lSsfW1DbGCFW6WLG3M4VNknjW5L_Q168gs_NwW5PnGpq8n1GFnW280ZnV47nQPVVRVD1N61RmYhW56rWC729h81QW72PJDc158Q2LW1njr6h7dtZ2Mf1GD1JK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">IFEval),<u>&nbsp;</u></a>summarizing long texts (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nkW5-072n8Bk1W7W7K0KyX1yRN49V_SZcN5GCHgTW7j7vQ_9gqhpRVJFfzQ2kv03WW8__MPc3Bjm4wW3QVRgb2sWcP6T4qV-8jy46kN6nj4gs1pLR2W4Vxlsj8gPqVBW8hMwj59gRFkqN8Zk4pDZyw_nW3Lm_kK3pTn8KN2Q3ZNvtSjzJW5Dt3rH45P4g_W3dcYW08DMt-TW2Pb_nT35PLzhW6YLJ-x89Ph1jW8rT2K-2ln9HzW126L4c2_CDrFW6j--BX9jX5ZdW2HLktw61t4Jnf4TcljW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">SQuALITY</a>), understanding videos (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pKVXYbPZ4zrbTXW7jWy_72BlXnNVfrdW53VB2XYMRScsQTGD7vW5Q4Dch5Y5QKyLkSlxLNqkGW1mcxF24vRPrwW2fV0LK86VB9TW5mpnws5xt0cQW2DRL0_2hLFCJW4Zw-d22HC2ScW5c_5Y24LHwvpW4_BQP86YP7v8W2wtF3N7gF2zpW2gnv3H8_L70pW66lw6v7rWLSwW55-K2T8-jpJcN5F66P2mpscjW2vBTDQ4hKFlfW5PWYvh4ByjR9W8QkKXQ4nqvCLW6dhzG16L1Qmwf4_Q_2804?ref=dl-staging-website.ghost.io\" rel=\"noopener\">LVBench</a>), and reading and acting on websites (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3lwW345VXL8MyLkRN1g_w89_HJZXW5PsGL05y27KtW5LvgQ_57PRlMW4gp8sg5FYNDcW1wrvJ64Zl4-NW36bvqb21jNyhW5LBK704RN8ylW9bbm1t6qRjr8W6t7wBH6fgFdbW2b6HQg6cqbpwW8B8nBZ3C8z0MW7XjT5p28-nfxW89hLWS5nndsFW8RJ0ZS3KZ290W7NDVXn3SLqGLN6LmrQDzSMzYW6vqlJM7zcWY3W15dx__4kSRb8Vm_nXn4zlLV6W93q0-R3BptmjW6GGvVt2-LHt_f3jKTFR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">MM-Mind2Web</a>). It processes 95 tokens per second. At $0.80/$3.20 per million tokens of input/output, it’s significantly less expensive than GPT-4o ($2.50/$10) and Claude 3.5 Sonnet ($3/$15) but slower than GPT-4o (115 tokens per second).</li><li><strong>Nova Lite</strong>&nbsp;compares favorably with Anthropic Claude Haiku, Google Gemini 1.5 Flash, and OpenAI GPT-4o Mini. Optimized for processing speed and efficiency, it too has a 300,000 token input context window. Nova Lite bests Claude 3.5 Sonnet and GPT-4o on VisualWebBench, which tests visual understanding of web pages. It also beats Claude 3.5 Haiku, GPT-4o Mini, and Gemini 1.5 Flash in multimodal agentic tasks that include MM-Mind2Web and the&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mMW3dwXYh7BJvWJW8Gv1mv65RNgdW9bBGXc40Bgy9W3bcnPn3lyknbN7Jw3QM_1JtmW257XTK5wWnJ2W2fFdNF6gZszPW8zvTPJ3-LYbxN8d9txFR-M02VkR84C3xQ5VRW1XBGmZ6LjnQPW1DC3061YvPqbW7BWfGf4t205ZVWfhZW3z2jdVW6FRVqW1Hw3DKW7-p-Qx7D8hWrW84jwLV8fl27KW425Mc-3bckJWN1XV80tGRKV0W8cYqbf5pCdt2W5d0D_63LJSNCW4QslLJ8wDN4cW5X-B1Z2XX_7BW6q5Hf23Hy663f59H93b04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Berkeley Function-Calling Leaderboard</a>. It processes 157 tokens per second and costs $0.06/$0.24 per million tokens of input/output, making it less expensive than GPT-4o mini ($0.15/$0.60), Claude 3.5 Haiku ($0.80/$4), or Gemini 1.5 Flash ($0.075/$0.30), but slower than Gemini 1.5 Flash (189 tokens per second).</li><li><strong>Nova Micro</strong>&nbsp;is a text-only model with a 128,000-token context window. It exceeds Llama 3.1 8B and Gemini Flash 8B on all 12 tests reported by Amazon, including generating code (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3ldVflFLk1NPY3XW4mPwdx6NCqkyW74c6qD2mxfkrW5BMyFg1_tpzbW20s7hp6bp3h5W5k66JP963pRrW7MK76V3R-YKpW7FXwQ-2f6BbDN7x58qw1ZcMtW6nd0361Rd0HwN3Lz9tz1K-FjW7xZ8pq9dynhKW8ddtMk2_wRpCN5RC7Jy7KsWsVCPRG817yRPvW4WtXlB7G21L9W4Jn40k7f1N4MW7K7qSM5QS7lqW2gm4MF6d36PjW2xhsmY16-nLFW14Ybt58F8hTCVxVC7S64NYWZf58X8Jv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">HumanEval</a>) and reading financial documents (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mvW2KVkSl5ymqVYW4nxtFQ6MjXL5W8Czg8S8X8dD2W7HxxkX8ZKk7pW917rt441WVMvW1VmDdM2nwzB7N2XQTZnvcnKNW12Sp5G6ZTpnVN6MRMvShJpZpW6FbhcN3jQhZrW6QQFyq41Dcz_W6dkTrT81kxp7W2Sfpg_9cRCtjW5n2slT3Q5rQxW6VlfXF8r_BVNW3pwqYY8pZ0snW2FvvH228NGB8W29tfJx72wHJnW10BJYg8ctpnpW93THB07kZ37HW4GWBqB4Pvgz-VFDSKY7PBqCzN31Qbv439mTKW4770WS8YzSmmf1SRf7F04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">FinQA</a>). It also beats the smaller Claude, Gemini, and Llama models on retrieval-augmented generation tasks (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mXW4xJ09l3bnxsSW8TnTQZ6RWHRrW22rH-Q8BG-wJW28KM2D1mxv1NW1gT71N8j4GW_W3hxkQH4WVm0VW28G-QQ7F94GjW9dZsJ94hpvCzN6vTPcGdlhcgV5JXqP8fklp9W7DxTqS1_-tn_N64Qt_VFl2TsW6DJ0cK5g4K9xN3Nn5D3N68GnW218SQd1-T2XpW2QFGzW2QxqQ9W76CwLJ2MbpxfW1QXf_p82ftNTW7HZ4jy4M0vYkW6f-xRz2sH2brW7L2h2H2ZKBhmVKKVTG8r5knBf2JB3TM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">CRAG</a>). It processes 210 tokens per second (the lowest latency among Nova models) and costs $0.035/$0.14 per million input/output tokens. That’s cheaper than Gemini Flash 8B ($0.0375/$0.15) and Llama 3.1 8B ($0.10/$0.10), but slower than Gemini Flash 8B (284.2 tokens per second).</li><li><strong>Nova Canvas</strong>&nbsp;accepts English-language text prompts up to 1,024 characters and produces images up to 4.2 megapixels in any aspect ratio. It also performs inpainting, outpainting, and background removal. It excels on&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nGVszv227VyXVWW4pPCjM54hs7tW4X_0tg2xMsbBW1y3Jdk1c8-P2W3MF6PZ8cCb4FW7k7ZRm7n0J_JW8qHQ3N4l19dHW62N7Y563M5wpW8hCS_f77KY1QW5mGNx16CV2pkMRMYRwZ-n7nW1bXC1z8-YlLLW5w4J-N5vGMmlW2MKLhl5W-KDCVjT2PT24NkscW3QBVX97XR_W7W7hBzLl3lBydLW1TY0Jn3h7gcxW2ktfLY6p_lChW58xcJG5p7D5yW5LQTyp3NtzgkV1hhCT67TqJsf7snPMM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">ImageReward</a>, a measure of human preference for generated images, surpassing OpenAI DALL·E 3 and Stability AI Stable Diffusion 3.5. Nova Canvas costs between $0.04 per image up to 1024x1024 pixels and $0.08 per image up to 2,048x2,048 pixels. Prices are hard to compare because many competitors charge by the month or year, but this is less expensive and higher-resolution than DALL·E 3 ($0.04 to $0.12 per image).</li><li><strong>Nova Reel</strong>&nbsp;accepts English-language prompts up to 512 characters and image prompts up to 720x1,280 pixels. It generates video clips of 720x1280 pixels up to six seconds long. It demonstrates superior ability to maintain consistent imagery from frame to frame, winning 67 percent of head-to-head comparisons with the next highest-scoring model, Runway Gen-3 Alpha. Nova Reel costs $0.08 per second of output, which is less expensive than Runway Gen-3 Alpha ($0.096 per second) and Kling 1.5 ($0.12 per second) in their standard monthly plans.</li></ul><p><strong>Behind the news:</strong>&nbsp;The company launched Bedrock in April 2023 with Stability AI’s Stable Diffusion for image generation, Anthropic’s Claude and AI21’s Jurassic-2 for text generation, and its own Titan models for text generation and embeddings. Not long afterward, it added language models from Cohere as well as services for agentic applications and medical applications. It plans to continue to provide models from other companies (including Anthropic), offering a range of choices.</p><p><strong>Why it matters:</strong>&nbsp;While other AI giants raced to outdo one another in models for text and multimodal processing, Amazon was relatively quiet. With Nova, it has staked out a strong position in those areas, as well as the startup-dominated domains of image and video generation. Moreover, it’s strengthening its cloud AI offerings with competitive performance, pricing, and speed. Nova’s pricing continues the rapid&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3pFW3w_PdM2bXK6PW4cD-QZ9lXRMdW3kClgp6xr2Y8VzytDn4fqgPtW8W64QB6pzNmJW8R_HdF6x_6RyW51nLBX4d-BRWW4fzrqj4rHcLNW4M2dv-5XrG_GW83N2DQ5GrZBGTMLbZ1TPpXhW2vZMkl8sMWZyW3MY8bf3slGjJW6GJlXF1hMDFzW5gDzPB9fTlctVY9MSn5jz7h1W2rrvzL7n8NbNW3T_TsK8g93MxN57-lg6JB53BN4Tn-T1NLKlDVVhDXZ5NnX9lW8j5d0R1BZwG4W6W4dgc6MmWR_W5NBHYf3fpn1QW3NvlVc97SWDXN7DHFVB4zsM8W268LPQ8jvjcxW3jNsmm2yYd8dW2hC19c2fgYdBVwyC8x4fsvT5f5fF42H04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">drop in AI prices</a>&nbsp;over the last year. Falling per-token prices help make AI agents or applications that process large inputs more practical. For example, Simon Willison, developer of the Django Python framework for web applications,&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mQW8h-Z_M8klLp6W2Y92m295v2GJW6hKPQP7QmtfbW4wHzPH6W7Z78W237d-F2nrY5gW88F8_v8Lg5wRW8WTcvZ9d1lq0W7bctcV32z483VKj1pY85cKh9W7P5Tf-4vnNZGN4sb4vf4dMy8W53vKM-1PNDkGW4zdsPz7q9QRFW66zZqQ898hh3W8C_FDR2JLTTtW43s80B2j8FXQW2WryXc3zqdg_W48JlL-6bfwFzW8g2fy06CvKsyW7t6NBW6MxY7LW7yFfrT8xBPmbW6V9V0k9hzdjkW2cm5254hG4_YN4Zs2XhkSl10f46fbJY04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">found</a>&nbsp;that Nova Lite generated descriptions for his photo library (tens of thousands of images) for less than $10.</p><p><strong>We’re thinking:</strong>&nbsp;The Nova suite is available via APIs as well as two web playgrounds (one in the Bedrock console, the other a new interface for building AI apps called <a href=\"https://www.linkedin.com/posts/mattgarman_at-reinvent-last-week-we-unveiled-amazon-activity-7272331800822095874-MKlY/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\">PartyRock</a>). This accords with Amazon Web Services’ focus on developers. For consumers, Amazon offers the earlier&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3myW2ry85N76RHr7W6jZH0k6KDnwkW4Kfb9z37hKCHW45qSc63Mn9L8W6bYkbT8zTySTV4YQs474j2rQW2zQlKP5jB4PRW6k1N6B8RPcRjVvJzQH8rRrgwW5CVK2X1GPhF5W9hWqFj465hRXW413c938n3CrGW8_ydV47Vgm0bW9d7NQd6MJ8CHW4356pt5SCSWtW4Jsr5999Bl-cW7DMQ0M6nL8M0W8R3n646rtW4dW1v2-YW85tbvYW4yxDbP1srlTyW5TtxjM7dpgLtW20VNQ13pTlHGW6BcQ-y4jRBXLW8x4JMx7mZQPyW1WdCNV1LZtg2W6bkhtd12s4BNf6m3vDP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Rufus</a>&nbsp;shopping bot; for enterprises, the <a href=\"https://aws.amazon.com/q/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\">Q</a> assistant. </p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--30-.png\" class=\"kg-image\" alt=\"o1 Family Benchmarks comparing pass rates across AIME, Codeforces, and GPQA.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--30-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--30-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--30-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"higher-reasoning\">Higher Reasoning</h1><p>OpenAI launched not only its highly anticipated o1 model but also an operating mode that enables the model to deliver higher performance — at a hefty price.</p><p><strong>What’s new:</strong>&nbsp;Kicking off a 12-day&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3l_W1Kqhmq2Xxlj6W81Tjc17TL6dJW7d9Z631dRXsXW5T1c7j5LkhgmW4g4VhF944DwTW96k-1Q1FbXhtW28KMXh9gHrQ4W214-Qs28g_YQVThhRR8QBQ7mW9kt_vK8CjFxgW7H5jPH3s_fS7W598Ny33zPSXgW3Zx9qz2nbdGMN4l3YJDQvBT3W78qY5d4s-crQVmrFyN7XZzNfW5j1wXK2SWSB8W5YgvBl5SBZflW5CvXq15VVmDRW8sczpB6brThkW1zcVyb7SS6TfN5xrQFHkS-stf8gXdJb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">holiday blitz</a>, OpenAI launched o1 (previously available in preview and mini versions) and&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lLW3CrR588gvJfXW1Nw8t738CW3_VVkdr85TMtmRW8qTphY6MhlwkW1bvm-_6fKnxhW4ydGy25t9Rs7W2j--QT89n5YWW712jj11zK8SHW2NBgGv1npSF9N7QgZYcXQ3YWW92DRrn4ltpVPW4dSQwL8VxrK6W90Fjv76kJYHrVskB4f3G1GfrVkSLJ-8WRYcRW3zhNYh30nQs6W7TfVKg1w84QSW8K6K5k1b_HyhN6Dw655kJRy_VqzKqz17JStcW32Kc5K8CfxZWW1cg5fC39CLZhW3CSkmK4zhFvtW6pbkwn5f3-ZTdCt66d04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">introduced</a>&nbsp;o1 pro mode, which processes more tokens at inference to produce more accurate output. Both options accept text and image inputs to generate text outputs. They’re available exclusively through a new ChatGPT Pro subscription for $200 monthly. API access is not yet available.</p><p><strong>How it works:</strong>&nbsp;According to an updated&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lWW5y6cqb8QtG-pV-rlP17gdnxBW53r2hv3dryT0V93Wvr1WSpm-N7Hd9kStHV7BW5gS75M1qJzLjN2hMdVFsC7ZLW4PNwrR5MNQ2CW17J9Xz3wx_pcW6PWqmP8RzV3wW1wh8XX7LnNl9W4p2Tt61j6r6pW1QPNRj3B9-4DW3lRPsv8944Q9W5dn51x7tR4_rW6FCY7F4vzBz9W77MHd673Z1KnN45qMBQtbk8RW1TpG6P1phjB8W3_qGVf5xbSPDW6xW6lg40vnB5W4yL5f43H-LMbW85-8-18B705PW7FWrxb8Lg1smf8Y124M04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">system card</a>, o1 models were trained on a mix of public, licensed, and proprietary text, code, and images, with a focus on technical, academic, and structured datasets. They respond to prompts by breaking them down into intermediate steps, each of which consumes a number of hidden “reasoning tokens.” The models don’t reveal these steps, but ChatGPT presents a natural-language summary of the reasoning process. The new o1 and o1 pro mode perform better than o1-preview and o1-mini, but their additional reasoning requires more processing, which translates into higher costs and slower responses.</p><ul><li>o1 consistently outperforms o1-preview in one-shot benchmarks that measure accuracy in advanced math problems (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3kZW86S3LY266HgJW5-1s_r7fVCWpF62DkRwd40mW5lXYqq1M69w7W1yNZPL8XpXMjW6xR2ff8MJPw6W33Ybdr4MtjM2W2vXQSh31gGpcW83jqpB7kTRD2W7L1bjZ3YR4zMN5G_GDRdz6GQW52MtSd52045WW12Cvqk601GHfW43rvhd6S19mpW6GhLHG5CMH7YW22lSd41zBGrhW8GBvbV8nK140W5dZyTR12vZ09N99m7W5t84FzW8Vb0Mt8071vzVbfvnV2mByJJW4RVgJM1GYcc1W3nBtYD60DtjHW6VdnSb87LFpHW3gZsKw6JpghNW5jcptf3qGLf9f5yPv1204?ref=dl-staging-website.ghost.io\" rel=\"noopener\">AIME 2024</a>), coding challenges (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mnW1BRNYl7VYKqjVkxCYW3qZFpxW3SZmd67PtBNmN56Hjz0GCylYW2TvZkK1nBhkXW3nd4dq6nFQ7MN3KWVVCP-zbNW3SxLWc4CLs_hW10wsC81Zh1QGW98_wMg1CSzCZW7vP2bC3QG1y1VlwdPD8NJZWwW7Ym59T47qVPVW22R5n94Hq8ylW95CYy36vL5tfW2DwXhW2M0BKvW8HLmpf4wypz4W2yLN3b6kLWX1W6TYM-w6_L2RrW1j2SgB69bTCcW6K5r9c3tSk-YW3ZYSjD5qYCkVf5nNh0R04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Codeforces</a>), and graduate-level science questions (<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nVW80Wt9n67q0mHW6h5Kgf3G3dZtW9jqs8Y60RQ5bW2NZP0G7hKYx-W76ZlPh3vczTVF37q9_y94vjW3FtkwZ6cJKxZW1bTlhm1fBTXvW15h8lT7jZ8gwW3SmRn185thDkW5PW_tv2YZKtsW1LL4lb6rDPSVW3rmGFL8HVRG8W6vp-Zg8FcJXbN8jzp9WjSvqnV5lLv-1TYtt6W19cB-92b3CNfW6xK5pl5nTjcrW6NWw1S4sRCRkW6TCRzb1BScClVWF-_H5ShRSYN5MhmpTsg3frf1m6J6M04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">GPQA Diamond</a>).</li><li>o1 pro mode performs only slightly better than o1 on one-shot tests, but its higher accuracy is more evident when it’s asked to respond to the same input four times in a row. For example, given a problem from the American International Mathematics Examination, o1 solves it correctly 78 percent of the time, o1 pro mode 86 percent of the time. Given the same problem four times, o1 solves it correctly in all four tries 67 percent of the time, while o1 pro mode solves it correctly in all four tries 80 percent of the time.</li><li>o1 and o1 pro mode are less prone to generating false or irrelevant information than o1-preview, as measured by OpenAI’s&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nbW62L9hn4L1cB1W5jnRDm4LdNHPVVGHh636KKH1W7951v81QYx5WW1kmLKp52HHMPW4R_LGN467vNdW5n5Gkw6VvZjCW1bVzyZ7zPNW2W8ln2C01FrrKTW9g4Y235FJJVBVrJcQZ7r8rqCW2Pytty5v5Q4dW3kjXgx3sTcD2W7z266R14vB4vVrzt7H4bYMzsW5z_Y3g3cfS2JVBNmG27RnBP6M6sTJYGWNB2W8FFC6P5nfMT5VKZk0W3-MgG0W1W_lpr76txbGW3qzcsb2Ms0ntf3Ncsx004?ref=dl-staging-website.ghost.io\" rel=\"noopener\">SimpleQA</a>, which tests the ability to recall facts about science, geography, history, and the like, and PersonQA, which tests the ability to recall facts about people.</li><li>ChatGPT Pro provides chatbot access to o1, o1 pro mode, and other OpenAI models. Subscribers get unlimited use of o1. OpenAI has not clarified whether o1 pro mode is subject to usage limits or other constraints.</li></ul><p><strong>Behind the news:</strong>&nbsp;Since September, when OpenAI introduced o1-preview and o1-mini, other model providers have implemented similar reasoning capabilities.&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3pxW5Wb6fz5HHHmdW5r-kKW2qFtQ4W4mY_DK1sDXMSW6Dk1Zf9cc1yPW5hZw1G3R-16YW5QgPLj8lD5HyW51SDHF8TChrQW5thcTR273LkrW7cr_BN7bNXdVW1s_wK65Vbsj1VnjSwX2F9TVlW3Jnx5Q68kqlpW8wsVp_2FwTnCV1z4tp3pjCH7W83XrdF41QR-pW8DTQYL5XdB9PW4YXRqd1rKjptW4yk87l131f7YW94qzbf36DNN1W3lbT3y3z3zZwW7SJn4z7BTDkKW768yDH7d4kgZW8b7G_N5n3ZcKW6LtYNZ6Zkr6gW4GMTk-2XVyvbW2ZSzMv5tKT0XW6M-h_H69P3G4W7JgY9k3zFNLJW3Fqkqn6whww-N7FF4n827hX4djgBj-04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">DeepSeek’s R1</a>&nbsp;displays reasoning steps that o1 models keep hidden. Alibaba’s&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lTW86ncsw46glbdW1_ymNn62GNtkW5dtj6L8Nns5ZW1YrD-t73WWvNVFTTJ95HVK7xW57NTwm5fvgl7W4ZPgPf2hG74fW4fZ0VR18G5-mW31rJ4F8v3t2PVDLGMg6-8LjwVn9zh26XdTCzW8Hnpf-1DCK7SW1q7cFW1Rbp9BW3qfqH23TYstTW3THQk02bDXy4W8wdl-X8x1tPvW3g6_VK64c-VhN2S0ShVVv61xW3XHPVx4j4cYQW4JmW812dFQ80VkmJ5s4M-Y6TN2h8r0Jt7kQDW4DW_5M2DrNC1W2jL6Yw1VCgFHdw4FvR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">QwQ 32B</a>&nbsp;excels at visual reasoning but is slower and has a smaller context window. Amazon’s&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdv5nR32W5BWr2F6lZ3nvVj93qZ2K_mhbW7g-BPf8LvgJQN8SZG8RbjBpNW32qglb6l_8zXW620hxm1d0ks3W257cqw8gq_5QW1xXk8k7H0mDRW6kb1hR6QVPv4W4l-d1c663ntjW4Yn4Sr2Q6RG_W8SJd806YYDgSW3jCqCj4nmqCzW8928xV4R0xZgW81z-sk2zLGKZW46HQrG6hxkCyW4X2JfK1Y5h9NN4hgQDp_l5NmW7hQLwT4YSTDcVywlCt896rHVW81L3Db1tfL3HW15_q684VW-06W6L6nn25ptvVtW3jl2wf64JYQtW2S0mXk3nXQb1W1c6F5g2JY5gVW12v27k2GbvTbW292rz61dD9KXW3vJ9Gr7RJWsrW2HmHBN5fF-6BW2DpcTv3wW9JpW1bFSN1367FZHW5TyRbs6_2bXdW7d5YN37FJ6TFW3XPg407HsJ0Df7VBzJ204?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Nova Premier</a>, which is billed as a model for “complex reasoning tasks,” is expected in early 2025, but Amazon has not yet described its performance, architecture, or other details.</p><p><strong>Why it matters:</strong>&nbsp;o1 and o1 pro mode highlight a dramatic shift in model development and pricing. Giving models more processing power at inference enables them to provide more accurate output, and it’s a key part of agentic workflows. It also continues to boost performance even as scaling laws that predict better performance with more training data and compute may be reaching their&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3pzW4r0mZh7NmkWcW4N-kgQ91WJvzW3GfjjW68ZbnQW6l8pdK5Zzz7HW6VXwLK9bls6gN9fvSrCfx8fGN8FDGN_Mt-_nW64mDVF4_VZQDW2v2-hM881vdHW6X6tmN2HjVlXW2mbSpJ5BK4d4VfnPnG3VjcRjMHsCsvw3LbzV9zXnS5tfXR2W3zHCHz6ZVNvPVWPlXZ51TYn_W6lF_ld352z2gW2WbLgN75GPqPW14zmNH1_0P6bW7yPVp81Rj1DsW2H6JqB5ccD4dW8_WwYz6wPVy-W7rmMpr2Glv1vW178Q7n1rXWs9W5jJ-S739w3qkW6Gbx2-1x34TyW744XH058fTRwW82RXdN841DM-W326N2Z63_Z65W4zRx5m7yMFddW6fYpQV1p6Kd2W5Bdvdz5VfvZQf85Gwlj04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">limits</a>. However, it also raises OpenAI’s costs, and at $200 a month, the price of access to o1 and o1 pro is steep. It’s a premium choice for developers who require exceptional accuracy or extensive reasoning.</p><p><strong>We’re thinking:</strong>&nbsp;Discovering scaling laws for using more processing at inference, or&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3n_W3m0vmR6dZJ38W44Wq-L45l4p7W6R2x3P3hGq5YW5l1YfC17qv2QW4YcdPC84jpS5N2t0RpTTBf7yW8JnV8Z4YRynMW5ZJ47t2Z7QxWW5McVhf1-kVZnW8nf9r77MRcJxVdDsFR2MlD_sW736ySV1vwGnrW7s3dx21QsB5BN2CHS-WjRXbJV82lkQ3YNw0rW1x0nbq43CMdvW8rrnM04lx2GBW6DNrh01mVHlPW1R30GC44fjjjW790DX24pJnlWW8rWDxL34pdP1W7J2Fql8Wnd2Yf4sJD3204?ref=dl-staging-website.ghost.io\" rel=\"noopener\">test-time compute</a>, is an unsolved problem. Although OpenAI hasn’t disclosed the algorithm behind o1 pro mode, recent&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3lPMhHlRW9v3YPW2KTtBt8yKrv9W25ZCfc6y-3mBW24lylK1_zmyFN2tHT_C2lTbmV9C3FY6yGq90V5wKBJ2q0xCNN8-sFH_6cfDsW66PHHk73LqJvW93dNsJ4LP2MmW37CpKc4G8ws-W1tbYwX1G2rXkW7F_Dl53qW905VQ7_YC93s8qFW7zM5_C5yfSDBW6Vbpn828SlgzN2jNjNT_HrkJW8bn3072fwp6dW656-fS6d79SJW3MvrgH60s3XrW8Fqjzp5Ys_86W3kZ1yw8zw9ZCf2zj8HM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">work</a>&nbsp;at Google allocated tokens dynamically at inference based on a prompt’s difficulty. This approach boosted the compute efficiency by four times and enabled a model that had shown “nontrivial success rates” to outperform one that was 14 times larger.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--37-.gif\" class=\"kg-image\" alt=\"Game character climbing a ladder with visible controls (QWASD) and health bars.\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--37-.gif 600w\"></figure><h1 id=\"game-worlds-on-tap\">Game Worlds on Tap</h1><p>A new model improves on recent progress in generating interactive virtual worlds from still images.</p><p><strong>What’s new:</strong>&nbsp;Jack Parker-Holder and colleagues from Google introduced&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf-3qgyTW8wLKSR6lZ3lLW1FWhkP4j57hqW99N8KZ1-pmR-W7rbc1p1Hc3L4W3zPK-_2l7g3HW7TZYNq5xqJv1W64kNqx4BCyZvW7_Hm9v4ng7xsW17YvSs7sNQ79VZrqtv6Lr_-YVtfyTs709vpKW5s4Y442HyWqnW7hgLzQ1YdbgWW57v_ws3m4Nb7W6MQd276J_4vhW1r0TRs3Nx9ZdW7QLr4r50h2rVW4l1b-V1NVn96W3GWv6j1pzhfQN2qVZnt_WcJxW9lws5H14QXMsW8f5GR22C09GKW6G4g1q7r342YW6433nb3tXkGnW8rPCps2bj9RCW7bP5Sr4S2BQcW6YWH0-5rDR_pN1tDd23Xvg8ZW72d5cY980VHQf8G_hxn04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Genie 2</a>, which generates three-dimensional video game worlds that respond to keyboard inputs in real time. The model’s output remains consistent (that is, elements don’t morph or disappear) for up to a minute, and it includes first-person shooters, walking simulators, and driving games from viewpoints that include first person, third person, and isometric. Genie 2 follows up on&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3n3W92Tvw-629NjHW80Pwt37fgR8vW2_BlP-653r63W5YPc8-4nhxXLW8SJ2DX5kPfdFW5hz1H98mKWvWW5nTS296wBRmNW9fJvvt7rNpCjW4713nF2_jZVDVCCZkl195F0RW11NQy41FZ1wtW7xKYNq5qSQClW83Q73S2wQBzvW7j1B6H2LtzvyW4_sZDm7z6zcCW3VYf5W7WXw2LW7PkLfM8D10HlW7txHtZ6LnPldW6Qqg9d4v5XjwW5PkgV17Kw6Q7W2rS91n5jhHsLW1kz29222JR_CW1k2lZp1LTljnW20Vdds83qtKWf2DgyMx04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Genie</a>, which generates two-dimensional games.</p><p><strong>How it works:</strong>&nbsp;Genie 2 is a latent diffusion model that generates video frames made up of an encoder, transformer, and decoder. The developers didn’t reveal how they built it or how they improved on earlier efforts.</p><ul><li>Given video frames, the encoder embeds them. Using those embeddings and keyboard input, the transformer generates the embedding of the next video frame. The decoder takes the new embedding and generates an image.</li><li>At inference, given an image as the starting frame, the encoder embeds it. Given the embedding and keyboard input, the transformer generates the embedding of the next frame, which the decoder uses to generate an image. After the initial frame, the transformer uses embeddings it generated previously plus keyboard input to generate the next embedding.</li></ul><p><strong>Behind the news:</strong>&nbsp;Genie 2 arrives on the heels of&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3nMW8ZQD4y7Q55HnVbZJrM8_7ZBXW77VZyB7Xyq53W7YMkQz3zJSQTW492stg8jyCVmW6552104LXbRnW8stCvg2N9_sBW8pVthw2Mc6jwN7-G-Mwzg2-tW1-T_3p2ncw6CW5CvDSy4xlTWCW1ydPK78dytByW1__y8g3QNzNWW2Hg8jB8BWz62VyjwB09bFvYmN7cNKdypvryMW9gqhB01lTcr-W98t7Y785_hk-W7jDV4X3QsBf9VTV1WJ5vNN9jVtVmS-7_HQFmN2dQsBF5ZxscW5RD_4_2fhyhtN8B0Zf8FBhFxW95wBcJ4VsJ-bW1NbGxG6bGHZjN72ncW2420jQN4smYlfNFRRbN5-PSBNSq3m5VJwy0t4v199Hf3Hwlgx04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Oasis</a>, which generates a Minecraft-like game in real time. Unlike Oasis, Genie 2 worlds are more consistent and not limited to one type of game. It also comes at the same time as another videogame generator,&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pQW8Ygtml4xrrffW4mkqcb1lXWLyW2nlT7q6xp_5FW84HCG83zVsp3W1YkqcJ8Kv-7rV9Ykwt1dl1yVW942ln07vZ0bnN3GcgqTdzRVGW89CNbw486pnhW1XZB1q1pm75vN4ZGV9dv3ktcW5t5NHs85QZ7NW62nHGX5mJ_nPN6G5G9Fllsw5W2GxKxG96J1DXW7RL3y97W4KvcVv_ybS8TqK3lW3xFB7r1pM74gW64nc4p5PLSS3VLqX0x1LMWwlW6jb4rq7RRdzFN2tbgx5BMlm7f3vb8yl04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">World Labs</a>. However, where Genie 2 generates the next frame given previous frames and keyboard input (acting, in terms of game development, as both graphics and physics engines), World Labs generates a 3D mesh of a game world from a single 2D image. This leaves the implementation of physics, graphics rendering, the player’s character, and other game mechanics to external software.</p><p><strong>Why it matters:</strong>&nbsp;Genie 2 extends models that visualize 3D scenes based on 2D images to encompass interactive worlds, a capability that could prove valuable in design, gaming, virtual reality, and other 3D applications. It generates imagery that, the authors suggest, could serve as training data for agents to learn how to navigate and respond to commands in 3D environments.</p><p><strong>We’re thinking:</strong>&nbsp;Generating gameplay directly in the manner of Genie 2 is a quick approach to developing a game, but the current technology comes with caveats. Developers can’t yet control a game’s physics or mechanics and they must manage any flaws in the model (such as a tendency to generate inconsistent worlds). In contrast, generating a 3D mesh, as World Labs does, is a more cumbersome approach, but it gives developers more control.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.gif\" class=\"kg-image\" alt=\"Graph showing how training loss affects token prediction accuracy and hallucination elimination.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.gif 600w\"></figure><h1 id=\"getting-the-facts-right\">Getting the Facts Right</h1><p>Large language models that remember more hallucinate less.</p><p><strong>What’s new:</strong>&nbsp;Johnny Li and colleagues at Lamini introduced&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mhM1QZXPd2Wq-MVqxvdCnKRnW10xjq08jntYdW8tvmmP27QqVpVXzvPr1b8dlJW7BYFh77dhCkPW4X0BGH3h86fvW5XtDtm81XzxHN79cj0ksrxZ0W1ZBSGs2ZjtsDW7WrF446DHMCMW88V1gG7n8kfpW3swr2W1YLRdpW8yjL7f1szhRbW3SfpmQ2PxxdfW15GqWq3mCl3sN5NJGjq77R2JW6l-cmj96y75bW3g1MtJ86q_wnW6sZZsl7hRpx6MKMxLTsVvk4W1X6r-54b5yG1f7RPVLv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Mixture of Memory Experts (MoME)</a>, a method that enables large language models (LLMs) to memorize many facts with relatively modest computational requirements. (Disclosure: Andrew Ng invested in Lamini.)</p><p><strong>Key insight:</strong>&nbsp;The key to getting factual answers from LLMs is to keep training it until it chooses the correct answer every time. In technical terms, train past the point where tokens relevant to the answer have a similar probability distribution, and continue until a single token has 100 percent probability. But this amount of training takes a lot of computation and, since the model may overfit the training set, it also may degrade performance on the test set. Fine-tuning is one solution, and fine-tuning a LoRA adapter to memorize facts reduces the computational burden. But a single LoRA adapter isn’t enough to store all of the knowledge in a large dataset. Training multiple adapters that are selected by cross-attention enables the LLM to memorize a variety of facts.</p><p><strong>How it works:</strong>&nbsp;The authors extended a pretrained&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nNW3WgmD-3-VNfJW6r44tC1MwZ69W5y4-C-83Z1lfW7YzQL31-JmXXW5tz2D46tGxPvM8dXQVhR7x5N618sdWr3BX_W7P_68t7-bP7NW7KJqvK4B8r7QW55PmJf5q3bpzW52KZDp3KF1t0W6bRJcL7NS-ZzW4jCTwl4NxMjMW2ZCK1K5q8x4pVF62v15wX0xrW7RFzBl7c7jN7W1JY1R13L8by8W3G1b8r6Y9XtXW1HyRCS6pWvktW46Ty_z5XB6fyW7QrBZn4QbkgvW3RPShF8XJMlvf408ytK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Llama-3-8B</a>&nbsp;with a large number (on the order of 1 million) of LoRA adapters and a cross-attention layer. They froze Llama-3-8B and trained the LoRA adapters to predict the next token in a custom dataset of over 1 million questions and answers.</p><ul><li>For any given question, the model learned to select 32 LoRA adapters, each of which was associated with an embedding. The model selected adapters by performing cross-attention between an embedding of the input query and all adapter embeddings.</li><li>The authors trained the LoRA adapters until they memorized all the answers as measured by the loss function (100 epochs).</li><li>At inference, given a query, the model used cross-attention to select a subset of LoRA adapters and responded accordingly.</li></ul><p><strong>Results:</strong>&nbsp;The authors&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3pPW5f_dkq5-WBV-W4PpktS21G4JbW1b7mhD8kLZ64VlQ1KP1YDJnlN6pd9KWXRdl1W1wfFlw89hvnsW71b2jF3n3BJ3W1whM-M4rg0DBW8zpLNS5SZFdsW4X0tbP8-kYHQW5rg3P36z5KpbW6fvxy_11vXb_VNSNwf27L97qW6KWVNb1_0y_8N7SS224h2HZYW4CTzbD2qY7WnW6gN8vT6Ps24mW6HNGgR3sNr80W7LL2B490-TlVW1v2bC81fprkcW4_4cMT5MLztLW95zzTk8Fhz9dW7LkT007Nf1mvW1RySd341g55ff35cWfb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">tested</a>&nbsp;their LoRA-enhanced model’s ability to answer questions about a database via SQL queries. The model, which was outfitted for retrieval-augmented generation (RAG), achieved 94.7 percent accuracy. An unnamed model with RAG achieved 50 percent accuracy.</p><p><strong>Yes, but:</strong>&nbsp;It stands to reason that the authors’ approach saves processing, but it’s unclear how much. The authors didn’t mention the cost of fine-tuning Llama-3-8B in the usual way on their training dataset for the same number of epochs.</p><p><strong>Why it matters:</strong>&nbsp;The authors argue that eliminating hallucinations is possible in typical training, it’s just computationally very expensive (not to mention the risk of overfitting). An architecture designed to store and retrieve facts, via LoRA adapters in this case, makes the process more feasible.</p><p><strong>We’re thinking:</strong>&nbsp;While some researchers want large language models to memorize facts, others want them to&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3p7N5R_dZxTbT43W4gd7FW4FjyFjW71QYR785qhP7W8mvKrr5m6xXGN4S_r5ddJGVSW1129Q14mpyG0W1zl4tr65cY40W8p1tH-8CWTbdW77g_jt5Dmq9RW6p2nRp5x-WSGW7MYNRc7YKBPKW5dHwn_8lVfXYW7kGq461gWXbWW7FtS4S3gVLyHW1tVJF13xrRHvMHvLF1RjwPxW69ZCN31z-77KW5HHPrC1TKZBJW31hJtr7N39PKW7QDhhT29mLxqW4nW2Gh7D7JBLW3FMf7H3pt9dmW8dXM5Y6FhfVZW14JdBp2qKfh3W4-NwMz2WbCSmW4m3snd9fHsxyW3LkD9L4rk_VXW3XBz--3JlBdYW2k0QqT6HwWDDN1Nj1Lgn3yjmW5x-xTW6gsNhdW6RMRb-86tQjtf8tv_6804?ref=dl-staging-website.ghost.io\" rel=\"noopener\">avoid memorizing their training data</a>. These aims address very different problems. Preventing LLMs from memorizing training data would make them less likely to regurgitate it verbatim and thus violate copyrights. On the other hand, this work memorizes facts so the model can deliver consistent, truthful responses that might be stated in a variety of ways.</p>","comment_id":"6759f81f58d8b10001af9b7b","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg","featured":false,"visibility":"public","created_at":"2024-12-11T12:37:51.000-08:00","updated_at":"2024-12-22T12:36:12.000-08:00","published_at":"2024-12-11T12:50:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"6759fb8358d8b10001af9bb7","name":"Dec 11, 2024","slug":"dec-11-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/dec-11-2024/"},{"id":"6759fb8358d8b10001af9bb8","name":"issue-279","slug":"issue-279","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-279/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-279/","excerpt":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs","meta_description":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created...","email_subject":null,"frontmatter":null,"feature_image_alt":"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"ChatGPT Prompt Engineering for Developers","databaseId":29452,"id":"cG9zdDoyOTQ1Mg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/05/cgpt-2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}