{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-284","id":"67883bc05ab5a20001e250b5","uuid":"0ffd55e1-6fd7-4ac6-86ea-414d31cf9787","title":"Tumbling Training Costs, Desktop AI Supercomputer, Tighter AI Export Restrictions, Improved Contrastive Loss","html":"<p>Dear friends,</p><p>Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!</p><p>Software is often written by teams that comprise Product Managers (PMs), who decide what to build (such as what features to implement for what users) and Software Developers, who write the code to build the product. Economics shows that when two goods are complements — such as cars (with internal-combustion engines) and gasoline — falling prices in one leads to higher demand for the other. For example, as cars became cheaper, more people bought them, which led to increased demand for gas. Something similar will happen in software. Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build.</p><p>This is why I’m excited about the future of Product Management, the discipline of developing and managing software products. I’m especially excited about the future of AI Product Management, the discipline of developing and managing AI software products.</p><p>Many companies have an Engineer:PM ratio of, say, 6:1. (The ratio varies widely by company and industry, and anywhere from 4:1 to 10:1 is typical.) As coding becomes more efficient, I think teams will need more product management work (as well as design work) as a fraction of the total workforce. Perhaps engineers will step in to do some of this work, but if it remains the purview of specialized Product Managers, then the demand for these roles will grow.</p><p>This change in the composition of software development teams is not yet moving forward at full speed. One major force slowing this shift, particularly in AI Product Management, is that Software Engineers, being technical, are understanding and embracing AI much faster than Product Managers. Even today, most companies have difficulty finding people who know how to develop products and also understand AI, and I expect this shortage to grow.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg\" class=\"kg-image\" alt=\"Two colleagues discuss their chatbot’s success; one suggests hiring an AI Product Manager.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/AIProductManager-2_1200px-1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/AIProductManager-2_1200px-1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px-1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Further, AI Product Management requires a different set of skills than traditional software Product Management. It requires:</p><ul><li><strong>Technical proficiency in AI.</strong>&nbsp;PMs need to understand what products might be technically feasible to build. They also need to understand the lifecycle of AI projects, such as data collection, building, then monitoring, and maintenance of AI models.</li><li><strong>Iterative development.</strong>&nbsp;Because AI development is much more iterative than traditional software and requires more course corrections along the way, PMs need to understand how to manage such a process.</li><li><strong>Data proficiency.</strong>&nbsp;AI products often learn from data, and they can be designed to generate richer forms of data than traditional software.</li><li><strong>Skill in managing ambiguity.</strong>&nbsp;Because AI’s performance is hard to predict in advance, PMs need to be comfortable with this and have tactics to manage it.</li><li><strong>Ongoing learning.</strong>&nbsp;AI technology is advancing rapidly. PMs, like everyone else who aims to make best use of the technology, need to keep up with the latest technology advances, product ideas, and how they fit into users’ lives.</li></ul><p>Finally, AI Product Managers will need to know how to ensure that AI is implemented responsibly (for example, when we need to implement guardrails to prevent bad outcomes), and also be skilled at&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/how-to-get-user-feedback-to-your-ai-products-fast/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8E3vaHtVCWyWM5X79V_-x7uED1QR5exdS62WzX7rqOxTAyyDUu5M6mivzzbnP3hw8qJKhG\" rel=\"noopener\">gathering feedback fast</a>&nbsp;to keep projects moving. Increasingly, I also expect strong product managers to be able to&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/my-ai-assisted-software-development-stack/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8E3vaHtVCWyWM5X79V_-x7uED1QR5exdS62WzX7rqOxTAyyDUu5M6mivzzbnP3hw8qJKhG\" rel=\"noopener\">build prototypes</a>&nbsp;for themselves.</p><p>The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.</p><p>The variety of valuable things we can build is nearly unlimited. What a great time to build!</p><p>Keep learning,</p><p>Andrew</p><hr><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class=\"kg-card kg-image-card\"><a href=\"https://www.deeplearning.ai/short-courses/reasoning-with-o1/?ref=dl-staging-website.ghost.io\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png\" class=\"kg-image\" alt=\"Promo banner for &quot;Reasoning with o1&quot;\" loading=\"lazy\" width=\"1890\" height=\"1063\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png 1600w, https://dl-staging-website.ghost.io/content/images/2025/01/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640--1-.png 1890w\" sizes=\"(min-width: 720px) 720px\"></a></figure><p>Get up-close and personal with OpenAI’s groundbreaking o1 model! In our short course “Reasoning with o1,” you’ll learn how to get the best performance in coding, planning, and STEM tasks; perform complex, multi-step tasks; and optimize prompts with meta prompting.&nbsp;<a href=\"https://www.deeplearning.ai/short-courses/reasoning-with-o1/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\">Enroll today</a></p><h1 id=\"news\">News</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--45-.png\" class=\"kg-image\" alt=\"DeepSeek-V3 accuracy across benchmarks compared to other AI models.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--45-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--45-.png 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--45-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"deepseek-ups-the-open-weights-ante\">DeepSeek Ups the Open Weights Ante</h1><p>A new model from Hangzhou upstart DeepSeek delivers outstanding performance and may change the equation for training costs.</p><p><strong>What’s new:&nbsp;</strong><a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3nFMJY6jXzXlLzW6K9V6T6g1R8CW58dNXs883YTPW9hfXnm8Vm21XW7bxgt11S62vhW29L7rC6rjnzBW7FmlPN4SGyh1W8Bd6TZ2J_y3gW1sVDwP7pkvzWW8PwzpD6HX-fqW3TtgW_6dP5Q8N8LwqNFGTdd4W8kWCXJ6R0n4jW3B2CNv1cKfdKW1_Ch9C88JcVNVFVcwh13bNq4W974xzr4LQPKCV3wNpr6RZHhlW7Z0nQJ81lj1zW3QTsm4467sn-W2L7n6T8yC7KXW8kdSfC6PPXWMf2Jk0Rj04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">DeepSeek-V3</a>&nbsp;is an open large language model that outperforms Llama 3.1 405B and GPT-4o on key benchmarks and achieves exceptional scores in coding and math. The weights are&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fd3qgyTW8wLKSR6lZ3mkN84dx4G1_5w4W162mZK4NFn5HVgP5Dc4Qx4SnW7MBgzF45KlmVW5V_4Hj1R5T62W8D1pS_4c7n-_W22CNh369YzHmW3DLdpc5h_J3LW3my6p45lQdk_W5nJCSQ1DCBSbW1fMB4Z1M6_j3W1z7lh_6zjVJFW90kD973Hsh4sW2L71TK58TkqXW7z7Dhp2kXPXLW1K8NNm6RfdjpW6hvLsK95JxBcW1fZjxj1l4gCRW27QYYB2fxZ5GVVxfsR1bxlh5W6X731F8mS7lMN97YQdJCf7N0W2QGFJJ2CNmHjW77nkdJ4mkCxgW3T3MpN4J49nVW2JrPsV1ZD3kpW2CTXbh78cVKKW59R61b8YHJwbf1T1QJg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">open</a>&nbsp;except for applications that involve military uses, harming minors, generating false information, and similar restrictions. You can download them&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dF3qgyTW7lCdLW6lZ3mzVr5syj8PKf63W6t471-3-QST6W4m_j6_70GsDTN4qs7KsY5CvQW3yjQ6T8WPTYPW58TJgY73vNxTV5DNW87dZFPJW5cxtvB63vJp5W7JKxCT77rKVrW2V09XN6NfCldW5RrZRp29q7DKW1rSpg57L_qsHW5mH1PF6-ZggFW2VxjQz4C6GjZW8FGXYd7Htr-XW4h8zZW2sl1MHW1FXp0Z6b5DrXW5LD_yY81dgZVW75rnB44zJyw_W8-lHhQ3tnSgFVJ2VDk224KSXW73M8gM5LPbpZN4tDHF8LBJQvW4VXwc57PRNQ6f7jgYGK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">here</a>.</p><p><strong>Mixture of experts (MoE) basics:</strong>&nbsp;The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.</p><p><strong>How it works:</strong>&nbsp;DeepSeek-V3 is a mixture-of-experts (MoE) transformer that comprises 671 billion parameters, of which 37 billion are active at any moment. The team trained the model in 2.79 million GPU hours — less than 1/10 the&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dY3qgyTW7Y8-PT6lZ3l8W4HZ3tr729ClLW935Ks498jK8WW6Cpm2f4bq26RW7GtCyN6lqPkGN97q92ns8MKGW1LtnMh7kvBhTW2D4x7F6gY8DsN6LxsSrg1PbCN3Vdp0CV4HQhW3Bv-4h3KqfwhN5jphRqJCyy9VlDbmb2pgxH6W48_SQd7SKKDfN9jX4rxVQmrzW80Y9Fs4XR_g4W3-9n_K7wKGV9V4nGPl5kd8XPW7NMjsB1vws0-W5RNSs02nwN1sW7swJ636y0Mc4W4QzSrm5LsTBqW4h-fN73yNG_KW1x6_PX21pqwkW8hgxgZ19z7w-N6xNv5qKTwqmW6x8nZX3R7r3Lf3Bwftg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">time required to train Llama 3.1 405B</a>, which DeepSeek-V3 substantially outperforms — at an extraordinarily low cost of $5.6 million.</p><ul><li>The developers trained it on roughly 15 trillion tokens, including a larger percentage of coding and math data relative to DeepSeek-V2. They fine-tuned it on a wide variety of tasks using output generated by&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fx3qgyTW95jsWP6lZ3mcW2dL6rK5GQ7gyW298xFz55md2QW3VrT5w3TfBw-W20TMxk8bfjWqW1BPGl528_8RVN13JxlYHtz7dW5s3pbt4_lvX_VPFFm_4StGCvW4Ml1P61scVmNW365HWl3Vp26BW6H-gxS1brh1BN1jHpx8m7Fl2W3wQqWF7pMr3zW9gXhPS1Rpc6gW50Rmkk17D3wWW9f7Hgc3LmvcZW42fJ-G3LPPd7W8ZWgz_6Sx6BmW1W36pt3DKrzJW76h02t3s3QK_W1jP2Sh30lY5RW2VB5lJ82vtKgW2tNfWx2QPkjmW1lRrMZ4nQCMKW3S70Cv6KvY4nW1dqyRQ1HR0lTW9krC0K5lDYdFW7RtsDb7lgvPQW9bd9Q95fb5XqW8bN3NW4Gxldqf74TD4n04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">DeepSeek-R1</a>&nbsp;and DeepSeek-V2.5. They further sharpened its performance across diverse domains using the reinforcement learning algorithm known as&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3kRW4Nfj6r1McW--W34-05Q445RFZV7wrw43Tfc8vW1Xh4M-3hMf_3W5zhKy12Q-ZbLW43_1dt3D8kCxW1ghRBY34Hfg_W58YTNx7xJDQSW7n9kKT1xHy1XN2v1tSsk3jdmW2QMvr_1kbGzQVyRVsT1zbjChW7_qDjw1rp7_ZW3dRSc41D_y8gW46bPsb5bVZXTW1g9vBR7QCzkWW3C7tC85y5z4MW50FfGX4jS2H9W5h_sxj6t3qnqW6gt_6K5FYkMvW5GjvvX6xLYNtV7QZX_8sHjPVf7KsVLP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">group relative policy optimization</a>. &nbsp;</li><li>Earlier&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3m7W1cDc8Z6JmgfDW23sKhP7lnBxYV1g8Yz3hMwRJW44B9285Dmq-_W3pWCPn2LYcFsW7z2NnZ6dlLSDW38sX6b1-NQSfN44pLdsH1hFRW7pyMhk5Dq0mQW8BG_0s4KZPZkW10pcqT4zxMbSW6d7RWz3bP5vLW6jwpKp3tnV_bW1N6KBj2sb5YNW7kD0JZ97Jt5zN6CxTjZQhpFcW2_QktY50bg2rW6k8B349kCG6bV8zlxl8H5JTLW1R_R0p712St_W4rLnFC7JqkzTW2qDJ_p62JKtmf2qNykz04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">work</a>&nbsp;showed that training to predict the next two tokens would improve performance over learning to predict just one. The authors implemented this procedure. The model learned to predict the first token as usual and used an additional set of layers to learn to predict the second token. The additional layers aren’t used at inference.</li><li>Following&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3nMW2bbzrc68PtWTN7vyjTL7nh0rW6YpKcH1tK-93N6x7SLl1qFHWW42GwzX7qyzpMW3rcWv23k9zYxW4Vbxnm5RLlgZW72ZCdx64yR1-W57_bHM3CsNdFW3pzJ3c5b3-sZW34vqFm3BLMBFW7D3Wsm6sfdlwV12QXk29-2PJW3DsRLQ4DTvhbW8dXkdN4PMqf5VkN6Sg7pV4gdW3gSx9Z3kj-q2W20GXvW6cHZvRVJrH4K90-rsqW7hkM1n9hP_13N4qzLTs4tn37W8DPnfT4q3QmSd26Zcl04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">DeepSeek-V2</a>, DeepSeek-V3 uses multi-head latent attention, which saves memory during execution relative to other variants of attention.</li><li>Also like DeepSeek-V2, the new model combines dedicated (routed) and shared experts. The model chooses eight of 256 experts for a particular input, but it also uses a shared expert that processes all inputs.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;In DeepSeek’s tests, DeepSeek-V3 outperformed Llama 3.1 405B and Qwen 2.5 72B across the board, and its performance compared favorably with that of GPT-4o.</p><ul><li>DeepSeek-V3 showed exceptional performance in coding and math tasks. In coding, DeepSeek-V3 dominated in five of the seven benchmarks tested. However, DeepSeek-V3 lost to o1 on one of the five, according to a public leaderboard. Specifically, on&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3npW4WVmGw3NHCqTW6Hz00L8Y9N8-N3qkcMFfr_L4W8ZGqt72DNMG2N1QzDyYYbsmvW6QTFWk7qQSvDW11T_7D4BcQCMW4vhVM47sBXPYVfG43r50zQKZW36TZJH1RNJGhW9k0hhp6b6FfSVJcNQS5krXJBW1nR3L08H0MzWW5KPMpG8pdV-GW6-PKGy8y1CP_W3638_B9bzrK2W5L1NX799PsBGN7CDwY4-HNRdW8-GryW39Kn64VLMV4W1jN7wRW3277332BBhrbW6zW69D5XBb6cf6cfblH04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Polyglot</a>, which tests a model’s ability to generate code in response to difficult requests in multiple programming languages, DeepSeek-V3 (48.5 percent accuracy) beat Claude Sonnet 3.5 (45.3 percent accuracy), though it lost to o1 (61.7 percent accuracy).&nbsp;</li><li>In language tasks, it performed neck-and-neck with Claude 3.5 Sonnet, achieving higher scores in some tasks and lower in others.</li></ul><p><strong>Behind the news:</strong>&nbsp;&nbsp;OpenAI’s o1 models excel thanks to agentic workflows in which they reflect on their own outputs, use tools, and so on. DeepSeek swims against the tide and achieves superior results without relying on agentic workflows.</p><p><strong>Why it matters:&nbsp;</strong>Open models continue to challenge closed models, giving developers high-quality options that they can modify and deploy at will. But the larger story is DeepSeek-V3’s shockingly low training cost.<strong>&nbsp;</strong>The team doesn’t explain precisely how the model achieves outstanding performance with such a low processing budget. (The paper credits “meticulous engineering optimizations.”) But it’s likely that DeepSeek’s steady refinement of MoE is a key factor. DeepSeek-V2, also an MoE model, saved more than 40 percent in training versus the earlier DeepSeek 67B, which didn’t employ MoE. In 2022,&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9cM5nR32W5BWr2F6lZ3p7W6J06mg32RF_cV2G26C6QGlLsW6GX21Z85ZjPMW1VkFnN1F6G3-W4LCDpd5CJ3dTF8Vg8ZW3y_7W4_5tX45PF8zwW62q0GZ3zwLXgN3B3jJcVN2FPW27GtlM5JRyxsW9kxr9B3f-hr6W5LzpbD2n6b60N6cfWGT67K2DW3qV_yR2r38g5W2BvGTy3j07gTW89pVcx71ns3sW97r8Qr6TM6qVW64_0dk6_MYWkW1Jrr7R5L5XdyW36lGzq1ylCCxW5jVLBx89Gyc0W8Rq09v1R5zBCV6Y3vx5Ph483W2qPtqQ6tyGXGW7CGzMV2bPdVsW1c2jZj3cvSv-VM629J4HdxPdW2vxFMK6jrl5nW615mCF70Scn0VFxcVn758JfWW99xGtM4xDZ_JW1581P11dHtzVW6-QpRc4ntJ5wW3Cy0bK72b6Zjd76_6804?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Microsoft</a>&nbsp;found that MoE cost five times less in training for equal performance compared to a dense model, and&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3m5N48JgSXzpZ0bN5JWS0JRJvbDW7CyjLM141wkMN32jxT2NdfvjW2NBTpG6tMLpJW7kN1Zr7pS0TCW2k6KSD6jmgT-W6k9LLW5rqb5BW6G-66w1jCFkYW9131681Wy3LTW78qFwD7FQ9fnW9fW9JK74l--CW4Z4ckW4TqVr6W2g0lXd8pVC_dW7pBY5y4GcSPrW5WW6Nm1g62XNW8w8NGk1Vg0rSW2x5nJw5Plt6fW7zrrwZ5Pvvp6W42Y_Km4J6HG7W3qg8Jm3LfL3_W5qgFnY3nd_qqf6d3ycl04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Google</a>&nbsp;and&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3krN99SKhWsktrBW4Sdg4G71RCmNW8S-JnS75SvqCW2fmGnV13mvyKW5K0XMw7DbdJGW5gQqjz6KW7KpW1_X4zq7rPhNnW212tlp7f0pZYN8K8t_VPnL1PW2Wflwn78MhFhW8SDN-r2MxHGXN7CD1TsQ11wTW3NV4c32s-FngW3d0z7q1XJ0CXW4HK-6m6gFh1TVMjd25730y7TW54Jdtk4vP5QVW3qVSbv24h9X1W1WM1Zm7VXjy8W5kmP-44J7hwvW3QRnX62g-901W1_-KHL8r4hQCf3g9WLT04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Meta</a>&nbsp;reported that MoE achieved better performance than dense models trained on the same numbers of tokens.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;If they can be replicated, DeepSeek’s results have significant implications for the economics of training foundation models. If indeed it now costs around $5 million to build a GPT-4o-level model, more teams will be able to train such models, and the cost of competing with the AI giants could fall dramatically.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/BIDENCHIPS-10_1200px.jpg\" class=\"kg-image\" alt=\"World map of AI export restrictions: Tier 1 (green), Tier 2 (gray), Tier 3 (red).\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/BIDENCHIPS-10_1200px.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/BIDENCHIPS-10_1200px.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/BIDENCHIPS-10_1200px.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"us-moves-to-expand-ai-export-restrictions\">U.S. Moves to Expand AI Export Restrictions</h1><p>The United States proposed limits on exports of AI technology that would dramatically expand previous restrictions, creating a new international hierarchy for access to advanced chips and models.</p><p><strong>What’s new:</strong>&nbsp;The Biden administration, which will transition to leadership under incoming President Trump next week, issued new&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9cs5nR32W50kH_H6lZ3nPW2CxHnd3xC8R7W85GfFd9lRg2xW3xN8RX6vFrPgW1BL9Yq4HSPD-W6g6Gzl8FbzqNW74l9Gf5NB3nQV6-7pr1fmPs4W3zwdhK72N2M4W6szqF43zDkwHW6J8hQ98fZMNDVNcPyW6pVlWBW3mbmBj522-sqW4HKfGy6p22gFMkyg6wjt61NVk4Qpx5sLswvW19Ctfp8Db2ZHW6JNqRv1tS_WYW7zCJrM6kKNnXW58sM9-6sxTsHW8q5l2x9d7y6NW4X5m9r662TkzW6MM9T865-LZmW99xxmD7pYxFyMRwmVCl6XHqW5yC_Zg1XVnPwW77MvZk3skDS6W85PVrT6KnrBDW21MNJ612gFqnVcSMM22H2Zq7W3dNJnC5wBg0WW7FMZ5q1nDKXNW54V-Rc1t_HXXf3xP8VK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">rules</a>&nbsp;that restrict exports of AI chips and models to most countries beyond a select group of close allies. The rules, which are not yet final, would create a three-tier system that limits exports to a number of close allies and blocks access entirely to China, Iran, North Korea, Russia, and others. They also would introduce the U.S.’ first-ever restrictions on exporting closed weights for large AI models.</p><p><strong>How it works:</strong>&nbsp;The restrictions were announced shortly after a&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dY3qgyTW7Y8-PT6lZ3kYW1Spmy-6WjWPCW2TG1R24KbTXhW47ph9X97mbWhN4WV55g6Pt2BW2LVxj05zHBhsV65ddR7tqCS2W2Fd3T5759xDHW8RVQRb1YjS3_W52q69j5f21c3W52X3Hq4s5CxBW19qTJx4YGH5sVMZsbK2NstcnW17jS-T5v7qWlW95T7JZ6FTn_KW5tr1xG1QfWCLN2xPKKj63jqyW13T4s16rC8gSW7BRBYb5Cqs8dW2wp8X47LWxVyW6Q0dw08pxNt7N886Jt3Qfhr-W5Rhp9F1GDY0LN8Y_tT9GgC5xW5vbk_T2-ZprKN5WyKzKWcRP4W3Q1RX_30k8LVf2k72Nv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">leak</a>&nbsp;reached the press. A public comment period of 120 days will enable the incoming U.S. Presidential administration to consider input from the business and diplomatic communities and modify the rules before they take effect. The rules are scheduled to take effect in one year. &nbsp;</p><ul><li>A new&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9cs5nR32W50kH_H6lZ3n_W7jf-0q3YlgY0N8WQTdm4f1XHVNGMl-3MWkhgW4gYMth79mrVSW2Q77tg5zKbJqW8fvGyV7K62gCW2dz2cb8xYNz_W5_7GQm4z8vGfW6J68vr5BTy_kW1-xzb72yZNPVW7PyfFR1pfGgjW2CLsNW2ch6q2W2qYG_52Hsg6gW36ynVK4BcTGSW5lPk6C7MrYbLW9l5jNd19yrjWW1CB6Rm6G53flW8V_9QZ4sYg_6N20XMbgwBQ-YW8XyPLl6glg5tVgw8DD4jHwvqW4Gt0gK8sDywKW10MQhm16tP7RW3FWYqS8C5__qW6LKMYd6FVFPCW2bMX7-5MWTYPW3-_HZ295_GM-W391hm75LRp5MW7W5_fn524VtqW5b2SY-7XhKsCVhQnJ7500xBTVxh4MT8YrgFHd2zVYM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">hierarchy</a>&nbsp;divides nations into three groups that would have different degrees of access to AI chips both designed in the U.S. and manufactured abroad using U.S. technology, as well as proprietary AI models.</li><li><strong>Tier 1:</strong>&nbsp;Australia, Japan, Taiwan, the United Kingdom, and most of Europe would retain nearly unrestricted access. However, these nations must keep 75 percent of their AI computing power within allied countries. No more than 10 percent can be transferred to any single country outside this group to ensure that advanced AI development remains concentrated among close U.S. allies.</li><li><strong>Tier 2:</strong>&nbsp;Traditional U.S. allies and trade partners like Israel, Saudi Arabia, and Singapore face an initial cap of 507 million units of total processing power (TPP) — roughly the computational capacity of 32,000 Nvidia H100 chips — through the first quarter of 2025. The cap would increase to 1.02 billion TPP by 2027. U.S. companies that operate in these countries can apply for higher limits: 633 million TPP in Q1 2025, rising to 5.064 billion TPP by Q1 2027.</li><li><strong>Tier 3:&nbsp;</strong>China, Russia, and around two dozen other countries are blocked from receiving advanced AI chips, model weights, and specialized knowledge related to these systems.</li><li>The U.S. Commerce Department’s export control agency must approve the export of models or transfer of weights of closed models that were trained using more than 10<sup>26</sup>&nbsp;computational operations. These rules target future systems, as no known models today used this amount of computation during training.</li><li>Companies based in the U.S. must maintain at least 50 percent of their total AI computing power within U.S. borders. They also must track distribution of their models, implement security measures, and submit to regular audits.</li></ul><p><strong>Behind the news:</strong>&nbsp;The proposed rules build on 2022’s&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dF5nR32W7lCGcx6lZ3pKVW_F2j8WPcfrW226Vzp5Vj1WvMCkqs5xJKFJW1S9wnH7lSFjyN8KVyPB8G-vKW4lTyRK5P1Wr7W2k9mDt1Y4whtW6x2mq42fnV1RW65_MGp9cnVvGW5ZDwk0634tmfW7dK-Dc4DPrnBW24XpTt3WHX69VmW8416qqBJJW1W282N8Ff2CCW8q5WhX3m7RDnW88ps939cR1zVW6mTN912J1NFFW8jnhjH3gFjrTW4NYLmj93yYVCW5vyhSv5MqSKtW2F0y0B6KylJXW7CBDDB8qZkqGW8L2tf8959_bFW2w6z4Q4l0zrbW3q40JL4JlltfW527TF03Tx0B8V5KHH26NvJ91W98jkDf4dMLz_W2j0X7b8sz_wlW1X2Rwx2fmFWHW8w1s9K92FSnxN3K8qT__RwzqW6sWTQM59w6ZcW39XM089lBsrvN3Z612XqTccnW1X-pLZ4WpWtMW54psJR6r4ZxtW7ywRvS3tkWZ2W6646G_5rK-36V5Bvl34xyQkBf4vQg1P04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">CHIPS and Science Act</a>, which was designed to strengthen domestic semiconductor production and restrict technologies abroad that could bear on U.S. security. An initial round of restrictions in late 2022&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fd3qgyTW8wLKSR6lZ3kLW3c9HN435-pH2W7LrxTq26GLDGW1z-Qsz6kfrgyW726W3v8L5qJBW44sL8D6hvv1yN9jKXQ6M2JCNW64Jlj64nr0XGW3XDtZG8r5s-pW1jfTP42wQyT2W2cSCKy5-VjRgW3JrYbV2h4z9KW2bXtPr14t3v7W91rC302wvlpjW7_qGS21HjV_GV5MhKy8txN6ZW70Blxz3gzRrZW2Cv5N63TwXflW2x_nwb3MHm55W48xvjJ3xNqMvW1dcn_x4VG1WVN8WNmXdCm004N4bpFy7lSph1W8SLtvs66rNGxW3T1BvB4VDQLVVgt0Sc6prpbxN144K2lj_7qsW8rlNmZ17_BDKV1XTjx4B6G2cf3pn9Wd04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">barred</a>&nbsp;semiconductor suppliers AMD and Nvidia from selling advanced chips to Chinese firms. In November 2024, the U.S.&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fx3qgyTW95jsWP6lZ3p1Vp_65M7mVMbzW7JmjC44NNGYfW6V1qsk4GYs2TW3XV7-z7jN7JVW6Mj7Cc369srxW8gTQJQ3ctYY2W489v1B2x3kcpN6b83NH9qljqW1QRbBL5h6b-5W928dxM28mF-jW7pkf3g84tfWrW6T4rTR6QLHNVW7dLstK3LKp5MW6V9pGZ7M4czwW5Kvd3F8yBF5bW48RJrv7xhkd4W69wydQ839PjPW4CGYwJ3whs5-W6v1z-x3n_mRDN4sCz9Y9qtn5W6QRrLX38xVt1W12blFS29SVXCW4KV2KM3YMMfdW2JN7sJ8GzgJYW2Bs4Zz88qKTLN1Dk800YKvH3W1CHmQZ7Q1k-qW49qD0P8xSKl-W2Kf2RK2qm87KW5VXhll6Bd4YZf2pz3C-04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">tightened</a>&nbsp;restrictions further, ordering Taiwan Semiconductor Manufacturing Company, which fabricates those chips, to halt production of advanced chips destined for China.&nbsp;</p><p><strong>Plus green AI infrastructure:</strong>&nbsp;In addition, President Biden issued an executive order to encourage the rapid build-out of computing infrastructure for AI. The federal government will hold competitions among private companies to lease sites it owns for the building of data centers at private expense. The selection of sites will take into account availability of sources of clean energy, including support for nuclear energy. The government will expedite permitting on these sites and support development of energy transmission lines around them. It will also encourage international allies to invest in AI infrastructure powered by clean energy.</p><p><strong>Why it matters:&nbsp;</strong>Protecting the United States’ advantages in high tech has been a rising priority for the White House over the past decade.&nbsp;The earlier export restrictions forced many Chinese AI developers to rely on less-powerful hardware. The new limits are likely to have a far broader impact. They could force developers in the Tier 2 and Tier 3 countries to build less resource-intensive models and lead them to collaborate more closely with each other, reducing the value of U.S.-made technology worldwide. They could hurt U.S. chip vendors, which have&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dF3qgyTW7lCdLW6lZ3pjW2Gc-GB8D0XgnW3kQvhz8Bf__6N6y-6FNZRy73W6yRFn81Wg2wLN6M_4p0qfWsTW7jtm1g20C34kW7WXWTk1qksxgW453s0x8BSv8bW7RcFGM7LZjZsN3zQ78lZ5lrgW3D-GB28KjqJTVQGNNx6bxgZbW5TBk3S6RWNy6W5Q9F2J6zp5RNW3Rgvwt4_yMgcW1MTTkF9g4Xs3W1cJmj-7Rmz-qW7CDvdF48lMLrW6ZC9LM7zh59yV1_dRp5-4QJjN2wNFn-VKLpwW2BC6hd5FHhz0W7BKpdm2nGHmTW6yX-rf66GhpLf23wdZq04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">warned</a>&nbsp;that the rules could weaken U.S. competitiveness in the global economy. They could also force companies that are building huge data centers to process AI calculations to&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fd3qgyTW8wLKSR6lZ3kYV5Vvd03zNf7fVYZ1R42xZL4qW1M-2z08M_YHgN1F1dyFZw3MJW6XrfsY927FlGW8g1y7N4WVWbSW1qcfZ23TVykZW5dkm478TGnqsW6mpylD7yNFJqW12g6mn78jHX8W2t9GXZ4xKCRzW7yp45P1fQMSkW8S3LR63zd92BW7mf2gr489MCZW1f2bfV4CG_xnW7zZZMt5Q-Qt1VF0F8_5bNJK_W8TXP0z57pPCmW2ZYMgB7lSXQZW94jpCb1D-Gh3W2kqS247W9xmQN3ZHxm86hp4jW56bVqf81kZTwW84cwfc6FD8N1W5gf_c52M2815W1XLlbQ5kMCf6W6Lc3Z48RbLHdN6YXCPwr2-C_f9bD4Lz04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">reconsider</a>&nbsp;their plans.</p><p><strong>We’re thinking:</strong>&nbsp;The Biden administration’s embargo on AI chips has been&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fd3qgyTW8wLKSR6lZ3p_W1PS5bh78F7p_W8Kx7QG8ThxShN7ww4rR4_Kw2W1RHrr94DNGR3W6HLNH25WLq2DN5KfhHYPlt80W8CWXWz5Xw9bgMHtvxBN9tGyW1vyhGD1RxwCKVBSRxs8p_R3pW66qDPs5FCzwQN5fHnRZzyw58W76nQV265__0mW7Gnd1649-CJNV9Rmzb5_rMKVW3JwFbg44JpbHW6WBQgV54CMPFW6lzc-D8rjxCyW2rsfGn3Z1KxRW5BbK1817-QL-N8c5MJB1y8KyW5yNKjP484qn8W271l9r44swHvW4p6wz850RF_sW34jk_X3TbXl4W1YCCWS7B_MZFW1T54Hz2lgQZSN6C8C1ChWT9rf530b9F04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">leaky</a>. So far, it has slowed down adversaries only slightly while spurring significant investment in potential&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9fx3qgyTW95jsWP6lZ3kNN2qzzNQfggxxW7tSQvz51BQhLW2kSZM-4P99pqW5TS10S2WQdlZW8GMNhf11SKbnN7Dj6d1K5cV_W1-yDYQ2rJ-hgW3N751B3JjC8HVpvh3K3HnBH2W71gjZM51SQtTW2HgsL22mDYq0N2HlBb8mRc8CVX3vpB5_00NYW2MJvtZ8N79_LW1CrsHH6y5LvzW5y-qqK2p7_kpN3vjfHSyGQg1W9lxs3Q4wJ4lLW3Y99W14nPwBCW7tSlv-7jcvcbW3qxdpW7g9TbmW2lDQ7T3jwf2TW1DdHqV8xsJh9VY1CYP4CTM1gW2VvXrt4VTfcdW2ty9nx8J1NP7N8T3g6rYr6X1W66y-sb1NjhrzW6VqLLL4bBWCxW4DWjqL64GcFSf621CDl04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">suppliers</a>&nbsp;that aren’t connected to the U.S. While the public comment period invites lobbying and industry feedback, ultimately geopolitical priorities may hold sway. Whatever the outcome, reducing the world’s dependence on U.S. chips and models would result in a very different global AI ecosystem.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--47-.jpg\" class=\"kg-image\" alt=\"GB10 Superchip architecture with Blackwell GPU and Grace CPU.\" loading=\"lazy\" width=\"1200\" height=\"674\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/01/unnamed--47-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/01/unnamed--47-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--47-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"ai-supercomputer-on-your-desk\">AI Supercomputer on Your Desk</h1><p>Nvidia’s new desktop computer is built specifically to run large AI models.</p><p><strong>What’s new:</strong>&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dF3qgyTW7lCdLW6lZ3ngW6M9rtw1KpkCLW35nzTZ6kxhJZN92X3KDhcBCrW87x7xs3cC5lnW5h9Fdy5mfNL_W295Nnm8bb016W2WP-TP5KBrZvW20GzsJ5yR4szN447cpl-b_55N7LkW7QqnQnzW5yTTHt7zX7SPW6xqPW14K0t2TW8BJxrf8RNcS4W29XMn24zCDXbW43q1tK1gctl7W5SmzpW8Wh3zGW7GR2Jt46vnMVW7k8hXg87m1cnN2Jn2kfKFYV2W4gbK1d4ljfxzW8qlSBj6rk-JYW3-V1BC3SZd9WW3rXrPb19VkLfW1WZBB26_g00Ff5q8rVv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Project Digits</a>&nbsp;is a personal supercomputer intended to help developers fine-tune and run large models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000.</p><p><strong>How it works:</strong>&nbsp;Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available.&nbsp;</p><ul><li>Project Digits runs Nvidia’s DGX operating system, a flavor of Ubuntu Linux.</li><li>The system is based on a GB10 system-on-a-chip that combines the Nvidia Blackwell GPU architecture (which serves as the basis for its latest B100 GPUs) and Grace CPU architecture (designed to manage AI workloads in data centers), connected via high-bandwidth NVLink interconnect.</li><li>It comes with 128 GB of unified memory and 4 terabytes of solid-state storage.</li><li>The system connects to Nvidia’s DGX Cloud service to enable developers to deploy models from a local machine to cloud infrastructure.</li></ul><p><strong>Behind the news:&nbsp;</strong>In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines.</p><p><strong>We’re thinking:</strong>&nbsp;We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--44-.gif\" class=\"kg-image\" alt=\"X-CLR loss: training models to link text captions and image similarity.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2025/01/unnamed--44-.gif 600w\"></figure><h1 id=\"calibrating-contrast\">Calibrating Contrast</h1><p>Contrastive loss functions make it possible to produce good embeddings without labeled data. A twist on this idea makes even more useful embeddings.</p><p><strong>What’s new:</strong>&nbsp;Vlad Sobal and colleagues at Meta, New York University, Brown University, Genentech, and Canadian Institute for Advanced Research introduced&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3mWW6tCWFZ36sXDwW7xKj1y779ftbW7dfjH53wkc00W2tNBQM7LGMc7W7QxNcm4mqz1CW4XNZgG6tCLgCW6cc1hr3pf1h1W6rjkft4XkgD8Vd6V8H78wdBTW4WKNt26VM0P3W5DrsjK30p8vpN3yKJQ8nrZBQN4mFVDR8JLrKN275KpqV8N2-W2QjrnH7NjFM-W6gskM72BfqGfW89JqZn4ndX1YW21zr9v3XRwBnW8p-kJr4m5yw6N59WrMjX4sdZW2V-N4v5KN0tTW1BtCWt7-FPXnf5VdXlC04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">X-Sample contrastive loss</a>&nbsp;(X-CLR), a self-supervised loss function that enables vision models to learn embeddings that capture similarities and differences among examples with greater subtlety.</p><p><strong>Key insight:</strong>&nbsp;Contrastive loss functions like&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dY3qgyTW7Y8-PT6lZ3nJW5tHqMg2NgJR8N1MF24HjMd2pW2J_YJc68mX3KW7-pFM17SXh4cW2lhZYF8JnRcDW1hhK8d5LP1WbVbMXd1794dhhW17891P2S_B6cW6TysQt6lK0QqW8tgn7b3Z2DXRN76Jd8yq8Kd4W336nPh151bz5W7l5LDp4RzppjW6hpbrj5HYs24W5d836W38tX_5W357_Bs26gp7nN2CcldlFrcRFW4M6T8S5xhF36VKT4wq32WHG9W4kzF2t6d-56lN5WdlCvKfBSRVKc0KX2cB6gQW2dwD4r3gmN6pW95SZTk1NmSPWW7wb8cK8CTdTbW2J_b9_6tXkFqf6K3YjW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">SimCLR</a>&nbsp;equally encourage a model to produce dissimilar embeddings of images of, say, a cat, a dog, and a dump truck. But, of course, cats and dogs are more similar to each other than either are to dump trucks. Instead of marking examples as similar or dissimilar, X-CLR assigns similarity scores, so a model can learn to produce embeddings that match those scores.</p><p><strong>How it works:</strong>&nbsp;The authors used X-CLR to train an embedding model on <a href=\"https://aclanthology.org/P18-1238/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\">Conceptual Captions</a>&nbsp;datasets of image-text pairs scraped from the web: CC-3M (3 million text-image pairs) and CC-12M (12 million text-image pairs). The model was similar to&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3p9W2YWpm11btm6QW8sLYj48dXkxzW6qw1Ls6-NsZQW5-YLNx1Dx4r-W4kGG3D3ZQjmHN4Dj-WdVTX6XW8GH-j06RVSRNW3s3bQL4sCJG2W5bNNGQ5M8J9VW2lpgCm5M3v06W6vMvQt52RFXtW66M-y-69Pf22W7Ky3H_1Tnkz1W7JhBHN6KLxCYW8hm5D63qdtBZW2nTB2s5v-XYbW5HMn5Q64RNvCW2wXGc38DlFShW61q5Mb3v7gTDW3Qcgf66pG7PZW2HT3Dj4jQT05W3lVYKC96c4-Yf4CCNv004?ref=dl-staging-website.ghost.io\" rel=\"noopener\">CLIP</a>, except the text encoder was a&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3pvW3tn39X2jZxHDW7_m1R21GGJckW2gcm-x7h1LN2N3PXcgKMrFS_W8P-m154xzRX6W4SPCKT4jrTGBN5RDPq0lJ7XYW6KRNWr17Bc4CW92Fb9Q5yqV_cW63v7718_B0c4W979qrZ40WyZmW3Z2vmm8LN70wVFXBHV6874htW2GBcnr2LJM7tW8gQSq82-DyXCVxNrJ32p1tl_W1KbNW78SfBCrW2g5xjL9010jcV16TL74zHsTPW5rg3VR1b76wnW6xlPqn1QLpL4W6YKrbz8wsFKDf6t7HGq04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">sentence transformer</a>&nbsp;pretrained on sentence pairs, and the vision encoder was a&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3nSW6VkQb73rvBTvW4Sl-4f6g14cpW48LvVq8_tr4pW66Tc-X7l-JzqW62L1mn73v23gW7tQ_978bwSZnW4W6b7M4CF7L5VgqV9W9l7mhSW3fq9Jk5YZLn_W8NjZm22Wcp6gW3DyH_X5y3HGHW7ddYgM69Qp3LW2dZqkq6LBhS9W8mwWLK6Mb2KMW5qxMng3BKM1yN14NRY7TPH8TW20JMsD1YGg_TN15V18RhQnncW47M9QF6KntgFW8ZhpX35FMFrrN85xgM48H140W5sH_qL8-5xbBf6Vsg-C04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">ResNet-50</a>&nbsp;pretrained on ImageNet.</p><ul><li>The sentence transformer embedded text captions for all examples. The system computed similarity scores according to cosine similarity between the text embeddings.</li><li>Similarly, a ResNet-50 computed image embeddings, and the system computed similarity scores between them.</li><li>The authors froze the sentence transformer and used the text similarity scores as labels in the loss function. The loss function minimized the difference between the similarity scores of the text embeddings and the corresponding similarity scores of the image embeddings.</li></ul><p><strong>Results:</strong>&nbsp;Systems trained using X-CLR outperformed competitors in&nbsp;<a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDS5m4T6qf8W427Ds551gWLTW46ZLVZ5qSGfcN4xH9dl3qgyTW6N1vHY6lZ3nQW5K3gxh59yWZFMZMG96D_JCpW1rfrRQ29PdLvW90BRBM76bGS-W8pLpw81mPlF9W3xcrWx5t7vHJW6BdzNf2mW4kVN33Wbp6wYQKLW2vG1JK2SPD89N1l7zjCR8xqNW5YHlzN7Ztq1QW8CHvSP5btkWbW5gyHrD4YQgMqVdTB8x2BQf4wW6hRytT46--jSW8fk--S5pnP9LW2qL6Qm3sh8mSW3P7_xV2z4dhwN6j8sLLLxW2TW4lHVZW4m-tftW8nqJV8729zg-N8tlSfsl-tgmf3qsxWW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\">ImageNet</a>&nbsp;classification, especially when less training data was available. (The authors followed CLIP’s method of classification: They computed the similarity between an image embedding and text embeddings of all classes. The image’s classification was the class that corresponds to the text embedding with the highest similarity to the image embedding.)</p><ul><li>The authors compared a system trained using X-CLR, one trained using SimCLR, and CLIP. After training on the CC-3M dataset, the X-CLR system achieved 58.2 percent accuracy on ImageNet, while the SimCLR model achieved 57.0 percent and CLIP achieved 41.0 percent.</li><li>Training on CC-12M resulted in smaller differences: X-CLR achieved 59.4 percent accuracy, SimCLR achieved 58.9 percent, and CLIP achieved 58.8 percent.</li></ul><p><strong>Why it matters:</strong>&nbsp;Contrastive loss functions are very useful, but the similar/dissimilar dichotomy leaves important nuances unaccounted for. Like CLIP, X-CLR takes advantage of both images and their captions for self-supervised learning. However, CLIP learns to recognize image-text pairs as similar or dissimilar, while X-CLR matches image-image pairs using captions as a similarity signal that’s continuous rather than discrete.</p><p><strong>We’re thinking:&nbsp;</strong>Reality is not black and white. Allowing for shades of gray makes for better modeling.</p>","comment_id":"67883bc05ab5a20001e250b5","feature_image":"https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px.jpg","featured":true,"visibility":"public","created_at":"2025-01-15T14:50:40.000-08:00","updated_at":"2025-02-13T13:50:07.000-08:00","published_at":"2025-01-15T15:23:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"67891a455ab5a20001e25134","name":"Jan 15, 2025","slug":"jan-15-2025","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/jan-15-2025/"},{"id":"678843df5ab5a20001e250c3","name":"issue-284","slug":"issue-284","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-284/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-284/","excerpt":"The Batch AI News and Insights: Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can decide what to build. AI Product Management has a bright future!","reading_time":13,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Tumbling Training Costs, Desktop AI Supercomputer, Tighter AI Export Restrictions, and more...","meta_description":"The Batch AI News and Insights: Writing software, especially prototypes, is becoming cheaper. This will lead to increased demand for people who can...","email_subject":null,"frontmatter":null,"feature_image_alt":"Two colleagues discuss their chatbot’s success; one suggests hiring an AI Product Manager.","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2025/01/AIProductManager-2_1200px.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"AI is the new electricity","databaseId":29050,"id":"cG9zdDoyOTA1MA==","featuredImage":{"node":{"altText":"AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook.","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/resources/#ebooks","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}