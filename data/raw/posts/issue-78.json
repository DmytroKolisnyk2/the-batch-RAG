{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-78","id":"60bfddae274d5b003b1062fe","uuid":"4324b479-c666-404c-8fb9-4e730b9f862e","title":"The Batch: Drivers Under Surveillance, What Is Fairness?, Cancer Treatment, Vision Improves Language, Trade In Your Gucci","html":"<p><em>Dear friends,</em></p><p><em>Over the last several decades, driven by a multitude of benchmarks, supervised learning algorithms have become really good at achieving high accuracy on test datasets. As valuable as this is, unfortunately maximizing average test set accuracy isn’t always enough. </em><br><br><em>I’ve heard too many conversations like this:</em><br><em>Machine learning engineer: </em>It did well on the test set!<br><em>Product manager: </em>But it doesn’t work for my application.<br><em>Machine learning engineer: </em>But . . . It did well on the test set!</p><p><em>What else is there?</em><br><br><em><strong>Robustness and generalization:</strong> In a production deployment, performance can degrade due to concept drift (where the function mapping from x-&gt;y changes; say, the model predicts housing prices y and inflation causes prices to rise) and data drift (where the input distribution changes). One important subset of data drift relates to performance on classes that are rare in or absent from the training set. For example, a speech recognition system may achieve high average accuracy despite poor performance on speakers with a British accent, because the training and test sets included few examples of British speakers. If the product takes off in the U.K. and a lot more British speakers jump in, its accuracy will plummet. A more robust system would fare better.</em></p><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/Screen-Shot-2021-02-10-at-11.54.50-AM-copy.png\" class=\"kg-image\" alt=\"Speech bubble that says &quot;It did well on the test set!&quot;\" loading=\"lazy\"></figure><p><em><strong>Performance on relatively important examples:</strong> Some examples are more important than others, and even if average test set accuracy is high, a system that performs poorly on important examples may be unacceptable. For example, users might forgive a search engine that doesn’t always return the best results to informational and transactional queries like “apple pie recipe” or “wireless data plan.” But when they enter a navigational query such as “stanford,” “youtube,” or “reddit,” they have a specific website in mind, and the search engine had better return the right URL or risk losing the user’s trust. In theory, weighting test examples according to their importance can address this issue, but it doesn’t always work in practice. <br><br><strong>Performance on key slices of data:</strong> Say a machine learning system predicts whether a prospective borrower will repay a loan, so as to decide whether to approve applications. Even if average accuracy is high, if the system is disproportionately inaccurate on applications by a specific minority group, we would be foolhardy to blindly deploy it. While the need to avoid bias toward particular groups of people is widely discussed, this issue applies in contexts beyond fairness to individuals. For example, if an ecommerce site recommends products, we wouldn’t want it to recommend products from large sellers exclusively and never products from small sellers. In this example, poor performance on important slices of the data — such as one ethnicity or one class of seller — can make a system unacceptable despite high average accuracy. <br><br><strong>My advice:</strong> If a product manager tells us that our AI system doesn’t work in their application, let’s recognize that our job isn’t only to achieve high average test accuracy — our job is to solve the problem at hand. To achieve this, we may need visualizations, larger datasets, more robust algorithms, performance audits, deployment processes like human-in-the-loop, and other tools.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id=\"news\">News</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/CARCAM.gif\" class=\"kg-image\" alt=\"Netradyne Driveri system used to monitore Amazon's delivery drivers working\" loading=\"lazy\"></figure><h2 id=\"eyes-on-drivers\">Eyes On Drivers</h2><p>Amazon is monitoring its delivery drivers with in-vehicle cameras that alert supervisors to dangerous behavior.<br><br><strong>What’s new:</strong> The online retail giant rolled out a ceiling-mounted surveillance system that flags drivers who, say, read texts, fail to use seatbelts, exceed the speed limit, or ignore a stop sign, <a href=\"https://www.cnbc.com/2021/02/03/amazon-using-ai-equipped-cameras-in-delivery-vans.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\"><em>CNBC</em></a> reported.<br><br><strong>How it works:</strong> The system, Netradyne <a href=\"https://www.netradyne.com/driveri/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Driveri</a>, uses street-facing and in-cab cameras along with an accelerometer and gyroscope to spot 16 unsafe behaviors.</p><ul><li>When it detects an offending behavior, the system warns the driver and automatically uploads a video to Amazon.</li><li>Drivers can upload videos manually to document potentially problematic events such as a person approaching the vehicle or an inaccessible delivery location.</li><li>Netradyne said its system reduces collisions by two thirds, according to <em><a href=\"https://www.theverge.com/2021/2/3/22265031/amazon-netradyne-driveri-survelliance-cameras-delivery-monitor-packages?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">The Verge</a></em>.</li></ul><p><strong>Yes, but:</strong> Some Amazon drivers said that the system violates their privacy and exacerbates pressure to meet the company’s aggressive delivery schedules.<br><br><strong>Behind the news:</strong> Amazon has expanded its force of local delivery drivers to more than <a href=\"https://www.washingtonpost.com/technology/2020/11/27/amazon-shipping-competitive-threat/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">400,000</a> as of November. It has used a similar computer vision system from <a href=\"https://www.smartdrive.net/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">SmartDrive </a>to monitor its long-haul truckers for sleepiness and distraction. Delivery competitor United Parcel Service also has tested a system, <a href=\"https://www.lytx.com/en-us/fleet-management/drivecam?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Lytx DriveCam</a>, that monitors drivers of its delivery vans.<br><br><strong>Why it matters:</strong> Investigations by <a href=\"https://www.buzzfeednews.com/article/carolineodonovan/amazon-next-day-delivery-deaths?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\"><em>BuzzFeed</em></a> and the <em><a href=\"https://www.nytimes.com/2019/09/05/us/amazon-delivery-drivers-accidents.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">The New York Times</a></em> charge that Amazon pressures drivers to make deliveries at a dangerously fast clip, resulting in numerous accidents and several deaths. While in-car surveillance is intrusive, proponents point out that it might help reduce human errors that can occur when people are under stress.<br><br><strong>We’re thinking:</strong> There are many ways that AI can enhance productivity and safety. Let’s make sure to do it in a way that’s empowering rather than dehumanizing.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/VOKEN-1.gif\" class=\"kg-image\" alt=\"Graphs and data related to visualized tokens (or vokens) \" loading=\"lazy\"></figure><h2 id=\"better-language-through-vision\">Better Language Through Vision</h2><p>For children, associating a word with a picture that illustrates it helps them learn the word’s meaning. New research aims to do something similar for machine learning models.<br><br><strong>What’s new:</strong> Hao Tan and Mohit Bansal at University of North Carolina Chapel Hill improved a BERT model’s performance on some language tasks by training it on a large dataset of image-word pairs, which they call visualized tokens, or <a href=\"https://arxiv.org/abs/2010.06775?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">vokens</a>.<br><br><strong>Key insight:</strong> Images can illuminate word meanings, but current datasets that associate images with words have a small vocabulary relative to the corpuses typically used to train language models. However, these smaller datasets can be used to train a model to find correspondences between words and images. Then that model can find such pairings in separate, much larger datasets of images and words. The resulting pairings can help an established language model understand words better.<br><br><strong>How it works:</strong> The authors trained a system called the vokenizer to pair BERT-style tokens — generally individual words or characters — with related images. They used the resulting visualized tokens to train BERT to predict such pairings and fine-tuned it on various language tasks.</p><ul><li>The vokenizer comprised a pretrained <a href=\"https://arxiv.org/abs/1611.05431?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">ResNeXt-101</a> vision model and a pretrained BERT, each followed by a two-layer neural network that generated representations separately for input images and tokens. To train it, the authors split <a href=\"https://arxiv.org/abs/1405.0312?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">COCO</a>, which depicts roughly dozens of object types with captions, into token-image pairs, associating an image with every token in a given caption. They trained the vokenizer to predict pairings by encouraging it to make the distance between pairs of images and tokens larger than the distance between unpaired images and tokens.</li><li>To create a large number of token-image pairs, the vokenizer paired images in the <a href=\"https://visualgenome.org/static/paper/Visual_Genome.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Visual Genome</a>, which depicts millions of objects, with words from English Wikipedia. First it generated a representation for each image. Then, for each token, it used a nearest neighbor search to find the image whose representation was closest.</li><li>Using a separate <a href=\"https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">BERT</a> with an extra fully-connected layer, the authors removed some tokens from Wikipedia sentences at random. They pretrained the model to predict both the missing tokens and the image paired with each token. Then they fine-tuned the model on <a href=\"https://arxiv.org/abs/1804.07461?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">GLUE</a> (which includes several language understanding tasks), <a href=\"https://arxiv.org/abs/1606.05250?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">SQuAD</a> (question answering), and <a href=\"https://arxiv.org/abs/1808.05326?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">SWAG</a> (language reasoning).</li></ul><p><strong>Results:</strong> BERT pretrained with the token-image pairs outperformed the same architecture trained in the same way but without the pairs on tasks in GLUE, SQuAD, and SWAG. For instance, it achieved 92.2 percent accuracy on <a href=\"https://www.kaggle.com/atulanandjha/stanford-sentiment-treebank-v2-sst2?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">SST2</a>, predicting the sentiment of movie reviews, compared to 89.3 percent for BERT without visual training. Similarly, on <a href=\"https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">SQuAD v1.1</a>, it achieved an F1 score of .867 on SQuAD compared to .853 for BERT without visual training.<br><br><strong>Why it matters:</strong> This work suggests the potential of visual learning to improve even best language models.<br><br><strong>We’re thinking:</strong> If associating words with images helps a model learn word meaning, why not sounds? Sonic tokens — sokens! — would pair, say, “horn” with the tone of a trumpet and “cat” with the sound of a meow.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/ezgif.com-gif-maker-97.gif\" class=\"kg-image\" alt=\"Scale of justice symbol over a map of India\" loading=\"lazy\"></figure><h2 id=\"fairness-east-and-west\">Fairness East and West</h2><p>Western governments and institutions struggling to formulate principles of algorithmic fairness tend to focus on issues like race and gender. A new study of AI in India found a different set of key issues.<br><br><strong>What’s new:</strong> Researchers at Google <a href=\"https://research.google/pubs/pub50002/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">interviewed</a> dozens of activists, academic experts, and legal authorities about the ways AI is deployed in India, especially with respect to marginalized groups. In part, their goal was to demonstrate how Western notions of bias and power don’t always apply directly to other cultures.<br><br><strong>What they found:</strong> The report highlights three ways in which issues surrounding AI in India differ from Western countries and may call for different approaches to achieve fairness.</p><ul><li><strong>Dataset bias:</strong> Half the Indian population lacks access to the internet — especially women and rural residents — so datasets compiled from online sources often exclude large swathes of society. Fixing the problem goes beyond data engineering. It requires a comprehensive approach that includes bringing marginalized communities into the digital realm.</li><li><strong>Civil rights:</strong> Many Indian citizens are subjected to intrusive AI, unwillingly or unwittingly. For example, some cities use AI to track the operational efficiency of sanitation workers, many of whom come from lower-caste groups. To address perceived abuses, Westerners typically appeal to courts, journalists, or activists. Many Indians, though, perceive such avenues to be largely unavailable.</li><li><strong>Technocracy:</strong> India is <a href=\"https://indiaai.gov.in/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">eager to modernize</a>, which motivates politicians and journalists to embrace AI initiatives uncritically. Compared with Western countries, fewer people in positions of power are qualified to assess such initiatives — a prerequisite to making their fairness a priority.</li></ul><p><strong>Behind the news:</strong> Other groups have sought to highlight the outsized influence that Western notions of ethics have on AI worldwide.</p><ul><li>The <a href=\"https://montrealethics.ai/research-summary-classical-ethics-in-a-is/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">IEEE Standards Association</a> recently investigated how applying Buddhist, Ubuntu, and Shinto-inspired ethics could improve responsible AI.</li><li>A 2019 study looked at how responsible AI guidelines should accommodate the massive influx of people who are newly online, many of whom live in countries like <a href=\"https://interactions.acm.org/archive/view/january-february-2019/toward-responsible-ai-for-the-next-billion-users?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Brazil, India, and Nigeria</a>.</li><li>A report published last year examined the social implications of AI in <a href=\"https://www.tandfonline.com/doi/abs/10.1080/13183222.2019.1589249?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">China and Korea</a>.</li></ul><p><strong>Why it matters:</strong> Most research into AI fairness comes from a U.S.-centric perspective rooted in laws such as the Civil Rights Act of 1964, which outlaws discrimination based on race, sex, and religion. Guidelines based on a single country’s experience are bound to fall short elsewhere and may even be harmful.<br><br><strong>We’re thinking:</strong> Many former colonies struggle with legal and educational systems imposed by Western powers. It’s important to avoid repeating similar patterns with AI systems.</p><hr><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM <a href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\">DEEPLEARNING.AI</a></h2><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/The-Batch-Image-1024x576.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Level up your AI career with our new event series, <em>AI Access</em>! Join us for “Integrating Design and Technical Innovation in AI-First Products” with Patrick Hebron, director of Adobe’s Machine Intelligence Design group. Patrick will offer a sneak peek at ways AI will transform creative tools and workflows. <a href=\"https://aiaccess219.eventbrite.com/?aff=batch&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">RSVP</a></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/RECEPTORNET.gif\" class=\"kg-image\" alt=\"Series of images and graphs related to cancer detection\" loading=\"lazy\"></figure><h2 id=\"shortcut-to-cancer-treatment\">Shortcut to Cancer Treatment</h2><p>Doctors who treat breast cancer typically use a quick, inexpensive tumor-tissue stain test to diagnose the illness and a slower, more costly one to determine treatment. A new neural network could help doctors to go straight from diagnosis to treatment.<br><br><strong>What’s new:</strong> The stain in the test for treatment highlights a key visual clue to the choice of therapy that’s otherwise invisible to human pathologists. Nikhil Naik at Salesforce and colleagues at University of Southern California built <a href=\"https://www.nature.com/articles/s41467-020-19334-3?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">ReceptorNet</a> to detect that clue in the diagnostic test.<br><br><strong>Key insight:</strong> The presence of estrogen receptor proteins is a sign that hormone therapy may work. In the diagnostic test, known as hematoxylin and eosin (H&amp;E), these proteins are invisible to the human eye. An attention mechanism, which identifies the most important parts of an input (in this case, a portion of an H&amp;E slide) in determining the output (a label that the proteins are present), can aggregate image areas where they occur so a vision network can classify the slide.<br><br><strong>How it works:</strong> ReceptorNet comprises a <a href=\"https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">ResNet-50</a> pretrained on <a href=\"https://arxiv.org/abs/1409.0575?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">ImageNet</a> followed by an attention layer and a fully connected layer. The researchers trained and tested ReceptorNet on images of H&amp;E slides, and augmentations of them, in the <a href=\"https://www.abctb.org.au/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Australian Breast Cancer Tissue Bank</a> and <a href=\"https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">The Cancer Genome Atlas</a> datasets.</p><ul><li>The authors isolated the images’ foreground using <a href=\"https://cw.fel.cvut.cz/wiki/_media/courses/a6m33bio/otsu.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Otsu’s method</a>, which distinguishes foreground from background based on variance in each pixel’s grayscale value, to remove background regions. They magnified the foregrounds 20 times and divided them into tiles of 256×256 pixels.</li><li>During training, they fed ReceptorNet 50 randomly sampled tiles per slide. The ResNet extracted representations of each tile and passed them <em>en masse</em> to the attention layer, which weighted their importance. The fully connected layer used the weighted representations to classify slides according to whether they contain estrogen receptors.</li><li>To combat overfitting, the authors used mean pixel regularization, randomly replacing 75 percent of tiles with a single-color image of the dataset’s mean pixel value.</li></ul><p><strong>Results:</strong> ReceptorNet achieved an area under the curve of 0.92 AUC, a measure of true versus false positives where 1 is a perfect score. The authors experimented with alternatives to the attention layer that didn’t perform as well, which suggests that attention was key. <br><br><strong>Yes, but:</strong> The authors had access only to H&amp;E images, so they couldn’t compare ReceptorNet’s performance against the test that’s typically used to guide treatment.<br><br><strong>Why it matters:</strong> ReceptorNet had a label for each tissue slide but not for each tile derived from it. The success of attention in aggregating and evaluating the representations extracted from each tile bodes well for this approach in reading medical images.<br><br><strong>We’re thinking:</strong> Where else could computer vision augment or replace slow, expensive medical tests?</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/ezgif.com-gif-maker-100.gif\" class=\"kg-image\" alt=\"Rebag app working on a cellphone\" loading=\"lazy\"></figure><h2 id=\"how-much-for-that-vintage-gucci\">How Much For That Vintage Gucci?</h2><p>Computer vision is helping people resell their used designer handbags.<br><br><strong>What’s new:</strong> Rebag, a resale company for luxury handbags, watches, and jewelry, launched Clair AI, an app that automatically appraises second-hand bags from brands like Gucci, Hermes, and Prada, <em><a href=\"https://www.vogue.com/article/rebag-launches-clair-ai-image-recognition-tool?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">Vogue</a></em> reported.<br><br><strong>How it works:</strong> Users take a close-up picture of a handbag against a neutral background. The app finds between one and five potential matches for designer, model, and style.</p><ul><li>Users choose the potential match that comes closest and adds details about the used bag’s condition and color. The system then calculates dollar figures for retail price and trade-in value.</li><li>Users can also submit photos of bags in magazines, videos, or other fashionista’s hands to find out what other people are carrying.</li><li>Rebag’s CEO said in a promotional <a href=\"https://youtu.be/xSuNSNFtG-g?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">video</a> that the app achieved 90 percent accuracy rate and took six years and millions of data points to develop.</li></ul><p><strong>Behind the news:</strong> Rebag’s revenue grew by 50 percent in 2020, riding a surge in demand for second-hand luxury goods. The market for used high-end items like watches, jewelry, fine art, and yachts grew in 2019 by <a href=\"https://luxe.digital/business/digital-luxury-reports/luxury-resale-transformation/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">12 percent </a>to <a href=\"https://www.bain.com/insights/luxury-goods-worldwide-market-study-fall-winter-2018/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">$26.5 billion</a>.<br><br><strong>Why it matters:</strong> Consumers are <a href=\"https://retailtouchpoints.com/features/trend-watch/second-hand-luxury-goods-not-an-oxymoron-but-a-6-billion-opportunity?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9FTvZU6MsOYOZ6A0SicaC9wqGaBBI4GuTj1xlHH0dHQgJnq2bVK_PhEOoKyMp03PG0IITd\" rel=\"noreferrer noopener\">mindful</a> of the resale value of high-ticket goods. An app that makes it easier to tap into that market could drive sales of both new and used items — and make it easy to unload the hideous thing that somehow looked fetching last summer.<br><br><strong>We’re thinking:</strong> We tested this system on the bags in our closet, but it wasn’t impressed by our prized NeurIPS tote.<br></p>","comment_id":"60bfcc5c274d5b003b1060df","feature_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-02-10-at-11.png","featured":false,"visibility":"public","created_at":"2021-06-08T13:00:28.000-07:00","updated_at":"2022-10-06T11:53:29.000-07:00","published_at":"2021-02-10T12:00:00.000-08:00","custom_excerpt":"Over the last several decades, driven by a multitude of benchmarks, supervised learning algorithms have become really good at achieving high accuracy on test datasets. As valuable as this is...","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"60bfddad274d5b003b1062c0","name":"issue-78","slug":"issue-78","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-78/"},{"id":"60cc1e8470a082003e13dd17","name":"Feb 10, 2021","slug":"feb-10-2021","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/feb-10-2021/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-78/","excerpt":"Over the last several decades, driven by a multitude of benchmarks, supervised learning algorithms have become really good at achieving high accuracy on test datasets. As valuable as this is...","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Drivers Under Surveillance, What Is Fairness?, Cancer Treatment","meta_description":"The Batch - AI News & Insights: Amazon is monitoring its delivery drivers with in-vehicle cameras that alert supervisors to dangerous behavior...","email_subject":null,"frontmatter":null,"feature_image_alt":"Speech bubble that says \"It did well on the test set!\"","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-02-10-at-11.png","dimensions":{"width":576,"height":324}},"banner":{"title":"AI Python for Beginners","databaseId":35163,"id":"cG9zdDozNTE2Mw==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/1-9.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YX9G3n","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}