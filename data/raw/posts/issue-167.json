{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-167","id":"634f0e72be967a003dce2467","uuid":"7b87c533-6a94-4202-a7b0-8d9b31002eb6","title":"The Batch: U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually), Massively Multilingual Translation, Smart Farms","html":"<p><em>Dear friends, </em><br><br><em>Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI? With the rise of text generators such as GPT-3 and Jurassic and image generators such as DALL·E, Midjourney, and Stable Diffusion, which take text input and produce output to match, there has been growing interest in how to craft prompts to get the output you want. For example, when generating an image of a panda, how does adding an adjective such as “beautiful” or a phrase like “trending on <a href=\"https://www.artstation.com/?sort_by=community&ref=dl-staging-website.ghost.io\">artstation</a>” influence the output? The response to a particular prompt can be hard to predict and varies from system to system.</em></p><p><em>So is prompt engineering an important direction for AI, or is it a hack?</em></p><p><em>Here’s how we got to this point:</em></p><ul><li><em>The availability of large amounts of text or text-image data enabled researchers to train text-to-text or text-to-image models.</em></li><li><em>Because of this, our models expect text as input.</em></li><li><em>So many people have started experimenting with more sophisticated prompts.</em></li></ul><p><em>Some people have predicted that prompt engineering jobs would be plentiful in the future. I do believe that text prompts will be an important way to tell machines what we want — after all, they’re a dominant way to tell other humans what we want. But I think that prompt engineering will be only a small piece of the puzzle, and breathless predictions about <a href=\"https://medium.com/nerd-for-tech/prompt-engineering-the-career-of-future-2fb93f90f117?ref=dl-staging-website.ghost.io\">the rise of professional prompt engineers</a> are missing the full picture.</em></p><p><em>Just as a TV has switches that allow you to precisely control the brightness and contrast of the image — which is more convenient than trying to use language to describe the image quality you want — I look forward to a user interface (UI) that enables us to tell computers what we want in a more intuitive and controllable way.</em></p><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2--1.jpg\" class=\"kg-image\" alt=\"Illustration of Andrew Ng on a computer searching for &quot;Panda bear&quot; and getting a Paddington instead\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/unnamed--2--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/unnamed--2--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2--1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p><em>Take speech synthesis (also called text-to-speech). Researchers have developed systems that allow users to specify which part of a sentence should be spoken with what emotion. Virtual knobs allow you to dial up or down the degree of different emotions. This provides fine control over the output that would be difficult to express in language. By examining an output and then fine-tuning the controls, you can iteratively improve the output until you get the effect you want.</em></p><p><em>So, while I expect text prompts to remain an important part of how we communicate with image generators, I look forward to more efficient and understandable ways for us to control their output. For example, could a set of virtual knobs enable you to generate an image that is 30 percent in the style of Studio Ghibli and 70 percent the style of Disney? Drawing sketches is another good way to communicate, and I’m excited by <a href=\"https://huggingface.co/spaces/fffiloni/stable-diffusion-color-sketch?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--gi3MRLgMq231cJCbVhy_KlPOqT6dwzcRwTNEM6D9A0LSVcWODttwPI95II3mrGZn2FnYnjHNu2FBM3AVMs4nCdAM5ApDQrBVQlFW8QJG1BFRQs18&utm_content=2&utm_source=hs_email\">img-to-img</a> UIs that help turn a sketch into a drawing.</em></p><p><em>Likewise, controlling large language models remains an important problem. If you want to generate empathetic, concise, or some other type of prose, is there an easier way than searching (sometimes haphazardly) among different prompts until you chance upon a good one?</em></p><p><em>When I’m just playing with these models, I find prompt engineering a creative and fun activity; but when I’m trying to get to a specific result, I find it frustratingly opaque. Text prompts are good at specifying a loose concept such as “a picture of a panda eating bamboo,” but new UIs will make it easier to get the results we want. And this will help open up generative algorithms to even more applications; say, text editors that can adjust a piece of writing to a specific style, or graphics editors that can make images that look a certain way.</em></p><p><em>Lots of exciting research ahead! I look forward to UIs that complement writing text prompts.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id=\"news\">News</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2022/10/CHIPS.jpg\" class=\"kg-image\" alt=\"Shot of Computer Processor Production Line at Advanced Semiconductor Foundry in Bright Environment\" loading=\"lazy\" width=\"2000\" height=\"1125\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/CHIPS.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/CHIPS.jpg 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2022/10/CHIPS.jpg 1600w, https://dl-staging-website.ghost.io/content/images/size/w2400/2022/10/CHIPS.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"ai-chips-spark-international-tension\">AI Chips Spark International Tension</h1><p>New U.S. restrictions on chip sales aim to hamper China’s AI efforts.</p><p><strong>What’s new:</strong> The U.S. government <a href=\"https://www.federalregister.gov/documents/2022/10/13/2022-21658/implementation-of-additional-export-controls-certain-advanced-computing-and-semiconductor?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_MBaJXD7glmkayjRjT7zdSY7uczHVO9hFYit7jG2j-1NVaSu-nwz84skkeHBC8Huu_yIsmCMfeG942gFw3cnxBTIZroMjgTKrWsl7b3WorDiKm_gQ&utm_content=2&utm_source=hs_email\">published</a> sweeping limits on sales of processors that involve U.S. designs and technology to Chinese businesses. U.S. officials <a href=\"https://www.nytimes.com/2022/10/07/business/economy/biden-chip-technology.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8imCFA70ZSL2pQ8YC4-65Y555FPewFc8zON8hPoN3gCX_feqAaWxnDs0s1DrlxVmHRnwsRPZTM8BHU5HsAyzFKjYSIv9W0GVFOGpDTdYyFyW6kA4A&utm_content=2&utm_source=hs_email\">stated</a> that the restrictions are meant to prevent China from militarizing AI.</p><p><strong>New rules:</strong> The rules block sales of certain processors as well as U.S.-made equipment used to design and manufacture them. This includes high-end graphics processing units (GPUs) and other processors optimized for machine learning.</p><ul><li>The rules apply to chips capable of processing and interconnection speeds on par with Nvidia’s flagship <a href=\"https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--jMG1OxWVbW-1u_5pmvL5dREIi_Zv_CiFA1EbjNUEzz2A_bbpoCE7ylaXOR4vBJTuuvPP7DRrFvgdrcVlCDdQpWF6bf8vLg6OO3XYC8Jsszz2mMBA&utm_content=2&utm_source=hs_email\">A100</a> GPU, which is designed to be used in data centers. (Nvidia <a href=\"https://www.barchart.com/story/news/10006245/u-s-ramps-up-restrictions-on-chinese-tech?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_TBZOM4yvKTGcOdHiLWsBs_QFrEGMq2hNxtP3oQDIZslQnvibBMM3FuTlhe8tctpii4E6AiqKE403ZMFyrOAOLlE9KFTHPURJLozXhS0U1t3_3WHo&utm_content=2&utm_source=hs_email\">supplies</a> 95 percent of China’s AI chips.) The less-capable chips typically found in personal computers and video game consoles are not restricted.</li><li>The restrictions prohibit sales to Chinese companies of advanced chips produced using U.S.-made software and hardware as well as sales of the equipment itself. This goes for companies anywhere in the world.</li><li>They also bar U.S. citizens and permanent residents from supporting development or manufacturing of advanced chips without permission from the U.S. government.</li></ul><p><strong>China’s response:</strong> A spokesperson for China’s foreign ministry <a href=\"https://www.fmprc.gov.cn/mfa_eng/xwfw_665399/s2510_665401/2511_665403/202210/t20221008_10779756.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9CSbX4gywNI-B_JykPxmJtEfUb6ZaSfhWgcf9xJUWCQgcv3mD5QhmVuPaDCy_jTG88wjsgRX5EfAjyPIdqR0gsalMG1fW6WHmKLKxKPC1GMgn2Woo&utm_content=2&utm_source=hs_email\">accused</a> the U.S. of abusing export-control measures to target Chinese firms, stating that it would hinder global cooperation and supply chains.<br><br><strong>Behind the news:</strong> The restrictions initially came to light in September, when Nvidia and AMD independently <a href=\"https://www.deeplearning.ai/the-batch/gpu-china/?ref=dl-staging-website.ghost.io\">alerted</a> shareholders that the U.S. had imposed controls on their most advanced products. However, their details became publicly available only last week. They represent a significant escalation of earlier U.S. efforts to thwart China’s ambitions in advanced technology.</p><ul><li>In May 2020, the U.S. <a href=\"https://www.theverge.com/2020/5/15/21259814/us-commerce-huawei-chip-manufacturers-5g?_hsmi=2&_hsenc=p2ANqtz--3RSBQBM4SfKt7ARFSwSQri9jUaDU98wDEJ6iGuP8DtYlL9ooElIDFkklmKMQLA0YJz8xs4NjMNka1t065VtWId2e42jPfNd3Fh1cgzcU_DHWt00U&ref=dl-staging-website.ghost.io\">required</a> foreign chipmakers that use U.S. equipment to obtain permission to do business with the Chinese tech giant Huawei.</li><li>In 2019, the government <a href=\"https://www.theverge.com/2019/5/15/18216988/white-house-huawei-china-equipment-ban-trump-executive-order?_hsmi=2&_hsenc=p2ANqtz--25nb-92mQA2V-r5FGRNOjiCwwz0vaYCxCRvV5clXHuOFzd2WsEtJV5LKb-_ZZIepWKpK5vf5TRDlRaq5ZKS4gKJNh_igxQvrVw6uDOxKycKBP_vM&ref=dl-staging-website.ghost.io\">blocked</a> U.S. firms from selling equipment to Huawei and 114 of its affiliates.</li><li>In 2015, the country <a href=\"https://www.pcworld.com/article/426879/us-blocks-intel-from-selling-xeon-chips-to-chinese-supercomputer-projects.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8tvA67B8Tx0-lIZkL6JBUBy6gzCPWoHV2cx6BIBCpe5RaXVnVozwj7IEneuT35pFJI2pLB3UDkVdhNhlo9pUWbTA2YlzjIBJ9PVtary-WG1tnAR9w&utm_content=2&utm_source=hs_email\">barred</a> Intel from selling high-end chips to the Chinese military.</li></ul><p><strong>Why it matters:</strong> China has announced its <a href=\"https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_xtAENFKAea8iV9eeCpaMrDZNqOQzzVsDyJQ-2idSXg-svONQ8NRAqQqKPfGkj_2SKOFEqDirO0SMX23WZubcK3Z6q3IDphhwCDMrEdR4D3Ui-fCw&utm_content=2&utm_source=hs_email\">ambition</a> to become the global leader in AI by 2030, and this requires access to cutting-edge processing power. The most advanced chips are manufactured in Taiwan and South Korea using chip-fabrication equipment made by U.S. companies, and the leading chip designers and makers of chip-design software reside in the U.S. This gives U.S. authorities a tight grip on other countries’ ability to buy and make chips. China’s effort to build domestic capacity to produce advanced semiconductors — which are hampered by the sheer difficulty and expense of etching features on silicon measured in nanometers  — now faces additional hardware, software, business, and talent hurdles.</p><p><strong>We’re thinking:</strong> International cooperation has been essential to recent progress in AI. As barriers rise between the U.S. and China, the AI community must navigate a world where geography will have a much bigger impact on access to ideas and resources.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--4-.gif\" class=\"kg-image\" alt=\"Series of images showing different AI tools for farmers \" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--4-.gif 600w\"></figure><h1 id=\"smarts-for-farms\">Smarts for Farms</h1><p>The next green revolution may be happening in the server room.</p><p><strong>What’s new:</strong> Microsoft <a href=\"https://blogs.microsoft.com/ai/microsoft-open-sources-its-farm-of-the-future-toolkit/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--IWjT_hBZRv52ENBdOKwOJsWN6UT2CP-IWWDyCO7WDEA_l2Bi0KDoLuqdEKafu4H7OgFIrNC7uTwXo9yhZ4fBnbcQD2KbtN_eg34NlL9dVoQ2Snm0&utm_content=2&utm_source=hs_email\">open-sourced</a> a set of AI tools designed to help farmers cut costs and improve yields.</p><p><strong>How it works:</strong> <a href=\"https://github.com/microsoft/farmvibes-ai?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8kwvUlR3XvM0naUHcS4boU6Ka5Me7AkON1FQ4HeXopHpmshY1ncuRMmiDnOH2jRqtaHTP2xTQYkd_m9AjFAF9thZNoLtpha0mBgDG3536GPyq0jg0&utm_content=2&utm_source=hs_email\">FarmVibes-AI</a> includes systems that analyze overhead imagery and sensor data to guide farm operations.</p><ul><li><a href=\"https://www.microsoft.com/en-us/research/publication/democratizing-data-driven-agriculture-using-affordable-hardware/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_B8AMjgYviZIU26lpiZP58faXBvUbi8qhNZcEJ2j5no1B9-0_F7GiPlaaNxDQ9Ax_sXFQmT1f0VJWxb4BQd9dYi_bKwcTXBLsKkAF7XQUxerQdluA&utm_content=2&utm_source=hs_email\">AsyncFusion</a> uses drone imagery, satellite imagery, and data from soil sensors to map soil conditions in real time. Farmers can use the output to plan where and when they should plant their fields.</li><li><a href=\"https://www.microsoft.com/en-us/research/publication/micro-climate-prediction-multi-scale-encoder-decoder-based-deep-learning-framework/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9CxHIxcVjetbie-netuNl_6UpQMrPfwjvtNa7L_w4zpExKBUOybywAv7VPXMV6VsXmHtefESADfFDkZgKGvx5Ym9h_OYtfIGwJEZqWOkC2rrhrUWE&utm_content=2&utm_source=hs_email\">DeepMC</a> is a neural network that combines data from soil sensors, climate sensors, and weather predictions to forecast field temperature, precipitation, and soil moisture up to 120 hours ahead. Its output can enable farmers to prepare for extreme temperatures and other events.</li><li><a href=\"https://arxiv.org/abs/2106.08408?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_xrO97qfmPDL-Y7qinZUWpXtioxzR72g8eIlIvivzCt3n6QgOO0IbTid953JR3M_H41oFOk-9itdb1aYthETJMb8w4rtLi1KObW3RxTBmYgpF-Cb8&utm_content=2&utm_source=hs_email\">SpaceEye</a>, another neural network, filters clouds from satellite imagery for use by AsyncFusion and DeepMC. Microsoft engineers trained the network via an adversarial method using infrared and visible-light images partly covered with synthetic clouds.</li></ul><p><strong>Behind the news:</strong> Nonprofits and academic institutions provide other open-source AI systems to increase food production in collaboration with large agribusiness firms, independent farmers, and rural communities.</p><ul><li>Last year, the Linux Foundation <a href=\"https://agstack.org/news/the-linux-foundation-launches-agstack-an-open-source-digital-infrastructure-project-for-agriculture-to-enable-a-global-collaboration-of-industry-government-and-academia/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8m8POjv1pqUoC5Kh2peyTBug3KsXlzymx-AmygBxcrse5z5FyoF01xin6XaHdYPcNffRwIYXLSFvHfOayKsIof3jGFShrEJUls_yWFF7haPyHF_fA&utm_content=2&utm_source=hs_email\">launched</a> Agstack, a partnership among universities, nonprofits, and IBM. The effort provides code, data, and frameworks to developers of open-source AI projects for agriculture.</li><li>MIT’s now-defunct <a href=\"https://www.media.mit.edu/groups/open-agriculture-openag/overview/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9fPkd0uFkDrOM2fJNxqZsGXuuAkz7kzZ40sDYxP2e7T7JN6ji_FPlvHa1K6iIaFIDnhoC96vw8kzKad7ewd3pwycLVoTomp6Il49viDRNoqXexB-8&utm_content=2&utm_source=hs_email\">OpenAg</a> included <a href=\"https://evolution.ml/cases/openag/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--irFTxhVsLh176LT2dzohow6T-1esoLkvvCy_w2uhJtdaVitxS3bG78sTTv-7C9pH5hL57vkRT58I1OD1fjtl-xhOz5CsnfGTcs63cxBMZk4ytfIg&utm_content=2&utm_source=hs_email\">models</a> that predicted how plants would grow under various environmental conditions.</li></ul><p><strong>Why it matters:</strong> The emerging practice of <a href=\"https://ispag.org/about/definition?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_EG-queNAOJNyroQk_NunSFz3oRKgs1-Mtts8HsThYrSEv3mUmrojgFNlmrfVtuU9mWWvMoqK4V69osAe8Q9ccK4e2oDbaaMDRDj9TAHaiX60bm4E&utm_content=2&utm_source=hs_email\">precision agriculture</a>, which seeks to take into account not only entire fields but also local conditions down to the level of individual plants, could help farmers sow seeds, grow crops, fight pests, and harvest produce more efficiently. Off-the-shelf systems may not serve farmers who work in different parts of the world or grow niche crops. Open-source projects can expand their options effectively and inexpensively.</p><p><strong>We’re thinking:</strong> Farmers tend to welcome innovations that improve yields and cut costs. They’re also famously self-sufficient, performing repairs and installing upgrades to their equipment. As self-driving tractors and precision-ag systems take root, they’re great candidates to become early adopters of industry-focused <a href=\"https://www.deeplearning.ai/the-batch/coding-ai-is-the-new-literacy/?ref=dl-staging-website.ghost.io\">platforms</a> that make it easy for anyone to build useful AI applications.</p><hr><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM <strong><a href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\">DEEPLEARNING.AI</a></strong></h2><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2022/10/MLS-TheBatch-ad.png\" class=\"kg-image\" alt=\"Machine Learning Specialization banner ad\" loading=\"lazy\" width=\"2000\" height=\"1047\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/MLS-TheBatch-ad.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/MLS-TheBatch-ad.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2022/10/MLS-TheBatch-ad.png 1600w, https://dl-staging-website.ghost.io/content/images/size/w2400/2022/10/MLS-TheBatch-ad.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Looking for a career that inspires you? Break into AI! </strong>The <em>Machine Learning Specialization</em> teaches foundational AI concepts through an intuitive visual approach. This beginner-friendly program, created by Andrew Ng and Stanford Online, makes it easier than ever to start your AI career. <a href=\"https://www.deeplearning.ai/courses/machine-learning-specialization/?ref=dl-staging-website.ghost.io\" rel=\"noopener\">Learn more</a></p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2022/10/ROGAN.jpg\" class=\"kg-image\" alt=\"AI-generated image of Joe Rogan interviewing Steve Jobs\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/ROGAN.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/ROGAN.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/ROGAN.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"all-synthetic-all-the-time\">All Synthetic, All the Time</h1><p>Joe Rogan meets Steve Jobs in an AI-generated podcast.</p><p><strong>What’s new:</strong> For the debut episode of a new podcast series, Play.ht synthesized a 19-minute interview between the rock-star podcaster and late Apple CEO. You can hear it <a href=\"https://podcast.ai/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8vwWIsI1L8w_xCxcGrfR9kpKsp0OdvcEuHJXpjiRpl6LNFzYw1zz1WVaPLR5s63Ffo9ZFPEvrr3ChVJPd_LG9RxuzC33BwrocGA2L2NuDPxXit4yU&utm_content=2&utm_source=hs_email\">here</a> and propose computer-generated participants in future episodes <a href=\"https://podcastio.canny.io/episode-ideas?_hsenc=p2ANqtz-8h7Qcy0VO3isHogRLNL1V871yywAZejhOmTHmWRpO-zViUnV_9CY9vl1UitfpQWT-cK3ESsqL40o1hx9CBqAgznUhAxMs3sA_unEMnBxQkjEIwJ6c&_hsmi=2&utm_campaign=The+Batch&utm_content=2&utm_medium=email&utm_source=hs_email\">here</a>.</p><p><strong>How it works:</strong> The Dubai-based startup created the episode using text generation and voice cloning.</p><ul><li>Play.ht generated the script using an unnamed natural language model that it fine-tuned on Jobs’ biography, interviews, and other sources.</li><li>It rendered the transcript into audio using proprietary synthetic voices trained on audio recordings of each speaker. Play.ht’s voice editor <a href=\"https://play.ht/text-to-ai-voice-editor/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9EYQ3fnCEvwlcQjqd7f_s7hzpRo9bEorHx2026ZKWKQpZR6_NDc5B_d_iVypMArNSbt08CuQwwsjpJJyNFScIYbiKHsmgkAQWRiDtrhC0FMmSourI&utm_content=2&utm_source=hs_email\">synthesizes</a> voices in over 120 languages with phonetic control over pronunciation.</li><li>The production is the first in a series called Podcast.ai. The public can <a href=\"https://podcastio.canny.io/episode-ideas?_hsenc=p2ANqtz-8DLmK9FwR9Qp-R2yVvUxYCXuASuOm835szsAC4s8ZavpTQxGpSush7vRsq5sAHGqKvcCK-tAvMkPBwpS1eyi1pqmDmyae8fU31NZreXIlgyj7_UwY&_hsmi=2&utm_campaign=The+Batch&utm_content=2&utm_medium=email&utm_source=hs_email\">propose</a> meetings of the virtual minds for future episodes.</li></ul><p><strong>Behind the news:</strong> Rogan was also the subject of an early experiment in voice cloning. In 2019, Toronto-based Dessa <a href=\"https://www.deeplearning.ai/the-batch/issue-vi/?ref=dl-staging-website.ghost.io\">released</a> ersatz Rogan audio clips — the first of a parade of fake celebrity voices.</p><ul><li>Earlier this year, James Earl Jones, the voice of Darth Vader, <a href=\"https://www.vanityfair.com/hollywood/2022/09/darth-vaders-voice-emanated-from-war-torn-ukraine?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--OcESTiwv6cSyTw5GU8keQ3ED3_Ad820upNwsEnCQHNMB3DhN7Jc4QM8mCr5S9F8-EOV6c51StKKhJkCBvzO1tXR4iFdfaOaqgPkhdHlRe2d97tkk&utm_content=2&utm_source=hs_email\">signed</a> a deal that permits Disney to recreate the Star Wars villain’s speech using technology from Ukrainian startup ReSpeecher.</li><li>Two documentary filmmakers separately generated vocal facsimiles of deceased celebrity chef <a href=\"https://www.newyorker.com/culture/annals-of-gastronomy/the-ethics-of-a-deepfake-anthony-bourdain-voice?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8pHYq17MpqRIH_9-LemE5QpwYD-uBGQJFlnZYm-pMUrlyYTxLTL4pG_H7CyguNWasU73Y5pmW4zXdtHJi8XhDRi19VyhPGIctI5uDbMOYVwc8UWFQ&utm_content=2&utm_source=hs_email\">Anthony Bourdain</a> and iconic artist <a href=\"https://www.resemble.ai/andy-warhol/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9vrGpD8oeC0oJkEO8TaAlpQp6_mXG1-uuqOZjtRnTcgIFT5poC7me4k-cFbu4442QAcFbgOyFeJD8c7THpBFU6dMSJvzXf1xY9vB-jdIYcOg8rncs&utm_content=2&utm_source=hs_email\">Andy Warhol</a>. The Bourdain imitation sparked controversy when his widow revealed that she had not given the filmmaker permission to recreate her husband’s voice.</li></ul><p><strong>Why it matters:</strong> The declamation is occasionally stilted and the script meandering (with occasional lapses into incoherence), but the rapid progress of generative audio combined with the entertainment world’s appetite for novelty suggests that satisfying synthetic productions may not be far off.<br><br><strong>We’re thinking:</strong> How long before we can produce <em><a href=\"https://www.youtube.com/playlist?list=PLkDaE6sCZn6FcbHlDzbVzf3TVgxzxK7lr&ref=dl-staging-website.ghost.io\">Heroes of Deep Learning</a></em> without actually talking with any of the heroes of deep learning?</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--5-.gif\" class=\"kg-image\" alt=\"Technical components of No Language Left Behind and how they fit together\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--5-.gif 600w\"></figure><h1 id=\"massively-multilingual-translation\">Massively Multilingual Translation</h1><p>Sentence pairs that have equivalent meanings in different languages — typically used to train machine translation systems — have been available in sufficient quantities for only around 100 languages. New work doubled that number and produced a more capable model.</p><p><strong>What’s new:</strong> Marta R. Costa-jussà and colleagues at Meta, Johns Hopkins, and UC Berkeley developed an automated process for scraping multilingual sentence pairs from the web. They released <a href=\"https://arxiv.org/abs/2207.04672?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--M99m5uj8I2DxSdY_SmnerMuM3FcLFlH-ksnLZfAhKN9J-No-X2NSiBFPuGdNUj1pm-Z0Zk_e_iwER3T5sfPypFZqqoUBn_XkXRP7gjjY5HpPXHzI&utm_content=2&utm_source=hs_email\">No Language Left Behind</a> (NLLB-200), a machine translation model that handles 200 languages. They also released the <a href=\"https://github.com/facebookresearch/fairseq/tree/nllb?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9gNxuxHnCNV9qE2WiGoX13Uvnr5tB5G7UdDr4SG-Z9p-tEhQfgRr527AWV_2hmHq2H4JdZKC-lY1i0r3mghX683XiFqbLNV-D26tdAl2qj5SnZjAo&utm_content=2&utm_source=hs_email\">models, code, and data</a> used to build it.</p><p><strong>Key insight:</strong> The web is full of text in various languages, including sentences that have the same meaning in different languages. For instance, unrelated pages in different languages may say the equivalent of, “Manchester United defeated Melbourne in yesterday’s match,” or “A long time ago in a galaxy far, far away.” An automated system can recognize such parallel sentences by learning to produce similar representations of sentences that have similar meaning regardless of their language. A teacher/student arrangement — with a multilingual teacher trained on languages with plentiful data to produce embeddings, and a separate monolingual student for each language scraped from the web — can align representations produced by the students.</p><p><strong>How they built the dataset:</strong> The authors identified languages in text scraped from the web, trained a teacher model on pre-existing multilingual data, and used it to train a student model to produce similar representations for similar meanings in the web text.</p><ul><li>The authors trained <a href=\"https://aclanthology.org/L18-1550/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-97f_99RZxBbjKsWapOmxZ1nSImhv2vq2fqVRspH7W65XR24BmzImgOA_rwWnSJSBHKoGGC7IdKz1cUgfhLcIN1mB9EMlAP4tctjGUcmRVAe7GU1fo&utm_content=2&utm_source=hs_email\">fasttext</a>, a linear classifier, to classify text according to its language. They trained it on publicly available datasets and their own corpus of 6,000 human-translated sentence pairs in 39 languages (released with this paper).</li><li>Fasttext classified the language of individual sentences and full paragraphs in web-text corpora such as <a href=\"https://commoncrawl.org/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--GEsxyWFFfSulLs4wmAdD3xU1RaQQrDp3sa5aYYbOMUkICicqnRX5WJCDCnoc0DqtIwJDmgCCNWuIGU47S2NO8OtHsLAYnCPPiwx9W4sa0CNCU3o0&utm_content=2&utm_source=hs_email\">Common Crawl</a> and <a href=\"https://aclanthology.org/2020.acl-main.417/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--c5wime8KVO9vame9Alp-ZvUq0d_8MYmI3Xcg6wgnF-jYiknILwQ4OVPZrDxFhcr_zyNwII7xSR0hkzIef8pXvsuiUAU-gt_uuQNES1fcrYZM_hlY&utm_content=2&utm_source=hs_email\">ParaCrawl</a>. The authors discarded sentences if their classification didn’t match that of the paragraph and removed sentences in languages for which they already had a lot of parallel data. After deleting duplicates, they had 43.7 billion sentences, each labeled as one of 148 languages.</li><li>They trained a separate transformer — a student — on each language (or several similar languages) to produce similar representations for sentences with similar meanings. To do this, they trained a Bidirectional LSTM — the teacher — to translate between the 93 languages in the <a href=\"https://aclanthology.org/L12-1246/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--7uTch3FXVlyrN9IEnpie-LoI2ZvnEYkt6RNMN67GMq_bwE1NX54r0AerME6VRtY3KsAtQ2Y6pMbv43O-rSNDj-OUImO_Gm-K-MQfLA8UWGbemfao&utm_content=2&utm_source=hs_email\">OPUS</a> dataset. This model learned similar representations of equivalent sentences in different languages. Using publicly available datasets of parallel sentences, the teacher received a sentence in one language (usually English) while a student received the equivalent sentence in its designated language(s). The students learned to maximize the cosine similarity between the teacher’s and students’ representations. Simultaneously, the students were trained to fill in missing words of sentences in their designated language(s).</li><li>The authors discarded sentence pairs if their representations’ cosine similarities were too different, leaving 1.1 billion parallel sentence pairs. Combined with pre-existing datasets, the parallel sentences represented 202 languages.</li></ul><p><strong>How they built the translator:</strong> NLLB-200 is a transformer encoder-decoder that comprises 54.5 billion parameters.</p><ul><li>In every fourth transformer layer (made up of a self-attention sublayer and a fully connected sublayer), the authors exchanged the fully connected sublayer with a <a href=\"https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9lgY7xQO9RQph_wmKLl5taqk1xbmwcvCiMLQFXlqzHNHN3bfuHoJfiotD-g6Q7Z7dVj3zmsWChrtN7nLmKzLzex9HDAPQgGCgMaPm04Et5ipBO9HM&utm_content=2&utm_source=hs_email\">Sparsely Gated Mixture-of-Experts</a> (MoE) sublayer that activated only a subnetwork of neurons for each input. This enabled the network to learn to activate different portions depending on the language, which may have helped to prevent learning about languages that had many examples from interfering with learning about languages that had few.</li><li>Training proceeded in two stages. In the first stage, NLLB-200 filled in missing words in sentences and translated between pairs of sentences in different languages. In the second, it trained only on translations. In both stages, the paired sentences included human-translated sentence pairs, sentences scraped from the web and paired automatically, and back translations in which the model converted its own translations back to the original language.</li></ul><p><strong>Results:</strong> The authors’ NLLB-200 model achieved 24.0 average <a href=\"https://aclanthology.org/2022.tacl-1.30/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8iUoLYm6tbUXe5Eyk7L8_vRAQstaMwWnnVmy0gt9VRN0CrG2DitUXddVBUfJbscq8_dxF0ByyVWIhr2UmIQJ6nayJHa8TkYdqpiQQcYQwZOKnSa4c&utm_content=2&utm_source=hs_email\">spBLEU</a> across all 202 languages, while the earlier <a href=\"https://arxiv.org/abs/2106.13736?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_GE1ZyOML7uWGl5w4g-91pBfHquWTfTsmpMeNmpwfjiBBJ48_zg70IO7cpua7LEPdPgR7SkUNkZt-udMdFmdzZurY3vM5-9Hbx-se2_5aSnrW0qu4&utm_content=2&utm_source=hs_email\">DeltaLM</a> achieved a 101-language average 16.7 spBLEU (which measures the overlap of word fragments between machine translations and ground truth, higher is better). A sparse NLLB-200 that used MoE rather than fully connected layers generally performed better than a dense version. For example, evaluated on Akan, a language spoken in Ghana for which little training data was available, the sparse model scored 36.2 <a href=\"https://aclanthology.org/W15-3049/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_ThKnXiBO2UMkqH7RUgaDYMdiihHCaYKQYzSOgx0geHm_Cfj-Op3uFPGiQroIFqmEDhBRbpa5J1TxpIASan3Taq6RWrc9DqIUuNopLTuKtRja3_sg&utm_content=2&utm_source=hs_email\">chrF</a>, while a dense version scored 35.6 chrF (which measures overlapping groups of consecutive characters between machine translations and ground truth, higher is better). NLLB-200 performed inconsistently compared to bilingual models: It achieved 36.2 chrF compared to an English-to-Akan model’s 16.8 chrF, but 51.4 chrF compared to an English-to-Gujarati model’s 51.7 chrF. A possible explanation: Languages that are dissimilar to other languages in the training data may not benefit as much from multilingual training.</p><p><strong>Why it matters:</strong> Faced with an apparent scarcity of data, the authors extracted it from the web. The data didn’t need to be perfect: To compensate for flaws such as typographical and grammatical errors, the model learned to convert its own translations — of flawed sentences but presumably many more correct ones — into good sentences.</p><p><strong>We’re thinking:</strong> University of Texas machine learning professor Raymond Mooney <a href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWH3P35RgQvpW9l9y2Y38dytHW6hm-BV4Rl4n_N3JhCG33q3npV1-WJV7CgHfqM9y5zFL2C-BW6N5VsV8CvWT2W8C3X5V839nFrN1MjyXHRVcdkW6JLDt47618bQW7jsgsc19hmFsW1m9RNq51tz-bN8164tNq8ybQW9jq5Mr72-CgjN86qWLFF0bVqW3CWlb25SR_G2W5vncQW5f5dyrW790cbF1Kwz6YW46dm5y4bR4CtW6wHgZ73_s6xpW5ymk8Z5T25XlW6Q9s374dpd05W5ntmJj4yN7Q2W1QqlY387gn2PW5Kq9F469pdPQVmbtDs6LqlkDVK4N7m13_9lQ31YL1?ref=dl-staging-website.ghost.io\" rel=\"noopener\">said</a>, “You can’t cram the meaning of a whole %&amp;!$# sentence into a single $&amp;!#* vector.” Apparently these researchers did it!</p>","comment_id":"634f0e72be967a003dce2467","feature_image":"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg","featured":false,"visibility":"public","created_at":"2022-10-18T13:37:06.000-07:00","updated_at":"2023-02-06T13:10:43.000-08:00","published_at":"2022-10-19T13:19:02.000-07:00","custom_excerpt":"The Batch - AI News & Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI?","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"634f1b6abe967a003dce251a","name":"issue-167","slug":"issue-167","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-167/"},{"id":"634f1b6abe967a003dce251b","name":"Oct 19, 2022","slug":"oct-19-2022","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-19-2022/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-167/","excerpt":"The Batch - AI News & Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI?","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more","meta_description":"The Batch - AI News & Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going...","email_subject":null,"frontmatter":null,"feature_image_alt":"Illustration of Andrew Ng on a computer searching for \"Panda bear\" and getting a Paddington instead","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"AI Python for Beginners","databaseId":35163,"id":"cG9zdDozNTE2Mw==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/1-9.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YX9G3n","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}