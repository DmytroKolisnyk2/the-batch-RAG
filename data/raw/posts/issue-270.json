{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.120","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-270","id":"6706fa8a504fea00012eb1a4","uuid":"f01d475b-16c7-4d7f-abe0-79d5679fbba1","title":"How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, OpenAI‚Äôs New Voice API","html":"<p>Dear friends,</p><p>Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize! It‚Äôs wonderful to see pioneering work in AI recognized, and this will be good for our whole field. Years ago, I was the first to call Geoff the ‚ÄúGodfather of Deep Learning,‚Äù which later became ‚ÄúGodfather of AI.‚Äù I‚Äôm thrilled at the recognition he‚Äôs receiving via this most prestigious of awards.</p><p>As Geoff relayed in the ‚ÄúHeroes of Deep Learning‚Äù&nbsp;<a href=\"https://www.youtube.com/watch?v=-eyhCTvrEtE&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">interview</a>&nbsp;I did with him years ago, his early work developing the foundations of neural networks has been instrumental to the rise of deep learning and AI. It has been years since I implemented a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Hopfield_network?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Hopfield network</a>, but John‚Äôs work, too, has been influential. Their recognition is well deserved!</p><p>But the Nobel committee wasn‚Äôt done yet. One day after the physics prize was announced, Demis Hassabis, John Jumper, and David Baker won the Chemistry Nobel Prize for their work on AlphaFold and protein design. AlphaFold and AlphaFold 2, as well as the work of Baker‚Äôs lab, are compelling applications of AI that made significant steps forward in chemistry and biology, and this award, too, is well deserved!</p><p>It‚Äôs remarkable that the Nobel committees for physics and chemistry, which are made up of scientists in those fields, chose to honor AI researchers with this year‚Äôs awards. This is a sign of our field‚Äôs growing impact on society.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY-1.jpg\" class=\"kg-image\" alt=\"Three people, Jeff Dean, Andrew Ng, and Geoff Hinton, stand together at Hinton‚Äôs retirement party, with Hinton holding a microphone.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/HINTON-PARTY-1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/HINTON-PARTY-1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY-1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>While it‚Äôs good that people from outside AI are recognizing AI researchers, I wonder if there‚Äôs room for the AI community to pick more award recipients ourselves. Best-known in computer science is the Turing Award, which is selected by a broad group of computer scientists, many of whom have deep AI knowledge. Many AI conferences give out best-paper awards. And applications of AI to other fields doubtless will continue to receive much-deserved recognition by leaders in those fields. I‚Äôm optimistic this will allow AI researchers to win more Nobel Prizes ‚Äî someday also in economics, literature, medicine, and peace, too.&nbsp;Nonetheless, this seems like a good time to see how all of us in AI can do more to recognize the work of innovators in our field.</p><p>Geoff once thanked me for my role in getting him anointed ‚ÄúGodfather of AI,‚Äù which he said was good for his career. I didn‚Äôt realize before that I had the power to give out such titles üòâ but I would love for there to be numerous godfathers and godmothers ‚Äî and many other awards ‚Äî in AI!</p><p>At Geoff's retirement party last October (pictured in the photo above), I spoke with affection and gratitude for all the work he has done to grow AI. Even as we cheer the new Nobel wins for AI, let‚Äôs continue to think about how we in AI can do more to celebrate the next generation of innovators.</p><p>Keep learning!</p><p>Andrew</p><h2 id=\"a-message-from-deeplearningai\">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class=\"kg-card kg-image-card\"><a href=\"https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.png\" class=\"kg-image\" alt=\"Promo banner for &quot;Introducing Multimodal Llama 3.2&quot;\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--15-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--15-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></a></figure><p>Try the new capabilities of Llama 3.2 in our latest course with Meta. Learn how to compose multimodal prompts, call custom tools, and use the Llama Stack API to build applications with Meta‚Äôs family of open weights models.&nbsp;<a href=\"https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Enroll for free!</a></p><h1 id=\"news\">News</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.gif\" class=\"kg-image\" alt=\"A demonstration of video editing through text input, altering a runner‚Äôs background and costume.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.gif 600w\"></figure><h1 id=\"familiar-faces-synthetic-soundtracks\">Familiar Faces, Synthetic Soundtracks</h1><p>Meta upped the ante for text-to-video generation with new systems that produce consistent characters and matching soundtracks.</p><p><strong>What‚Äôs new:&nbsp;</strong>Meta presented&nbsp;<a href=\"https://ai.meta.com/research/movie-gen/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Movie Gen</a>, a series of four systems that generate videos, include consistent characters, alter generated imagery, and add matching sound effects and music. Movie Gen will be&nbsp;<a href=\"https://www.instagram.com/zuck/reel/DAs_J17Pw0G/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">available</a>&nbsp;on Instagram in 2025. Meanwhile, you can view and listen to examples&nbsp;<a href=\"https://ai.meta.com/research/movie-gen/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">here</a>. The team&nbsp;<a href=\"https://ai.meta.com/static-resource/movie-gen-research-paper?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">explains</a>&nbsp;how the model was built an extensive 92-page paper.</p><p><strong>Generated videos:</strong>&nbsp;Movie Gen Video can output 256 frames (up to 16 seconds at 16 frames per second) at 1920x1080-pixel resolution. It includes a convolutional neural network autoencoder, transformer, and multiple embedding models.</p><ul><li>Movie Gen Video produces imagery by flow matching, a technique related to diffusion. It learned to remove noise from noisy versions of images and videos given matching text descriptions from 1 billion image-text pairs and 100 million video-text pairs. At inference, it starts with pure noise and generates detailed imagery according to a text prompt.</li><li>The system concatenates multiple text embeddings to combine the strengths of different embedding models.&nbsp;<a href=\"https://arxiv.org/abs/2205.05131?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">UL2</a>&nbsp;was trained on text-only data, so its embeddings may provide ‚Äúreasoning abilities,‚Äù according to the authors.&nbsp;<a href=\"https://arxiv.org/abs/2309.16671?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Long-prompt MetaCLIP</a>&nbsp;was trained to produce similar text and image representations, so its embeddings might be useful for ‚Äúcross-modal generation.‚Äù&nbsp;<a href=\"https://arxiv.org/abs/2105.13626?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">ByT5</a>&nbsp;produces embeddings of individual text elements such as letters, numbers, and symbols; the system uses it when a prompt requests text within a clip.&nbsp;</li></ul><p><strong>Consistent characters:</strong>&nbsp;Given an image of a face, a fine-tuned version of Movie Gen Video generates a video that depicts a person with that face.&nbsp;</p><ul><li>To gather a training dataset for this capability, the team filtered Movie Gen Video‚Äôs pretraining dataset for clips that show a single face and consecutive frames are similar to one another. They built video-face examples by pairing each clip with a frame selected from the clip at random. To train the system, the team fed it text, the clip with added noise, and the single-frame face. It learned to remove the noise.</li><li>Trained on this data alone, the system generated videos in which the person always faces the camera. To expand the variety of poses, they further trained it on examples that substituted the faces in the previous step with&nbsp;<a href=\"https://arxiv.org/abs/2409.13346?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">generated versions</a>&nbsp;with alternate poses and facial expressions.</li></ul><p><strong>Altered clips:</strong>&nbsp;The team modified Movie Gen Video‚Äôs autoencoder to accept an embedding of an alteration ‚Äî say, changing the background or adding an object. They trained the system to alter videos in three stages:</p><ul><li>First, they trained the system, given a starting image and an instruction to alter it, to produce an altered image.</li><li>They further trained the system to produce altered clips. They generated two datasets of before-and-after clips based on instructions. (i) For instance, given a random frame and an instruction to, say, replace a person with a cat, the system altered the frame accordingly. Then the team subjected both frames to a series of augmentations selected at random, creating matching clips, one featuring a person, the other featuring a cat. Given the initial clip and the instruction, the system learned to generate the altered clip. (ii) The team used&nbsp;<a href=\"https://arxiv.org/abs/2303.05499?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">DINO</a>&nbsp;and&nbsp;<a href=\"https://arxiv.org/abs/2408.00714?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">SAM 2</a>&nbsp;to segment clips. Given an unsegmented clip and an instruction such as ‚Äúmark &lt;object&gt; with &lt;color&gt;,‚Äù the system learned to generate the segmented clip.&nbsp;</li><li>Finally, they trained the system to restore altered clips to their original content. They built a dataset by taking a ground-truth clip and using their system to generate an altered version according to an instruction. Then Llama 3 rewrote the instruction to modify the altered clip to match the original. Given the altered clip and the instruction, the system learned to generate the original clip.</li></ul><p><strong>Synthetic soundtracks:</strong>&nbsp;Given a text description, a system called Movie Gen Audio generates sound effects and instrumental music for video clips up to 30 seconds long. It includes a&nbsp;<a href=\"https://arxiv.org/abs/2306.06546?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">DACVAE</a>&nbsp;audio encoder (which encodes sounds that comes before and/or after the target audio), Long-prompt MetaCLIP video encoder,&nbsp;<a href=\"https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">T5</a>&nbsp;text encoder, vanilla neural network that encodes the current time step, and transformer.</p><ul><li>Movie Gen Audio learned to remove noise from noisy versions of audio associated with 1 million videos with text captions.&nbsp; At inference, it starts with pure noise and generates up to 30 seconds of audio at once.</li><li>At inference, it can extend audio. Given the last n seconds of audio, the associated portion of a video, and a text description, it can generate the next 30 - n seconds.</li></ul><p><strong>Results:</strong>&nbsp;Overall, Movie Gen achieved performance roughly equal to or better than competitors in qualitative evaluations of overall quality and a number of specific qualities (such as ‚Äúrealness‚Äù). Human evaluators rated their preferences for Movie Gen or a competitor. The team reported the results in terms of net win rate (win percentage minus loss percentage) between -100 percent and 100 percent, where a score above zero means that a system won more than it lost.</p><ul><li>For overall video quality, Movie Gen achieved a net win rate of 35.02 percent versus Runway Gen3, 8.23 percent versus Sora (based on the prompts and generated clips available on OpenAI‚Äôs website), and 3.87 percent versus Kling 1.5.</li><li>Generating clips of specific characters, Movie Gen achieved a net win rate of 64.74 percent versus ID-Animator, the state of the art for this capability.</li><li>Generating soundtracks for videos from the SReal SFX dataset, Movie Gen Audio achieved a net win rate between 32 percent and 85 percent compared to various video-to-audio models.</li><li>Altering videos in the&nbsp;<a href=\"https://arxiv.org/abs/2403.09334?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">TGVE+</a>&nbsp;dataset, Movie Gen beat all competitors more than 70 percent of the time.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;With Movie Gen, table stakes for video generation rises to include consistent characters, soundtracks, and various video-to-video alterations. The 92-page paper is a valuable resource for builders of video generation systems, explaining in detail how the team filtered data, structured models, and trained them to achieve good results.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;Meta has a great track record of publishing both model weights and papers that describe how the models were built. Kudos to the Movie Gen team for publishing the details of this work!</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.gif\" class=\"kg-image\" alt=\"A smartphone on a table showing an incoming call with voice waveform displayed on screen.\" loading=\"lazy\" width=\"600\" height=\"337\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.gif 600w\"></figure><h1 id=\"voice-to-voice-and-more-for-gpt-4o-api\">Voice-to-Voice and More for GPT-4o API</h1><p>OpenAI launched a suite of new and updated tools to help AI developers build applications and reduce costs.</p><p><strong>What‚Äôs new:&nbsp;</strong>At its annual DevDay conference, OpenAI&nbsp;introduced an&nbsp;<a href=\"https://openai.com/index/introducing-the-realtime-api/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">API<u>&nbsp;</u></a>for speech processing using GPT-4o,&nbsp;<a href=\"https://openai.com/index/api-model-distillation/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">distillation tools</a>,&nbsp;<a href=\"https://openai.com/index/introducing-vision-to-the-fine-tuning-api/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">vision fine-tuning capabilities</a>, and the ability to&nbsp;<a href=\"https://openai.com/index/api-prompt-caching/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">cache prompts</a>&nbsp;for later re-use. These tools are designed to make it easier to build fast applications using audio inputs and outputs, customize models, and cut costs for common tasks.</p><p><strong>Development simplified:</strong>&nbsp;The new offerings aim to make it easier to build applications using OpenAI models, with an emphasis on voice input/output and image input, customizing models, and resolving common pain points.</p><ul><li>The Realtime API enables speech-to-speech interactions with GPT-4o using six preset voices, like ChatGPT's Advanced Voice Mode but with lower latency. The API&nbsp;<a href=\"https://openai.com/api/pricing/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">costs</a>&nbsp;$100/$200 per 1 million input/output tokens (about $0.06/$0.24 per minute of input/output). (The API processes text at $5/$20 per million input/output tokens.</li><li>The Chat Completions API now accepts voice input and generates voice outputs for GPT-4o‚Äôs usual price ($3.75/$15 per million input/output tokens). However, it generates outputs less quickly than the Realtime API. (OpenAI didn‚Äôt disclose specific latency measurements.)</li><li>The distillation tools simplify the process of using larger models like o1-preview as teachers whose output is used to fine-tune smaller, more cost-efficient students like GPT-4o mini. Developers can generate datasets, fine-tune models, and evaluate performance within OpenAI's platform. For example, you can use GPT-4o to create responses to customer-service questions, then use the resulting dataset to fine-tune GPT-4o mini.</li><li>Vision fine-tuning allows developers to enhance GPT-4o's image understanding by fine-tuning the model on a custom image dataset. For instance, developers can improve visual search, object detection, or image analysis for a particular application by fine-tuning the model on domain-specific images. Vision fine-tuning costs $25 per million training tokens for GPT-4o, but OpenAI will give developers 1 million free training tokens per day through October 31.</li><li>Prompt caching automatically reuses input tokens that were entered in recent interactions with GPT-4o, GPT-4o mini, and their fine-tuned variants. Repeated prompts cost half as much and get processed faster. The discount and speed especially benefit applications like chatbots and code editors, which frequently reuse input context.</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI is undertaking a major corporate transformation. A recent funding round&nbsp;<a href=\"https://www.nytimes.com/2024/10/02/technology/openai-valuation-150-billion.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">values</a>&nbsp;OpenAI at $157 billion, making it among the world‚Äôs most valuable private companies, and the company is&nbsp;<a href=\"https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">transferring</a>&nbsp;more control from its nonprofit board to its for-profit subsidiary. Meanwhile, it has seen an&nbsp;<a href=\"https://techcrunch.com/2024/10/03/a-co-lead-on-sora-openais-video-generator-has-left-for-google/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">exodus</a>&nbsp;of executives that include CTO Mira Murati, Sora co-lead Tim Brooks, chief research officer Bob McGrew, research VP Barret Zoph, and&nbsp;<a href=\"https://www.businessinsider.com/openai-talent-exodus-joke-tech-world-mira-murati-sam-altman-2024-9?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">other key researchers</a>.</p><p><strong>Why it matters:&nbsp;</strong>The Realtime API enables speech input and output without converting speech to text, allowing for more natural voice interactions. Such interactions open a wide range of applications, and they‚Äôre crucial for real-time systems like customer service bots and virtual assistants. Although&nbsp;<a href=\"https://aws.amazon.com/blogs/machine-learning/use-llama-3-1-405b-to-generate-synthetic-data-for-fine-tuning-tasks/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Amazon Web Service</a>&nbsp;and&nbsp;<a href=\"https://labelbox.com/guides/end-to-end-workflow-for-knowledge-distillation-with-nlp/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Labelbox</a>&nbsp;provide services to distill knowledge from OpenAI models into open architectures, OpenAI‚Äôs tools ease the process of distilling from OpenAI models into other OpenAI models. Image fine-tuning and prompt caching, like similar capabilities for Anthropic Claude and Google Gemini, are welcome additions.&nbsp;</p><p><strong>We‚Äôre thinking:</strong>&nbsp;OpenAI‚Äôs offerings have come a long way since&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/all-the-new-models-and-products-announced-by-openai-during-devday/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">DevDay 2023</a>, when speech recognition was ‚Äúcoming soon.‚Äù We‚Äôre eager to see what developers do with voice-driven applications!</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.png\" class=\"kg-image\" alt=\"Collage of various images featuring a baseball player, movie scenes, portraits, landscapes, and diverse wildlife.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--16-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--16-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"german-court-laion-didn%E2%80%99t-violate-copyrights\">German Court: LAION Didn‚Äôt Violate Copyrights</h1><p>A German court dismissed a copyright lawsuit against LAION, the nonprofit responsible for large-scale image datasets used to train Midjourney, Stable Diffusion, and other image generators.</p><p><strong>What‚Äôs new:</strong>&nbsp;The court&nbsp;<a href=\"https://www.technollama.co.uk/laion-wins-copyright-infringement-lawsuit-in-german-court?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">rejected</a>&nbsp;a lawsuit claiming that cataloging images on the web to train machine learning models violates the image owners‚Äô copyrights. It ruled that LAION‚Äôs activities fall under protections for scientific research.</p><p><strong>How it works:</strong>&nbsp;LAION doesn‚Äôt distribute images. Instead, it compiles links to images and related text that are published on publicly available websites. Model builders who wish to use the images and/or text must download them from those sources. In 2023, photographer Robert Kneschke&nbsp;<a href=\"https://www.technollama.co.uk/photographer-sues-laion-for-copyright-infringement?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">sued</a>&nbsp;LAION for including his photos. The court‚Äôs&nbsp;<a href=\"https://drive.google.com/file/d/1A_vnSJUwlrVovhIqA4rKIFaOktR4TvBt/view?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">decision</a>&nbsp;emphasized several key points.</p><ul><li>LAION, while compiling links to images, had indeed made unauthorized copies of images protected by copyright, as defined by German law. However, Germany‚Äôs Copyright Act allows unauthorized use of copyrighted works for scientific research. The court ruled that LAION had collected the material for this purpose, so it did not violate copyrights.</li><li>Moreover, the court found that downloading images and text in order to correlate them likely fell under a further exemption to copyright for data mining. This finding wasn‚Äôt definitive because the exemption for research made it irrelevant, but the court mentioned it to help guide future rulings.</li><li>The dataset‚Äôs noncommercial status was a key factor in the ruling. LAION distributed the dataset for free, and no commercial entity controlled its operations. Although a LAION dataset may be used to train a machine learning model that‚Äôs intended to be sold commercially, this is not sufficient to classify creating such datasets as commercial activity. The plaintiff contended that, because some LAION members have paid roles in commercial companies, LAION could be considered a commercial entity. However, the court rejected that argument.</li></ul><p><strong>Behind the news:</strong>&nbsp;Several other artists have sued&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/the-story-of-laion-the-dataset-behind-stable-diffusion/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">LAION</a>, which stands for Large-scale AI Open Network, claiming that the organization used their works without their consent. They have also sued AI companies, including a&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/artists-file-a-lawsuit-against-stability-ai-and-midjourney/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">class action suit</a>&nbsp;against Stability AI, Midjourney, and DeviantArt for using materials under copyright, including images in LAION‚Äôs datasets, to train their models. Similar cases have been brought against makers of&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/sony-umg-and-warner-music-sue-suno-and-udio-over-alleged-copyright-violations/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">music generators</a>&nbsp;and&nbsp;<a href=\"https://www.deeplearning.ai/the-batch/judge-dismisses-key-arguments-in-ai-copyright-lawsuit-against-github-microsoft-and-openai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">coding assistants</a>. All these lawsuits, which are in progress, rest on the plaintiff‚Äôs claim that assembling a training dataset of copyrighted works infringes copyrights.</p><p><strong>Why it matters:</strong>&nbsp;The German ruling is the first AI-related decision in Europe since the adoption of the AI Act, and the court took that law‚Äôs intent into account when making its decision. It affirms that creating text-image pairs of publicly available material for the purpose of training machine learning models does not violate copyrights, even if commercial organizations later use the data. However, the court did not address whether training AI models on such datasets, or using the trained models in a commercial setting, violates copyrights.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;This decision is encouraging news for AI researchers. We hope jurisdictions worldwide establish that training models on media that‚Äôs available on the open web is fair and legal.</p><hr><figure class=\"kg-card kg-image-card\"><img src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.png\" class=\"kg-image\" alt=\"Diagram illustrating the process of developing, deploying, and promoting a malicious LLM application for phishing and malicious services.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--17-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--17-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h1 id=\"ai%E2%80%99s-criminal-underground-revealed\">AI‚Äôs Criminal Underground Revealed</h1><p>Researchers probed the black market for AI services that are designed to facilitate cybercrime.</p><p><strong>What‚Äôs new</strong>: Zilong Lin and colleagues at Indiana University Bloomington&nbsp;<a href=\"https://arxiv.org/abs/2401.03315?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">studied</a>&nbsp;how large language models (LLMs) are used to provide harmful services, specifically generating malicious code, phishing emails, and phishing websites. They weren‚Äôt very effective, by and large (though a high success rate may not be necessary to support a thriving market in automated criminal activity).</p><p><strong>Risky business:</strong>&nbsp;Providers base such services on either uncensored LLMs ‚Äî that is, those that weren‚Äôt fine-tuned to reflect human preferences or don‚Äôt employ input/output filters ‚Äî or publicly available models that they prompt using jailbreak techniques that circumvent built-in guardrails. They sell their services in hacker‚Äôs marketplaces and forums, charging far less than typical traditional malware vendors, but services based on models that have been fine-tuned to deliver malicious output command a premium. The authors found that one&nbsp;service generated revenue of more than $28,000 in two months.</p><p><strong>Sprawling market:&nbsp;</strong>The authors identified 212 harmful services. Of those, 125 were hosted on the Poe AI platform, 73 were on FlowGPT, and the remaining 14 resided on unique servers. Of those, the authors were unable to access five because either the provider blocked them, or the service was fraudulent. They identified 11 LLMs used by these services including Claude-2-100k, GPT-4, and Pygmalion-13B (a variant of LLaMA-13B).</p><p><strong>Testing output quality:&nbsp;</strong>The authors prompted more than 200 services using over 30 prompts to generate malicious code, phishing emails, or phishing websites. They evaluated the responses according to:</p><ul><li>Format: How often they followed the expected format (as defined by regular expressions)</li><li>Compilability: How often generated Python, C, or C++ code was able to compile</li><li>Validity: How often generated HTML and CSS ran successfully in both Chrome and Firefox</li><li>Readability: How often generated phishing emails were fluent and coherent according to the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Gunning_fog_index?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">Gunning fog Index</a>&nbsp;of reading difficulty</li><li>Evasiveness, or how often generated text both succeeded in all previous checks and evaded detection by&nbsp;<a href=\"https://www.virustotal.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">VirusTotal</a>&nbsp;(for malicious code and phishing sites) or&nbsp;<a href=\"https://www.oopspam.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">OOPSpam</a>&nbsp;(for phishing emails).</li></ul><p>In all three tasks, at least one service achieved evasiveness of 67 percent or higher, while the majority of services achieved an evasiveness of less than 30 percent.</p><p><strong>Testing real-world effectiveness:&nbsp;</strong>In addition, the authors ran practical tests to see how well the output worked in real-world situations. They prompted nine services to generate code that would target three specific vulnerabilities that relate to buffer overflow and SQL injection. In these tests, the models were markedly less successful.</p><ul><li>The authors tested generated code for two vulnerabilities on&nbsp;<a href=\"https://www.vicidial.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">VICIdial</a>, a call-center system known to be vulnerable to such issues. Of 22 generated programs that were able to compile, none changed VICIdial‚Äôs databases or disclosed system data.</li><li>They tested generated code further on&nbsp;<a href=\"https://owasp.org/www-project-webgoat/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">OWASP WebGoat 7.1</a>, a website that provides code with known security flaws. Of 39 generated programs that were able to compile, seven launched successful attacks. However, these attacks did not target the specific vulnerabilities requested by the authors.</li></ul><p><strong>Why it matters</strong>: Previous work showed that LLMs-based services could generate&nbsp;<a href=\"https://dl.acm.org/doi/10.1145/3544548.3581318?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\">misinformation</a>&nbsp;and other malicious output, but little research has probed their actual use in cybercrime. This work evaluates their quality and effectiveness. In addition, the authors released the prompts they used to circumvent guardrails and generate malicious output ‚Äî a resource for further research that aims to fix such issues in future models.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;It‚Äôs encouraging to see that harmful services didn‚Äôt get far in real-world tests, and the authors' findings should put a damper on alarmist scenarios of AI-enabled cybercrime. That doesn‚Äôt mean we don‚Äôt need to worry about harmful applications of AI technology. The AI community has a responsibility to design its products to be beneficial and evaluate them thoroughly for safety.</p>","comment_id":"6706fa8a504fea00012eb1a4","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg","featured":false,"visibility":"public","created_at":"2024-10-09T14:50:02.000-07:00","updated_at":"2024-10-09T16:44:38.000-07:00","published_at":"2024-10-09T14:59:00.000-07:00","custom_excerpt":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"6706fd5f504fea00012eb1ac","name":"issue 270","slug":"issue-270","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-270/"},{"id":"6706fd5f504fea00012eb1ad","name":"Oct 09, 2024","slug":"oct-09-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-09-2024/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-270/","excerpt":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more...","meta_description":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg","dimensions":{"width":1200,"height":675}},"banner":{"title":"ChatGPT Prompt Engineering for Developers","databaseId":29452,"id":"cG9zdDoyOTQ1Mg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/05/cgpt-2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"‚ú® Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"Hugging Face C5","date":"2025-04-23T07:45:01","databaseId":36454,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4lAbjwN","courseName":"Building Code Agents with Hugging Face smolagents","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(77, 59, 189, 1) 0%, rgba(21, 94, 252, 1) 100%)","isOpenInNewTab":true}}]}}},"__N_SSG":true}