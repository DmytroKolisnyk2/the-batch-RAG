{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing All Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJy-ZveJRYY6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"QDRANT_URL\"] = \"...\"\n",
        "os.environ[\"QDRANT_API_KEY\"] = \"...\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
        "os.environ[\"NGROK_TOKEN\"] = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data collection pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAHlLap4liQm",
        "outputId": "a4689f71-cb01-4ed9-e76c-d0df01c21248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build ID: v_7Wdn7Y_3E7b3v5FzsK6 | Initial posts: 16\n",
            "Page 2: 15 posts\n",
            "Page 3: 15 posts\n",
            "Page 4: 15 posts\n",
            "Page 5: 15 posts\n",
            "Page 6: 15 posts\n",
            "Page 7: 15 posts\n",
            "Page 8: 15 posts\n",
            "Page 9: 15 posts\n",
            "Page 10: 15 posts\n",
            "Page 11: 15 posts\n",
            "Page 12: 15 posts\n",
            "Page 13: 15 posts\n",
            "Page 14: 15 posts\n",
            "Page 15: 15 posts\n",
            "Page 16: 15 posts\n",
            "Page 17: 15 posts\n",
            "Page 18: 15 posts\n",
            "Page 19: 15 posts\n",
            "Page 20: 15 posts\n",
            "Page 21: 15 posts\n",
            "Page 22: 2 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading posts: 100%|██████████| 318/318 [07:36<00:00,  1.43s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup as BS\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Base URL and local directories\n",
        "BASE_URL = \"https://www.deeplearning.ai\"\n",
        "RAW_DIR = Path(\"data/raw\")\n",
        "PAGE_DIR = RAW_DIR / \"pages\"\n",
        "POST_DIR = RAW_DIR / \"posts\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "# Create necessary directories if they don't exist\n",
        "for directory in (PAGE_DIR, POST_DIR):\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def backoff_sleep(attempt: int) -> None:\n",
        "    \"\"\"\n",
        "    Sleep with exponential backoff to handle rate limiting.\n",
        "    \"\"\"\n",
        "    time.sleep((2 ** attempt) + random.random())\n",
        "\n",
        "def fetch_front_page() -> tuple[str, list[dict]]:\n",
        "    \"\"\"\n",
        "    Retrieve the build ID and list of posts from the main page's __NEXT_DATA__.\n",
        "    Saves the retrieved JSON to a local file.\n",
        "    \"\"\"\n",
        "    url = f\"{BASE_URL}/the-batch\"\n",
        "    response = requests.get(url, headers=HEADERS, timeout=15)\n",
        "    response.raise_for_status()\n",
        "    data = json.loads(BS(response.text, \"lxml\").select_one(\"#__NEXT_DATA__\").string)\n",
        "    build_id = data[\"buildId\"]\n",
        "    posts = data[\"props\"][\"pageProps\"][\"posts\"]\n",
        "\n",
        "    # Save front page JSON\n",
        "    (PAGE_DIR / \"page_1.json\").write_text(json.dumps(data, ensure_ascii=False, indent=2))\n",
        "    return build_id, posts\n",
        "\n",
        "def fetch_index_page(build_id: str, page: int) -> list[dict] | None:\n",
        "    \"\"\"\n",
        "    Fetch a paginated index JSON for posts.\n",
        "    Returns a list of post dicts, or None if no more pages exist.\n",
        "    \"\"\"\n",
        "    url = f\"{BASE_URL}/_next/data/{build_id}/the-batch/page/{page}.json?pageNo={page}\"\n",
        "    response = requests.get(url, headers=HEADERS, timeout=15)\n",
        "    if response.status_code == 404:\n",
        "        return None\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "\n",
        "    # Save page JSON\n",
        "    (PAGE_DIR / f\"page_{page}.json\").write_text(json.dumps(data, ensure_ascii=False, indent=2))\n",
        "    return data.get(\"pageProps\", {}).get(\"posts\", [])\n",
        "\n",
        "def fetch_post_json(build_id: str, slug: str) -> None:\n",
        "    \"\"\"\n",
        "    Download the post JSON for a given slug.\n",
        "    Uses exponential backoff on HTTP 429 or 504 errors.\n",
        "    \"\"\"\n",
        "    output_path = POST_DIR / f\"{slug}.json\"\n",
        "    if output_path.exists():\n",
        "        return\n",
        "\n",
        "    url = f\"{BASE_URL}/_next/data/{build_id}/the-batch/{slug}.json?slug={slug}\"\n",
        "    max_retries = 3\n",
        "    for attempt in range(max_retries):\n",
        "        response = requests.get(url, headers=HEADERS, timeout=30)\n",
        "        if response.status_code in (429, 504):\n",
        "            backoff_sleep(attempt)\n",
        "            continue\n",
        "        if response.status_code == 404:\n",
        "            print(f\"Warning: {slug} returned 404, skipping.\")\n",
        "            return\n",
        "        response.raise_for_status()\n",
        "        output_path.write_text(response.text, encoding=\"utf-8\")\n",
        "        return\n",
        "\n",
        "    print(f\"Warning: {slug} failed after {max_retries} retries due to rate limiting.\")\n",
        "\n",
        "def scrape_batch_posts():\n",
        "    # Fetch front page build ID and initial posts\n",
        "    build_id, all_posts = fetch_front_page()\n",
        "    print(f\"Build ID: {build_id} | Initial posts: {len(all_posts)}\")\n",
        "\n",
        "    # Fetch subsequent index pages\n",
        "    page_number = 2\n",
        "    while True:\n",
        "        posts = fetch_index_page(build_id, page_number)\n",
        "        if not posts:\n",
        "            break\n",
        "        print(f\"Page {page_number}: {len(posts)} posts\")\n",
        "        all_posts.extend(posts)\n",
        "        page_number += 1\n",
        "        time.sleep(0.3)\n",
        "\n",
        "    # Save metadata about all posts\n",
        "    meta_file = Path(\"data/posts_meta.jsonl\")\n",
        "    meta_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with meta_file.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for post in all_posts:\n",
        "            f.write(json.dumps(post, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    # Download each post's content\n",
        "    for post in tqdm(all_posts, desc=\"Downloading posts\"):\n",
        "        fetch_post_json(build_id, post[\"slug\"])\n",
        "\n",
        "scrape_batch_posts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Content Processing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqfitEMMTrMZ",
        "outputId": "0a31fa72-e0d1-43b0-be4a-5a00950c6dfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing posts: 100%|██████████| 316/316 [00:06<00:00, 51.18it/s]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Iterable, Tuple, Dict, List\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import html2text\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Directories\n",
        "RAW_DIR = Path(\"data/raw/posts\")\n",
        "PROC_DIR = Path(\"data/processed\")\n",
        "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Text-chunking parameters\n",
        "CHUNK_SIZE = 768      # characters per chunk\n",
        "CHUNK_OVERLAP = 128   # overlap between chunks\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "# Configure HTML-to-markdown converter\n",
        "md_converter = html2text.HTML2Text()\n",
        "md_converter.body_width = 0  # disable line wrapping\n",
        "\n",
        "def parse_html(html: str) -> Tuple[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Convert HTML to Markdown and extract image info.\n",
        "    Returns:\n",
        "      - markdown text (str)\n",
        "      - list of image dicts: { \"url\": ..., \"alt\": ... }\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    # Extract all <img> tags\n",
        "    images: List[Dict] = []\n",
        "    for img in soup.select(\"img[src]\"):\n",
        "        src = img[\"src\"]\n",
        "        if src.startswith(\"//\"):\n",
        "            src = \"https:\" + src\n",
        "        images.append({\"url\": src, \"alt\": img.get(\"alt\", \"\")})\n",
        "\n",
        "    # Remove unwanted tags\n",
        "    for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "        tag.decompose()\n",
        "\n",
        "    # Convert to Markdown and collapse multiple blank lines\n",
        "    markdown = md_converter.handle(str(soup))\n",
        "    markdown = re.sub(r\"\\n{3,}\", \"\\n\\n\", markdown).strip()\n",
        "\n",
        "    return markdown, images\n",
        "\n",
        "def article_to_documents(post_json: dict) -> Tuple[List[Document], List[Dict]]:\n",
        "    \"\"\"\n",
        "    Turn a post JSON into:\n",
        "      - a list of Document objects (text chunks)\n",
        "      - a list of image metadata dicts\n",
        "    \"\"\"\n",
        "    post = post_json[\"pageProps\"][\"cmsData\"][\"post\"]\n",
        "    slug = post[\"slug\"]\n",
        "    title = post[\"title\"]\n",
        "    published = post[\"published_at\"]\n",
        "    feature_image = post.get(\"feature_image\")\n",
        "    html_content = post[\"html\"]\n",
        "\n",
        "    # Parse HTML into markdown + image list\n",
        "    markdown, images = parse_html(html_content)\n",
        "\n",
        "    # Prepend feature image if available\n",
        "    if feature_image:\n",
        "        images.insert(0, {\n",
        "            \"url\": feature_image,\n",
        "            \"alt\": post.get(\"feature_image_alt\", \"\")\n",
        "        })\n",
        "\n",
        "    # Split markdown into chunks\n",
        "    chunks = text_splitter.split_text(markdown)\n",
        "    docs: List[Document] = []\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        docs.append(Document(\n",
        "            page_content=chunk,\n",
        "            metadata={\n",
        "                \"slug\": slug,\n",
        "                \"title\": title,\n",
        "                \"published\": published,\n",
        "                \"chunk_id\": idx,\n",
        "                \"n_chunks\": len(chunks),\n",
        "            },\n",
        "        ))\n",
        "\n",
        "    # Attach slug to each image record\n",
        "    images_metadata = [{\"slug\": slug, **img} for img in images]\n",
        "    return docs, images_metadata\n",
        "\n",
        "def iter_post_files() -> Iterable[Path]:\n",
        "    \"\"\"Yield all JSON files in the raw posts directory.\"\"\"\n",
        "    return RAW_DIR.glob(\"*.json\")\n",
        "\n",
        "# Output file paths\n",
        "docs_output = PROC_DIR / \"chunks.jsonl\"\n",
        "images_output = PROC_DIR / \"images.jsonl\"\n",
        "\n",
        "# Process each post and write out chunks & images\n",
        "with docs_output.open(\"w\", encoding=\"utf-8\") as doc_file, \\\n",
        "     images_output.open(\"w\", encoding=\"utf-8\") as img_file:\n",
        "\n",
        "    for post_file in tqdm(list(iter_post_files()), desc=\"Processing posts\"):\n",
        "        post_data = json.loads(post_file.read_text(encoding=\"utf-8\"))\n",
        "        docs, imgs = article_to_documents(post_data)\n",
        "\n",
        "        # Write each Document as a JSON line\n",
        "        for doc in docs:\n",
        "            doc_file.write(json.dumps(doc.model_dump(), ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "        # Write each image record as a JSON line\n",
        "        for img in imgs:\n",
        "            img_file.write(json.dumps(img, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing into Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "hXbh2hd5Zpck"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import uuid\n",
        "import io\n",
        "from pathlib import Path\n",
        "from functools import lru_cache\n",
        "\n",
        "import torch\n",
        "import requests\n",
        "from PIL import Image, ImageSequence\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models as qmodels\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = Path(\"data/processed\")\n",
        "CHUNKS = DATA_DIR / \"chunks.jsonl\"\n",
        "IMAGES = DATA_DIR / \"images.jsonl\"\n",
        "\n",
        "# Device & Models\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "TXT_MODEL = SentenceTransformer(\"intfloat/e5-base-v2\", device=DEVICE)\n",
        "CLIP_MODEL = SentenceTransformer(\"clip-ViT-B-32\", device=DEVICE)\n",
        "\n",
        "TXT_DIM = TXT_MODEL.get_sentence_embedding_dimension() or 768\n",
        "IMG_DIM = CLIP_MODEL.get_sentence_embedding_dimension() or 512\n",
        "\n",
        "# Qdrant Cloud config\n",
        "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
        "QDRANT_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "assert QDRANT_URL and QDRANT_KEY, \"Set QDRANT_URL and QDRANT_API_KEY environment variables\"\n",
        "\n",
        "COLLECTION = \"batch_multimodal\"\n",
        "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_KEY, timeout=60)\n",
        "\n",
        "CAPTIONER_DEVICE = 0 if torch.cuda.is_available() else -1  # -1 → CPU\n",
        "\n",
        "@lru_cache()\n",
        "def captioner():\n",
        "    \"\"\"Load and cache the BLIP image-to-text pipeline.\"\"\"\n",
        "    return pipeline(\n",
        "        \"image-to-text\",\n",
        "        model=\"Salesforce/blip-image-captioning-base\",\n",
        "        device=CAPTIONER_DEVICE,\n",
        "    )\n",
        "\n",
        "def generate_caption(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Download an image (handles GIFs by selecting the first frame),\n",
        "    then generate and return a caption via BLIP.\n",
        "    Returns an empty string on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=10)\n",
        "        resp.raise_for_status()\n",
        "        buf = io.BytesIO(resp.content)\n",
        "        img = Image.open(buf)\n",
        "        # If animated or GIF, take first frame\n",
        "        if getattr(img, \"is_animated\", False) or img.format == \"GIF\":\n",
        "            frame = next(ImageSequence.Iterator(img))\n",
        "            img = frame.convert(\"RGB\")\n",
        "        else:\n",
        "            img = img.convert(\"RGB\")\n",
        "\n",
        "        result = captioner()(img, max_new_tokens=30)[0]\n",
        "        return result.get(\"generated_text\", \"\").strip()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def safe_caption(meta: dict) -> str:\n",
        "    \"\"\"\n",
        "    Use provided alt text if it has >=2 words, otherwise generate via BLIP.\n",
        "    \"\"\"\n",
        "    alt = (meta.get(\"alt\") or \"\").strip()\n",
        "    if len(alt.split()) < 2:\n",
        "        return generate_caption(meta[\"url\"])\n",
        "    return alt\n",
        "\n",
        "def batched(iterable, n: int):\n",
        "    \"\"\"Yield successive n-sized batches from iterable.\"\"\"\n",
        "    it = iter(iterable)\n",
        "    while True:\n",
        "        batch = list(itertools.islice(it, n))\n",
        "        if not batch:\n",
        "            break\n",
        "        yield batch\n",
        "\n",
        "# Index Text Chunks\n",
        "def index_text(client: QdrantClient):\n",
        "    \"\"\"Read text chunks, compute embeddings, and upsert into Qdrant.\"\"\"\n",
        "    with CHUNKS.open(encoding=\"utf-8\") as f:\n",
        "        docs = [json.loads(line) for line in f]\n",
        "\n",
        "    for batch in tqdm(batched(docs, 256), total=len(docs)//256 + 1, desc=\"Text\"):\n",
        "        texts = [doc[\"page_content\"] for doc in batch]\n",
        "        embeds = TXT_MODEL.encode(texts, batch_size=32, show_progress_bar=False)\n",
        "\n",
        "        points = []\n",
        "        for doc, vec in zip(batch, embeds):\n",
        "            payload = {\n",
        "                **doc.get(\"metadata\", {}),\n",
        "                \"page_content\": doc[\"page_content\"],\n",
        "                \"doc_type\": \"text\",\n",
        "            }\n",
        "            points.append(qmodels.PointStruct(\n",
        "                id=str(uuid.uuid4()),\n",
        "                vector={\"text\": vec.tolist()},\n",
        "                payload=payload,\n",
        "            ))\n",
        "\n",
        "        client.upsert(collection_name=COLLECTION, points=points)\n",
        "\n",
        "# ── 2Index Images\n",
        "def index_images(client: QdrantClient):\n",
        "    \"\"\"Read image metadata, generate captions, compute embeddings, and upsert into Qdrant.\"\"\"\n",
        "    with IMAGES.open(encoding=\"utf-8\") as f:\n",
        "        imgs = [json.loads(line) for line in f]\n",
        "\n",
        "    for batch in tqdm(batched(imgs, 128), total=len(imgs)//128 + 1, desc=\"Img\"):\n",
        "        captioned = []\n",
        "        for meta in batch:\n",
        "            cap = safe_caption(meta)\n",
        "            if cap:\n",
        "                captioned.append((meta, cap))\n",
        "\n",
        "        if not captioned:\n",
        "            continue\n",
        "\n",
        "        metas, captions = zip(*captioned)\n",
        "        embeds = CLIP_MODEL.encode(list(captions), batch_size=32, show_progress_bar=False)\n",
        "\n",
        "        points = []\n",
        "        for meta, vec, cap in zip(metas, embeds, captions):\n",
        "            points.append(qmodels.PointStruct(\n",
        "                id=str(uuid.uuid4()),\n",
        "                vector={\"image\": vec.tolist()},\n",
        "                payload={\n",
        "                    \"slug\": meta[\"slug\"],\n",
        "                    \"img_url\": meta[\"url\"],\n",
        "                    \"caption\": cap,\n",
        "                    \"doc_type\": \"image\",\n",
        "                },\n",
        "            ))\n",
        "\n",
        "        client.upsert(collection_name=COLLECTION, points=points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUyZRXahO18_",
        "outputId": "4e9ff818-ef81-41ce-eb6b-8a8c1d308c3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Img:   0%|          | 0/19 [00:00<?, ?it/s]Device set to use cuda:0\n",
            "Img: 100%|██████████| 19/19 [05:09<00:00, 16.29s/it]\n",
            "Text: 100%|██████████| 62/62 [06:07<00:00,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Qdrant Cloud population completed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the collection if it doesn't exist\n",
        "existing = [c.name for c in client.get_collections().collections]\n",
        "if COLLECTION not in existing:\n",
        "    client.recreate_collection(\n",
        "        collection_name=COLLECTION,\n",
        "        vectors_config={\n",
        "            \"text\":  qmodels.VectorParams(size=int(TXT_DIM), distance=\"Cosine\"),\n",
        "            \"image\": qmodels.VectorParams(size=int(IMG_DIM), distance=\"Cosine\"),\n",
        "        },\n",
        "    )\n",
        "\n",
        "index_images(client)\n",
        "index_text(client)\n",
        "\n",
        "print(\"✅ Qdrant Cloud population completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Streamlit Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "fNjYvlG-mjlL"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit URL:\", public_url)\n",
        "\n",
        "!streamlit run streamlit_app.py \\\n",
        "    --server.port 8501 \\\n",
        "    --server.address 0.0.0.0 \\\n",
        "    --server.headless true \\\n",
        "    --server.fileWatcherType none &"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
